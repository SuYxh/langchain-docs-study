# 13. æµå¼å¤„ç†è¯¦è§£

## ç®€å•æ¥è¯´

**Streamingï¼ˆæµå¼å¤„ç†ï¼‰å°±æ˜¯è®© AI å›å¤"è¾¹æƒ³è¾¹è¯´"ï¼Œè€Œä¸æ˜¯"æ†‹åŠå¤©ä¸€å£æ°”å…¨åå‡ºæ¥"ã€‚** LangGraph æä¾› 5 ç§æµæ¨¡å¼ï¼Œè®©ä½ èƒ½å®æ—¶è·å– LLM è¾“å‡ºã€å›¾çŠ¶æ€å˜åŒ–å’Œè‡ªå®šä¹‰è¿›åº¦ä¿¡æ¯ï¼Œå¤§å¹…æå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ æœ¬èŠ‚ç›®æ ‡

å­¦å®Œæœ¬èŠ‚ï¼Œä½ å°†èƒ½å¤Ÿå›ç­”ï¼š

1. LangGraph æ”¯æŒå“ª 5 ç§æµæ¨¡å¼ï¼Ÿå„è‡ªé€‚ç”¨ä»€ä¹ˆåœºæ™¯ï¼Ÿ
2. å¦‚ä½•å®ç° LLM è¾“å‡ºçš„"æ‰“å­—æœºæ•ˆæœ"ï¼Ÿ
3. å¦‚ä½•æ¨é€è‡ªå®šä¹‰çš„è¿›åº¦ä¿¡æ¯ç»™å‰ç«¯ï¼Ÿ
4. å­å›¾çš„æµå¼è¾“å‡ºå¦‚ä½•é…ç½®ï¼Ÿ
5. å¤šä¸ª LLM è°ƒç”¨æ—¶ï¼Œå¦‚ä½•åªæµå¼è¾“å‡ºç‰¹å®šçš„é‚£ä¸ªï¼Ÿ

---

## æ ¸å¿ƒç—›ç‚¹ä¸è§£å†³æ–¹æ¡ˆ

### ç—›ç‚¹ï¼šç”¨æˆ·ç›¯ç€ç©ºç™½å±å¹•ç­‰åˆ°ç„¦è™‘

| åœºæ™¯ | ä¼ ç»Ÿ invoke() çš„é—®é¢˜ | ç”¨æˆ·æ„Ÿå— |
|------|---------------------|---------|
| é•¿æ–‡æœ¬ç”Ÿæˆ | ç­‰ 30 ç§’æ‰æœ‰ååº” | "å®ƒæ˜¯ä¸æ˜¯æŒ‚äº†ï¼Ÿ" |
| å¤šæ­¥éª¤ä»»åŠ¡ | çœ‹ä¸åˆ°ä¸­é—´è¿›åº¦ | "åˆ°åº•åœ¨å¹²å˜›ï¼Ÿ" |
| å¤æ‚ Agent | å·¥å…·è°ƒç”¨å¾ˆæ…¢ | "æˆ‘è¦ä¸è¦åˆ·æ–°ï¼Ÿ" |
| å­å›¾åµŒå¥— | åªçœ‹åˆ°æœ€ç»ˆç»“æœ | "ä¸­é—´éƒ½å‘ç”Ÿäº†å•¥ï¼Ÿ" |

### è§£å†³ï¼šåƒç›´æ’­ä¸€æ ·å®æ—¶æ¨é€

```
ä¼ ç»Ÿæ–¹å¼ï¼ˆinvokeï¼‰ï¼š
ç”¨æˆ·è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ [ç­‰å¾…30ç§’] â†’ å®Œæ•´ç»“æœ

æµå¼æ–¹å¼ï¼ˆstreamï¼‰ï¼š
ç”¨æˆ·è¾“å…¥ â†’ token1 â†’ token2 â†’ token3 â†’ ... â†’ tokenN â†’ ç»“æŸ
          â†“        â†“        â†“              â†“
         å®æ—¶æ˜¾ç¤º  å®æ—¶æ˜¾ç¤º  å®æ—¶æ˜¾ç¤º      å®æ—¶æ˜¾ç¤º
```

---

## ç”Ÿæ´»åŒ–ç±»æ¯”

### ğŸ­ ç±»æ¯”ï¼šå¤–å–é…é€è¿½è¸ªç³»ç»Ÿ

æŠŠ LangGraph çš„ Streaming æƒ³è±¡æˆä¸€ä¸ª**å¤–å– App çš„å®æ—¶é…é€è¿½è¸ª**ï¼š

| LangGraph æ¦‚å¿µ | å¤–å–ç±»æ¯” |
|---------------|---------|
| **Graphï¼ˆå›¾ï¼‰** | æ•´ä¸ªé¤å…çš„å‡ºé¤æµç¨‹ |
| **Nodeï¼ˆèŠ‚ç‚¹ï¼‰** | å„ä¸ªå·¥ä½ï¼šå¤‡èœå‘˜ã€å¨å¸ˆã€æ‰“åŒ…å‘˜ |
| **Stateï¼ˆçŠ¶æ€ï¼‰** | è®¢å•çš„å½“å‰çŠ¶æ€ |
| **`updates` æ¨¡å¼** | "å¨å¸ˆå¼€å§‹ç‚’èœäº†"ã€"æ‰“åŒ…å‘˜æ­£åœ¨è£…ç›’" |
| **`values` æ¨¡å¼** | "è®¢å•123ï¼Œå·²å¤‡èœï¼Œæ­£åœ¨ç‚’åˆ¶ï¼Œé¢„è®¡5åˆ†é’Ÿ" |
| **`messages` æ¨¡å¼** | å¨å¸ˆç›´æ’­ï¼š"ç°åœ¨æ”¾ç›â€¦â€¦åŠ ç‚¹ç³–â€¦â€¦èµ·é”…ï¼" |
| **`custom` æ¨¡å¼** | è‡ªå®šä¹‰æ¨é€ï¼š"æœ¬åº—ä»Šæ—¥ç‰¹æƒ å·²åŠ å…¥æ‚¨çš„è®¢å•" |
| **`debug` æ¨¡å¼** | åå¨ç›‘æ§å…¨å¼€ï¼šåŸæ–™åº“å­˜ã€ç‡ƒæ°”ç«åŠ›ã€å†·é“¾æ¸©åº¦â€¦ |

**æ²¡æœ‰ Streaming**ï¼šç‚¹å®Œå¤–å–åªèƒ½ç­‰ï¼Œç›´åˆ°éª‘æ‰‹æ•²é—¨ã€‚

**æœ‰äº† Streaming**ï¼š
```
å•†å®¶å·²æ¥å• â†’ å¤‡èœä¸­ â†’ åˆ¶ä½œä¸­ â†’ å·²å‡ºé¤ â†’ éª‘æ‰‹å·²å–é¤ â†’ è·æ‚¨è¿˜æœ‰2å…¬é‡Œ
```

æ•´ä¸ªè¿‡ç¨‹é€æ˜å¯è§ï¼Œç„¦è™‘æ„Ÿå¤§å¤§é™ä½ï¼

---

## 5 ç§æµæ¨¡å¼è¯¦è§£

### æ¨¡å¼é€ŸæŸ¥è¡¨

| æ¨¡å¼ | å¤§ç™½è¯è§£é‡Š | é€‚ç”¨åœºæ™¯ |
|-----|-----------|---------|
| **`values`** | æ¯ä¸€æ­¥éƒ½ç»™ä½ **å®Œæ•´çš„å½“å‰çŠ¶æ€**å¿«ç…§ | éœ€è¦éšæ—¶çŸ¥é“"æ•´ä½“æ˜¯ä»€ä¹ˆæƒ…å†µ" |
| **`updates`** | åªå‘Šè¯‰ä½ **è¿™ä¸€æ­¥æ”¹å˜äº†ä»€ä¹ˆ**ï¼ˆå¢é‡ï¼‰ | åªå…³å¿ƒå˜åŒ–ï¼ŒèŠ‚çœå¸¦å®½ |
| **`messages`** | ä¸€ä¸ª token ä¸€ä¸ª token åœ°æ¨é€ **LLM è¾“å‡º** | å®ç°æ‰“å­—æœºæ•ˆæœ ğŸ”¥ æœ€å¸¸ç”¨ |
| **`custom`** | ä½ è‡ªå·±å®šä¹‰çš„**ä»»æ„æ•°æ®** | æ¨é€è¿›åº¦æ¡ã€çŠ¶æ€æç¤º |
| **`debug`** | æŠŠ**èƒ½ç»™çš„ä¿¡æ¯å…¨ç»™ä½ **ï¼Œäº‹æ— å·¨ç»† | è°ƒè¯•é—®é¢˜ï¼Œæ’æŸ¥ bug |

### æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    graph.stream(inputs, options)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ values  â”‚          â”‚ updates â”‚          â”‚messages â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
   å®Œæ•´çŠ¶æ€å¿«ç…§          çŠ¶æ€å¢é‡æ›´æ–°         LLM Token æµ
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                           â”‚
        â–¼                                           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ custom  â”‚                                â”‚  debug  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                                          â”‚
   è‡ªå®šä¹‰æ•°æ®æ¨é€                              è¯¦ç»†è°ƒè¯•ä¿¡æ¯
```

---

## åŸºç¡€ç”¨æ³•

### 1. `updates` æ¨¡å¼ï¼šåªçœ‹å˜åŒ–

```typescript
import { StateGraph, Annotation, START, END } from "@langchain/langgraph";

const State = Annotation.Root({
  topic: Annotation<string>(),
  joke: Annotation<string>(),
});

const graph = new StateGraph(State)
  .addNode("refineTopic", (state) => {
    return { topic: state.topic + " and cats" };
  })
  .addNode("generateJoke", (state) => {
    return { joke: `This is a joke about ${state.topic}` };
  })
  .addEdge(START, "refineTopic")
  .addEdge("refineTopic", "generateJoke")
  .addEdge("generateJoke", END)
  .compile();

for await (const chunk of await graph.stream(
  { topic: "ice cream" },
  { streamMode: "updates" }
)) {
  console.log(chunk);
}
```

**è¾“å‡º**ï¼š

```
{ refineTopic: { topic: 'ice cream and cats' } }
{ generateJoke: { joke: 'This is a joke about ice cream and cats' } }
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æ¯å½“æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œï¼Œå°±å‘Šè¯‰æˆ‘è¿™ä¸ªèŠ‚ç‚¹æ”¹äº†å•¥ã€‚ç¬¬ä¸€è¡Œæ˜¯ `refineTopic` èŠ‚ç‚¹æŠŠ topic æ”¹æˆäº† `ice cream and cats`ï¼Œç¬¬äºŒè¡Œæ˜¯ `generateJoke` èŠ‚ç‚¹ç”Ÿæˆäº†ç¬‘è¯ã€‚"

---

### 2. `values` æ¨¡å¼ï¼šçœ‹å®Œæ•´çŠ¶æ€

```typescript
for await (const chunk of await graph.stream(
  { topic: "ice cream" },
  { streamMode: "values" }
)) {
  console.log(chunk);
}
```

**è¾“å‡º**ï¼š

```
{ topic: 'ice cream', joke: '' }
{ topic: 'ice cream and cats', joke: '' }
{ topic: 'ice cream and cats', joke: 'This is a joke about ice cream and cats' }
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æ¯ä¸€æ­¥éƒ½ç»™æˆ‘å®Œæ•´çš„çŠ¶æ€å¿«ç…§ã€‚ç¬¬ä¸€è¡Œæ˜¯åˆå§‹çŠ¶æ€ï¼Œç¬¬äºŒè¡Œæ˜¯ `refineTopic` æ‰§è¡Œåçš„å®Œæ•´çŠ¶æ€ï¼Œç¬¬ä¸‰è¡Œæ˜¯æœ€ç»ˆçŠ¶æ€ã€‚"

---

### 3. `messages` æ¨¡å¼ï¼šLLM æ‰“å­—æœºæ•ˆæœ ğŸ”¥

è¿™æ˜¯å®ç°"æ‰“å­—æœºæ•ˆæœ"çš„æ ¸å¿ƒæ¨¡å¼ï¼š

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { StateGraph, Annotation, START, END } from "@langchain/langgraph";

const State = Annotation.Root({
  topic: Annotation<string>(),
  joke: Annotation<string>(),
});

const model = new ChatOpenAI({ model: "gpt-4o-mini" });

const callModel = async (state: typeof State.State) => {
  const response = await model.invoke([
    { role: "user", content: `Generate a joke about ${state.topic}` },
  ]);
  return { joke: response.content };
};

const graph = new StateGraph(State)
  .addNode("callModel", callModel)
  .addEdge(START, "callModel")
  .addEdge("callModel", END)
  .compile();

for await (const [messageChunk, metadata] of await graph.stream(
  { topic: "ice cream" },
  { streamMode: "messages" }
)) {
  if (messageChunk.content) {
    process.stdout.write(messageChunk.content as string);
  }
}
```

**è¾“å‡ºæ•ˆæœ**ï¼ˆé€å­—æ˜¾ç¤ºï¼‰ï¼š

```
Why did the ice cream go to therapy? Because it had too many toppings and couldn't stop melting down!
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "LLM æ¯ç”Ÿæˆä¸€ä¸ª tokenï¼Œå°±ç«‹åˆ»æ¨ç»™æˆ‘ã€‚ç”¨æˆ·çœ‹åˆ°çš„æ•ˆæœå°±æ˜¯æ–‡å­—ä¸€ä¸ªä¸€ä¸ªå¾€å¤–è¹¦ï¼Œå°±åƒæœ‰äººåœ¨å®æ—¶æ‰“å­—ä¸€æ ·ã€‚"

**è¿”å›å€¼ç»“æ„**ï¼š

```typescript
[messageChunk, metadata]
```

- `messageChunk`ï¼šLLM ç”Ÿæˆçš„ token ç‰‡æ®µ
- `metadata`ï¼šå…ƒæ•°æ®ï¼ŒåŒ…å«èŠ‚ç‚¹åã€æ ‡ç­¾ç­‰ä¿¡æ¯

---

### 4. `custom` æ¨¡å¼ï¼šæ¨é€è‡ªå®šä¹‰æ•°æ®

å½“ä½ éœ€è¦æ¨é€è¿›åº¦æ¡ã€çŠ¶æ€æç¤ºç­‰è‡ªå®šä¹‰ä¿¡æ¯æ—¶ï¼š

```typescript
import { StateGraph, Annotation, START, END, LangGraphRunnableConfig } from "@langchain/langgraph";

const State = Annotation.Root({
  query: Annotation<string>(),
  result: Annotation<string>(),
});

const processData = async (
  state: typeof State.State,
  config: LangGraphRunnableConfig
) => {
  config.writer?.({ progress: "0%", status: "å¼€å§‹å¤„ç†..." });
  
  await new Promise(resolve => setTimeout(resolve, 1000));
  config.writer?.({ progress: "50%", status: "æ­£åœ¨åˆ†ææ•°æ®..." });
  
  await new Promise(resolve => setTimeout(resolve, 1000));
  config.writer?.({ progress: "100%", status: "å¤„ç†å®Œæˆï¼" });
  
  return { result: "å¤„ç†ç»“æœï¼šæ•°æ®åˆ†æå®Œæˆ" };
};

const graph = new StateGraph(State)
  .addNode("processData", processData)
  .addEdge(START, "processData")
  .addEdge("processData", END)
  .compile();

for await (const chunk of await graph.stream(
  { query: "åˆ†æé”€å”®æ•°æ®" },
  { streamMode: "custom" }
)) {
  console.log(chunk);
}
```

**è¾“å‡º**ï¼š

```
{ progress: '0%', status: 'å¼€å§‹å¤„ç†...' }
{ progress: '50%', status: 'æ­£åœ¨åˆ†ææ•°æ®...' }
{ progress: '100%', status: 'å¤„ç†å®Œæˆï¼' }
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æˆ‘åœ¨èŠ‚ç‚¹é‡Œç”¨ `config.writer()` æ‰‹åŠ¨æ¨é€äº† 3 æ¬¡è¿›åº¦ä¿¡æ¯ã€‚å‰ç«¯å¯ä»¥æ ¹æ®è¿™äº›ä¿¡æ¯æ›´æ–°è¿›åº¦æ¡ï¼Œè®©ç”¨æˆ·çŸ¥é“åå°æ­£åœ¨å¹²æ´»ã€‚"

---

### 5. `debug` æ¨¡å¼ï¼šè°ƒè¯•åˆ©å™¨

```typescript
for await (const chunk of await graph.stream(
  { topic: "ice cream" },
  { streamMode: "debug" }
)) {
  console.log(JSON.stringify(chunk, null, 2));
}
```

**è¾“å‡º**ï¼ˆä¿¡æ¯éå¸¸è¯¦ç»†ï¼‰ï¼š

```json
{
  "type": "task",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "step": 1,
  "payload": {
    "name": "refineTopic",
    "input": { "topic": "ice cream" },
    "triggers": ["start:refineTopic"]
  }
}
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æŠŠæ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ‰€æœ‰ç»†èŠ‚éƒ½ç»™æˆ‘ï¼ŒåŒ…æ‹¬æ—¶é—´æˆ³ã€æ­¥éª¤ç¼–å·ã€èŠ‚ç‚¹åç§°ã€è¾“å…¥è¾“å‡ºç­‰ã€‚è°ƒè¯•é—®é¢˜æ—¶è¶…æœ‰ç”¨ï¼Œä½†ä¿¡æ¯é‡å¾ˆå¤§ï¼Œç”Ÿäº§ç¯å¢ƒåˆ«å¼€ã€‚"

---

## å¤šæ¨¡å¼ç»„åˆ

å¯ä»¥åŒæ—¶ä½¿ç”¨å¤šç§æµæ¨¡å¼ï¼š

```typescript
for await (const [mode, chunk] of await graph.stream(
  { topic: "ice cream" },
  { streamMode: ["updates", "custom"] }
)) {
  console.log(`[${mode}]`, chunk);
}
```

**è¾“å‡º**ï¼š

```
[custom] { progress: '0%', status: 'å¼€å§‹å¤„ç†...' }
[updates] { refineTopic: { topic: 'ice cream and cats' } }
[custom] { progress: '100%', status: 'å¤„ç†å®Œæˆï¼' }
[updates] { generateJoke: { joke: '...' } }
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æˆ‘æƒ³åŒæ—¶çœ‹åˆ°çŠ¶æ€æ›´æ–°å’Œè‡ªå®šä¹‰è¿›åº¦ã€‚è¿”å›çš„æ˜¯ `[mode, chunk]` å…ƒç»„ï¼Œ`mode` å‘Šè¯‰æˆ‘è¿™æ¡æ•°æ®æ¥è‡ªå“ªä¸ªæµæ¨¡å¼ã€‚"

---

## å­å›¾æµå¼è¾“å‡º

å½“å›¾ä¸­åµŒå¥—äº†å­å›¾æ—¶ï¼Œé»˜è®¤åªèƒ½çœ‹åˆ°çˆ¶å›¾çš„è¾“å‡ºã€‚è®¾ç½® `subgraphs: true` åå¯ä»¥çœ‹åˆ°å­å›¾å†…éƒ¨çš„æ‰§è¡Œç»†èŠ‚ï¼š

```typescript
import { StateGraph, Annotation, START, END } from "@langchain/langgraph";

const SubgraphState = Annotation.Root({
  foo: Annotation<string>(),
  bar: Annotation<string>(),
});

const subgraph = new StateGraph(SubgraphState)
  .addNode("subNode1", (state) => ({ bar: "bar" }))
  .addNode("subNode2", (state) => ({ foo: state.foo + state.bar }))
  .addEdge(START, "subNode1")
  .addEdge("subNode1", "subNode2")
  .addEdge("subNode2", END)
  .compile();

const ParentState = Annotation.Root({
  foo: Annotation<string>(),
});

const parentGraph = new StateGraph(ParentState)
  .addNode("parentNode", (state) => ({ foo: "hi! " + state.foo }))
  .addNode("callSubgraph", subgraph)
  .addEdge(START, "parentNode")
  .addEdge("parentNode", "callSubgraph")
  .addEdge("callSubgraph", END)
  .compile();

for await (const chunk of await parentGraph.stream(
  { foo: "foo" },
  {
    subgraphs: true,
    streamMode: "updates",
  }
)) {
  console.log(chunk);
}
```

**è¾“å‡º**ï¼š

```
[[], { parentNode: { foo: 'hi! foo' } }]
[['callSubgraph:abc123'], { subNode1: { bar: 'bar' } }]
[['callSubgraph:abc123'], { subNode2: { foo: 'hi! foobar' } }]
[[], { callSubgraph: { foo: 'hi! foobar' } }]
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "è¿”å›çš„æ˜¯ `[namespace, data]` å…ƒç»„ã€‚`[]` è¡¨ç¤ºçˆ¶å›¾ï¼Œ`['callSubgraph:abc123']` è¡¨ç¤ºå­å›¾ã€‚è¿™æ ·æˆ‘å°±èƒ½çœ‹åˆ°å­å›¾å†…éƒ¨æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæƒ…å†µäº†ã€‚"

---

## é«˜çº§æŠ€å·§

### 1. æŒ‰æ ‡ç­¾è¿‡æ»¤ LLM è¾“å‡º

å½“å›¾ä¸­æœ‰å¤šä¸ª LLM è°ƒç”¨æ—¶ï¼Œå¯ä»¥ç”¨æ ‡ç­¾ç­›é€‰ï¼š

```typescript
import { ChatOpenAI } from "@langchain/openai";

const jokeModel = new ChatOpenAI({
  model: "gpt-4o-mini",
  tags: ["joke"],
});

const poemModel = new ChatOpenAI({
  model: "gpt-4o-mini",
  tags: ["poem"],
});

for await (const [msg, metadata] of await graph.stream(
  { topic: "cats" },
  { streamMode: "messages" }
)) {
  if (metadata.tags?.includes("joke")) {
    process.stdout.write(msg.content as string);
  }
}
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "æˆ‘æœ‰ä¸¤ä¸ª LLMï¼Œä¸€ä¸ªå†™ç¬‘è¯ï¼Œä¸€ä¸ªå†™è¯—ã€‚æˆ‘åªæƒ³çœ‹ç¬‘è¯é‚£ä¸ªçš„å®æ—¶è¾“å‡ºï¼Œé€šè¿‡ `tags` è¿‡æ»¤å°±è¡Œã€‚"

### 2. æŒ‰èŠ‚ç‚¹è¿‡æ»¤ LLM è¾“å‡º

```typescript
for await (const [msg, metadata] of await graph.stream(
  { topic: "cats" },
  { streamMode: "messages" }
)) {
  if (msg.content && metadata.langgraph_node === "writeJoke") {
    process.stdout.write(msg.content as string);
  }
}
```

ğŸ’¡ **äººè¯è§£è¯»**ï¼š
> "metadata é‡Œæœ‰ `langgraph_node` å­—æ®µï¼Œå‘Šè¯‰æˆ‘è¿™ä¸ª token æ¥è‡ªå“ªä¸ªèŠ‚ç‚¹ã€‚æˆ‘åªè¦ `writeJoke` èŠ‚ç‚¹çš„è¾“å‡ºã€‚"

### 3. åœ¨å·¥å…·ä¸­æ¨é€è‡ªå®šä¹‰æ•°æ®

```typescript
import { tool } from "@langchain/core/tools";
import { z } from "zod";

const queryDatabase = tool(
  async (input, config) => {
    config.writer?.({ type: "progress", data: "æŸ¥è¯¢ä¸­ 0/100..." });
    
    // æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    config.writer?.({ type: "progress", data: "æŸ¥è¯¢å®Œæˆ 100/100" });
    
    return "æŸ¥è¯¢ç»“æœï¼šå…±æ‰¾åˆ° 42 æ¡è®°å½•";
  },
  {
    name: "query_database",
    description: "æŸ¥è¯¢æ•°æ®åº“",
    schema: z.object({
      query: z.string().describe("SQL æŸ¥è¯¢è¯­å¥"),
    }),
  }
);
```

### 4. ä½¿ç”¨ä»»æ„ LLMï¼ˆé LangChain é›†æˆï¼‰

å¦‚æœä½ çš„ LLM æ²¡æœ‰ LangChain é›†æˆï¼Œå¯ä»¥ç”¨ `custom` æ¨¡å¼æ‰‹åŠ¨æµå¼ï¼š

```typescript
import OpenAI from "openai";

const openaiClient = new OpenAI();

const callArbitraryModel = async (state: any, config: LangGraphRunnableConfig) => {
  const response = await openaiClient.chat.completions.create({
    messages: [{ role: "user", content: state.prompt }],
    model: "gpt-4o-mini",
    stream: true,
  });

  let fullContent = "";
  for await (const chunk of response) {
    const content = chunk.choices[0]?.delta?.content || "";
    fullContent += content;
    config.writer?.({ token: content });
  }

  return { result: fullContent };
};
```

### 5. ç¦ç”¨ç‰¹å®šæ¨¡å‹çš„æµå¼

æŸäº›æ¨¡å‹ï¼ˆå¦‚ o1-previewï¼‰ä¸æ”¯æŒæµå¼ï¼Œéœ€è¦æ˜¾å¼ç¦ç”¨ï¼š

```typescript
const model = new ChatOpenAI({
  model: "o1-preview",
  streaming: false,
});
```

---

## å®Œæ•´ä¸šåŠ¡åœºæ™¯ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { StateGraph, Annotation, START, END, LangGraphRunnableConfig } from "@langchain/langgraph";
import { tool } from "@langchain/core/tools";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { z } from "zod";

const State = Annotation.Root({
  messages: Annotation<any[]>({
    reducer: (curr, update) => [...curr, ...update],
    default: () => [],
  }),
  orderInfo: Annotation<string>(),
});

const queryOrder = tool(
  async (input, config) => {
    config.writer?.({ type: "status", message: "æ­£åœ¨æŸ¥è¯¢è®¢å•ä¿¡æ¯..." });
    await new Promise(resolve => setTimeout(resolve, 500));
    
    config.writer?.({ type: "status", message: "å·²æ‰¾åˆ°è®¢å•ï¼Œæ­£åœ¨è·å–ç‰©æµçŠ¶æ€..." });
    await new Promise(resolve => setTimeout(resolve, 500));
    
    return `è®¢å• ${input.orderId} å½“å‰çŠ¶æ€ï¼šè¿è¾“ä¸­ï¼Œé¢„è®¡æ˜å¤©é€è¾¾`;
  },
  {
    name: "query_order",
    description: "æŸ¥è¯¢è®¢å•çŠ¶æ€",
    schema: z.object({
      orderId: z.string().describe("è®¢å•å·"),
    }),
  }
);

const tools = [queryOrder];
const toolNode = new ToolNode(tools);

const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  tags: ["customer_service"],
}).bindTools(tools);

const callModel = async (state: typeof State.State) => {
  const response = await model.invoke(state.messages);
  return { messages: [response] };
};

const shouldContinue = (state: typeof State.State) => {
  const lastMessage = state.messages[state.messages.length - 1];
  if (lastMessage.tool_calls?.length > 0) {
    return "tools";
  }
  return END;
};

const graph = new StateGraph(State)
  .addNode("agent", callModel)
  .addNode("tools", toolNode)
  .addEdge(START, "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END])
  .addEdge("tools", "agent")
  .compile();

async function main() {
  const inputs = {
    messages: [
      { role: "user", content: "æˆ‘è®¢å• #12345 çš„ç‰©æµçŠ¶æ€æ˜¯ä»€ä¹ˆï¼Ÿ" }
    ],
  };

  console.log("=== æ™ºèƒ½å®¢æœç³»ç»Ÿ ===\n");
  console.log("ç”¨æˆ·ï¼šæˆ‘è®¢å• #12345 çš„ç‰©æµçŠ¶æ€æ˜¯ä»€ä¹ˆï¼Ÿ\n");
  console.log("å®¢æœï¼š");

  for await (const [mode, chunk] of await graph.stream(
    inputs,
    { streamMode: ["messages", "custom"] }
  )) {
    if (mode === "custom") {
      console.log(`\nğŸ“ ${chunk.message}`);
    } else if (mode === "messages") {
      const [msg, metadata] = chunk;
      if (msg.content && metadata.langgraph_node === "agent") {
        process.stdout.write(msg.content as string);
      }
    }
  }
  console.log("\n");
}

main();
```

**æ‰§è¡Œæ•ˆæœ**ï¼š

```
=== æ™ºèƒ½å®¢æœç³»ç»Ÿ ===

ç”¨æˆ·ï¼šæˆ‘è®¢å• #12345 çš„ç‰©æµçŠ¶æ€æ˜¯ä»€ä¹ˆï¼Ÿ

å®¢æœï¼š
ğŸ“ æ­£åœ¨æŸ¥è¯¢è®¢å•ä¿¡æ¯...
ğŸ“ å·²æ‰¾åˆ°è®¢å•ï¼Œæ­£åœ¨è·å–ç‰©æµçŠ¶æ€...
æ‚¨çš„è®¢å• #12345 å½“å‰çŠ¶æ€æ˜¯è¿è¾“ä¸­ï¼Œé¢„è®¡æ˜å¤©é€è¾¾ã€‚è¿˜æœ‰å…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ
```

---

## æ€»ç»“å¯¹æ¯”è¡¨

| æµæ¨¡å¼ | è¿”å›æ ¼å¼ | å…¸å‹ç”¨é€” | æ€§èƒ½å½±å“ |
|-------|---------|---------|---------|
| `values` | `state` | ç›‘æ§å®Œæ•´çŠ¶æ€ | æ•°æ®é‡å¤§ |
| `updates` | `{ nodeName: updates }` | ç›‘æ§çŠ¶æ€å˜åŒ– | æ•°æ®é‡å° |
| `messages` | `[messageChunk, metadata]` | æ‰“å­—æœºæ•ˆæœ | å®æ—¶æ€§å¥½ |
| `custom` | è‡ªå®šä¹‰æ•°æ® | è¿›åº¦æ¨é€ | æŒ‰éœ€ä½¿ç”¨ |
| `debug` | è¯¦ç»†è°ƒè¯•ä¿¡æ¯ | æ’æŸ¥é—®é¢˜ | æ•°æ®é‡æå¤§ |

---

## æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **5 ç§æµæ¨¡å¼**ï¼š`values`ï¼ˆå®Œæ•´çŠ¶æ€ï¼‰ã€`updates`ï¼ˆå¢é‡æ›´æ–°ï¼‰ã€`messages`ï¼ˆLLM Tokenï¼‰ã€`custom`ï¼ˆè‡ªå®šä¹‰æ•°æ®ï¼‰ã€`debug`ï¼ˆè°ƒè¯•ä¿¡æ¯ï¼‰

2. **æ‰“å­—æœºæ•ˆæœ**ï¼šä½¿ç”¨ `streamMode: "messages"` å®ç° LLM è¾“å‡ºçš„é€å­—æ˜¾ç¤º

3. **è‡ªå®šä¹‰è¿›åº¦**ï¼šåœ¨èŠ‚ç‚¹æˆ–å·¥å…·ä¸­ä½¿ç”¨ `config.writer()` æ¨é€è‡ªå®šä¹‰æ•°æ®

4. **å­å›¾æµå¼**ï¼šè®¾ç½® `subgraphs: true` å¯ä»¥çœ‹åˆ°å­å›¾å†…éƒ¨çš„æ‰§è¡Œç»†èŠ‚

5. **è¿‡æ»¤æŠ€å·§**ï¼šé€šè¿‡ `tags` æˆ– `langgraph_node` è¿‡æ»¤ç‰¹å®š LLM çš„è¾“å‡º

---

## ä¸‹ä¸€æ­¥å­¦ä¹ 

- **ç¬¬ 14 ç« ï¼šä¸­æ–­æœºåˆ¶** - å­¦ä¹ å¦‚ä½•è®©å›¾"æš‚åœ"ç­‰å¾…äººå·¥ç¡®è®¤
- **ç¬¬ 15 ç« ï¼šå­å›¾æ„å»º** - æ·±å…¥å­¦ä¹ å­å›¾çš„è®¾è®¡ä¸çŠ¶æ€å…±äº«
