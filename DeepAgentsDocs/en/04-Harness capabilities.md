> ## Documentation Index
> Fetch the complete documentation index at: https://docs.langchain.com/llms.txt
> Use this file to discover all available pages before exploring further.

# Harness capabilities

An agent harness is a combination of several different capabilities that make building long-running agents easier:

* [Planning capabilities](#planning-capabilities)
* [Virtual filesystem](#virtual-filesystem-access)
* [Task delegation (subagents)](#task-delegation-subagents)
* [Context and token management](#context-management)
* [Code execution](#code-execution)
* [Human-in-the-loop](#human-in-the-loop)

Alongside these capabilities, deep agents use [Skills](#skills) and [Memory](#memory) for additional context and instructions.

## Planning capabilities

The harness provides a `write_todos` tool that agents can use to maintain a structured task list.

**Features:**

* Track multiple tasks with statuses (`'pending'`, `'in_progress'`, `'completed'`)
* Persisted in agent state
* Helps agent organize complex multi-step work
* Useful for long-running tasks and planning

## Virtual filesystem access

The harness provides a configurable virtual filesystem which can be backed by different pluggable backends.
The backends support the following file system operations:

| Tool         | Description                                                  |
| ------------ | ------------------------------------------------------------ |
| `ls`         | List files in a directory with metadata (size, modified time) |
| `read_file`  | Read file contents with line numbers, supports offset/limit for large files. Also supports reading images (`.png`, `.jpg`, `.jpeg`, `.gif`, `.webp`), returning them as multimodal content blocks. |
| `write_file` | Create new files                                             |
| `edit_file`  | Perform exact string replacements in files (with global replace mode) |
| `glob`       | Find files matching patterns (e.g., `**/*.py`)               |
| `grep`       | Search file contents with multiple output modes (files only, content with context, or counts) |
| `execute`    | Run shell commands in the environment (available with [sandbox backends](/oss/javascript/deepagents/sandboxes) only) |

The virtual filesystem is used by several other harness capabilities such as skills, memory, code execution, and context management.
You can also use the file system when building custom tools and middleware for deep agents.

For more information, see [backends](/oss/javascript/deepagents/backends).

## Task delegation (subagents)

The harness allows the main agent to create ephemeral "subagents" for isolated multi-step tasks.

**Why it's useful:**

* **Context isolation** - Subagent's work doesn't clutter main agent's context
* **Parallel execution** - Multiple subagents can run concurrently
* **Specialization** - Subagents can have different tools/configurations
* **Token efficiency** - Large subtask context is compressed into a single result

**How it works:**

* Main agent has a `task` tool
* When invoked, it creates a fresh agent instance with its own context
* Subagent executes autonomously until completion
* Returns a single final report to the main agent
* Subagents are stateless (can't send multiple messages back)

**Default subagent:**

* "general-purpose" subagent automatically available
* Has filesystem tools by default
* Can be customized with additional tools/middleware

**Custom subagents:**

* Define specialized subagents with specific tools
* Example: code-reviewer, web-researcher, test-runner
* Configure via `subagents` parameter

## Context management

Deep agents can handle long-running tasks by making use of effective context management.

Agents have access to several kinds of context.
Some sources are provided to the agent at startup; others become available during runtime, such as user input.

This section provides an overview of the different kinds of context your deep agent has access to and manages.

### Input context

Input context consists of sources of information provided to your deep agent at startup that are added to the prompt.

#### Prompts

Deep agents use system prompts to define the agent's role, behavior, capabilities, and knowledge base.
If you provide a custom system prompt, this gets prepended to the built-in system prompt which includes detailed guidance for using built-in tools like the planning tool, filesystem tools, and subagents.

Middleware that adds tools (such as the filesystem middleware) automatically appends tool-specific instructions to the system prompt, creating tool prompts that explain how to use those tools effectively.

The final deep agent prompt consists of the following parts:

1. Custom system\_prompt (if provided)
2. [Base agent prompt](https://github.com/langchain-ai/deepagents/blob/595f6fe66bd974eaba9d429a76217607cb02f7a8/libs/deepagents/deepagents/graph.py#L36)
3. To-do list prompt: Instructions for how to plan with to do lists
4. Memory prompt: AGENTS.md + memory usage guidelines (only when `memory` provided)
5. Skills prompt: Skills locations + list of skills with frontmatter information + usage (only when skills provided)
6. Virtual filesystem prompt (filesystem + execute tool docs if applicable)
7. Subagent prompt: Task tool usage
8. User-provided middleware prompts (if custom middleware is provided)
9. Human-in-the-loop prompt (when `interrupt_on` is set)
10. Local context prompt: Current directory, project info,... (when using CLI locally)

### Runtime context

Deep agents use a pattern called context compression which works by reducing the size of the information in an agent's working memory while preserving the details that are relevant to the task.
The following techniques are the built-in features to ensure the context passed to LLMs stays within its context window limit:

* [Offloading large tool inputs and results](#offloading-large-tool-inputs-and-results)
* [Summarization](#summarization)

You can also configure deep agents to use [long-term memory](#long-term-memory) to allow them to store information across different threads and conversations.

#### Offloading large tool inputs and results

Deep agents use the [built-in filesystem tools](#virtual-filesystem-access) to automatically offload content and to search and retrieve that offloaded content as needed.
Content offloading happens in two cases:

1. **Tool call inputs exceed 20,000 tokens** (configurable via `tool_token_limit_before_evict`): File write and edit operations leave behind tool calls containing the complete file content in the agent's conversation history.
   Since this content is already persisted to the filesystem, it's often redundant.
   As the session context crosses 85% of the model’s available window, Deep agents will truncate older tool calls, replacing them with a pointer to the file on disk and reducing the size of the active context.

   <img src="https://qn.huat.xyz/mac/202602201648483.png" alt="An example of offloading showing a large input which is saved to disk and the truncated version is used for the tool call" data-og-width="1091" width="1091" data-og-height="814" height="814" data-path="oss/images/deepagents/offloading-inputs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=280&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=544650b68280a6d91241bbfbdc613e81 280w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=560&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=5c93768e7d456633d690b9c9f24ad9d3 560w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=840&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=a8553da6f05aa7699cb084e25b12af23 840w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=1100&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=9f906ee84955a23c4e5be0df6ffa5c84 1100w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=1650&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=472f7567cae9a81b3c4fe79f91766d80 1650w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-inputs.png?w=2500&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=f45994d77cce0d734924e6763b6568c3 2500w" />

2. **Tool call results exceed 20,000 tokens** (configurable via `tool_token_limit_before_evict`): When this occurs, the deep agent offloads the response to the configured backend and substitutes it with a file path reference and a preview of the first 10 lines. Agents can then re-read or search the content as needed.

   <img src="https://qn.huat.xyz/mac/202602201648891.png" alt="An example of offloading showing a large tool response that is replaced with a message about the location of the offloaded results and the first 10 lines of the result" data-og-width="1360" width="1360" data-og-height="922" height="922" data-path="oss/images/deepagents/offloading-results.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=280&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=4dabd620ea3ac3b5ba315d4137b43de3 280w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=560&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=afc65620e0a37a325fc886b44de819c1 560w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=840&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=c2a490f1318d7cb0e7e0330a9a970fb1 840w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=1100&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=c659515395a509db746d8e5f34717886 1100w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=1650&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=1614c8a3a5632e81d77a166a1414f99c 1650w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/offloading-results.png?w=2500&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=355a417f6404bc617a062d7f7f9907f1 2500w" />

#### Summarization

When the context size crosses the model's context window limit (for example 85% of `max_input_tokens`), and there is no more context eligible for offloading, the deep agent summarizes the message history.

This process has two components:

* **In-context summary**: An LLM generates a structured summary of the conversation—including session intent, artifacts created, and next steps—which replaces the full conversation history in the agent's working memory.
* **Filesystem preservation**: The complete, original conversation messages are written to the filesystem as a canonical record.

This dual approach ensures the agent maintains awareness of its goals and progress (via the summary) while preserving the ability to recover specific details when needed (via filesystem search).

<img src="https://qn.huat.xyz/mac/202602201648377.png" alt="An example of summarization showing an agent's conversation history, where several steps get compacted" data-og-width="1000" width="1000" data-og-height="587" height="587" data-path="oss/images/deepagents/summarization.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=280&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=e7259f3c8ca61e5329fbe7ae8d0eebed 280w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=560&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=184c0f8a43c2127a5356d07bfaa4ba27 560w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=840&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=1b572c3908e87a6003dbfe5d94e3172b 840w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=1100&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=88d8df1393ae90391e6813d6d83a63f8 1100w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=1650&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=7593561188db79b3dfb949dc19f6dd0d 1650w, https://mintcdn.com/langchain-5e9cc07a/0G7fpRWZQ2tFN1wL/oss/images/deepagents/summarization.png?w=2500&fit=max&auto=format&n=0G7fpRWZQ2tFN1wL&q=85&s=d0f14c6b93f20245dba5a3c83169ba37 2500w" />

**Configuration:**

* Triggers at 85% of the model's `max_input_tokens` from its [model profile](/oss/javascript/langchain/models#model-profiles)
* Keeps 10% of tokens as recent context
* Falls back to 170,000-token trigger / 6 messages kept if model profile is unavailable
* Older messages are summarized by the model

**Why it's useful:**

* Enables very long conversations without hitting context limits
* Preserves recent context while compressing ancient history
* Transparent to the agent (appears as a special system message)

#### Long-term memory

When using the default filesystem, your deep agent stores its working memory files in agent state, which only persists within a single thread.
Long-term memory enables your deep agent to persist information across different threads and conversations.
To use long-term memory, you must use a `CompositeBackend` that routes specific paths (typically `/memories/`) to a LangGraph Store, which provides durable cross-thread persistence.
The `CompositeBackend` is a hybrid storage system where some files persist indefinitely while others remain scoped to a single thread.

Files that the agent stores in the long-term memory path (for example, `/memories/preferences.txt`) survive agent restarts and can be accessed from any conversation thread.
Deep agents can use these files for storing user preferences, accumulated knowledge, research progress, or any information that should persist beyond a single session.

For more information, see [Long-term memory](/oss/javascript/deepagents/long-term-memory).

## Code execution

When you use a [sandbox backend](/oss/javascript/deepagents/sandboxes), the harness exposes an `execute` tool that lets the agent run shell commands in an isolated environment. This enables the agent to install dependencies, run scripts, and execute code as part of its task.

**How it works:**

* Sandbox backends implement the `SandboxBackendProtocol` — when detected, the harness adds the `execute` tool to the agent's available tools
* Without a sandbox backend, the agent only has filesystem tools (`read_file`, `write_file`, etc.) and cannot run commands
* The `execute` tool returns combined stdout/stderr, exit code, and truncates large outputs (saving to a file for the agent to read incrementally)

**Why it's useful:**

* **Security** — Code runs in isolation, protecting your host system from the agent's operations
* **Clean environments** — Use specific dependencies or OS configurations without local setup
* **Reproducibility** — Consistent execution environments across teams

For setup, providers, and file transfer APIs, see [Sandboxes](/oss/javascript/deepagents/sandboxes).

## Human-in-the-loop

The harness can pause agent execution at specified tool calls to allow human approval or modification. This feature is opt-in via the `interrupt_on` parameter.

**Configuration:**

* Pass `interrupt_on` to `create_deep_agent` with a mapping of tool names to interrupt configurations
* Example: `interrupt_on={"edit_file": True}` pauses before every edit
* You can provide approval messages or modify tool inputs when prompted

**Why it's useful:**

* Safety gates for destructive operations
* User verification before expensive API calls
* Interactive debugging and guidance

## Skills

The harness supports skills that provide specialized workflows and domain knowledge to your deep agent.

**How it works:**

* Skills follow the [Agent Skills standard](https://agentskills.io/)
* Each skill is a directory containing a `SKILL.md` file with instructions and metadata
* Skills can include additional scripts, reference docs, templates, and other resources
* Skills use progressive disclosure—they are only loaded when the agent determines they're useful for the current task
* Agent reads frontmatter from each `SKILL.md` file at startup, then reviews full skill content when needed

**Why it's useful:**

* Reduces token usage by only loading relevant skills when needed
* Bundles capabilities together into larger actions with additional context
* Provides specialized expertise without cluttering the system prompt
* Enables modular, reusable agent capabilities

For more information, see [Skills](/oss/javascript/deepagents/skills).

## Memory

The harness supports persistent memory files that provide extra context to your deep agent across conversations.
These files often contain general coding style, preferences, conventions, and guidelines that help the agent understand how to work with your codebase and follow your preferences.

**How it works:**

* Uses [`AGENTS.md` files](https://agents.md/) to provide persistent context
* Memory files are always loaded (unlike skills, which use progressive disclosure)
* Pass one or more file paths to the `memory` parameter when creating your agent
* Files are stored in the agent's backend (StateBackend, StoreBackend, or FilesystemBackend)
* The agent can update memory based on your interactions, feedback, and identified patterns

**Why it's useful:**

* Provides persistent context that doesn't need to be re-specified each conversation
* Useful for storing user preferences, project guidelines, or domain knowledge
* Always available to the agent, ensuring consistent behavior

For configuration details and examples, see [Memory](/oss/javascript/deepagents/customization#memory).

***

<Callout icon="edit">
  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/deepagents/harness.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>

<Callout icon="terminal-2">
  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Callout>