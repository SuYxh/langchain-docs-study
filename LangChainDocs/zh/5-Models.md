> ## æ–‡æ¡£ç´¢å¼•
> è·å–å®Œæ•´æ–‡æ¡£ç´¢å¼•è¯·è®¿é—®ï¼šhttps://docs.langchain.com/llms.txt
> åœ¨æ·±å…¥æ¢ç´¢ä¹‹å‰ï¼Œè¯·ä½¿ç”¨æ­¤æ–‡ä»¶å‘ç°æ‰€æœ‰å¯ç”¨é¡µé¢ã€‚

# Models (æ¨¡å‹)

[LLMs](https://en.wikipedia.org/wiki/Large_language_model) æ˜¯å¼ºå¤§çš„äººå·¥æ™ºèƒ½å·¥å…·ï¼Œå¯ä»¥åƒäººç±»ä¸€æ ·è§£é‡Šå’Œç”Ÿæˆæ–‡æœ¬ã€‚å®ƒä»¬éå¸¸é€šç”¨ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œä¸“é—¨è®­ç»ƒï¼Œå°±èƒ½ç¼–å†™å†…å®¹ã€ç¿»è¯‘è¯­è¨€ã€æ€»ç»“å’Œå›ç­”é—®é¢˜ã€‚

é™¤äº†æ–‡æœ¬ç”Ÿæˆï¼Œè®¸å¤šæ¨¡å‹è¿˜æ”¯æŒï¼š

* <Icon icon="hammer" size={16} /> [å·¥å…·è°ƒç”¨ (Tool calling)](#tool-calling) - è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼ˆå¦‚æ•°æ®åº“æŸ¥è¯¢æˆ– API è°ƒç”¨ï¼‰å¹¶åœ¨å“åº”ä¸­ä½¿ç”¨ç»“æœã€‚
* <Icon icon="shapes" size={16} /> [ç»“æ„åŒ–è¾“å‡º (Structured output)](#structured-output) - æ¨¡å‹çš„å“åº”è¢«é™åˆ¶ä¸ºéµå¾ªå®šä¹‰çš„æ ¼å¼ã€‚
* <Icon icon="image" size={16} /> [å¤šæ¨¡æ€ (Multimodality)](#multimodal) - å¤„ç†å’Œè¿”å›é™¤æ–‡æœ¬ä»¥å¤–çš„æ•°æ®ï¼Œå¦‚å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ã€‚
* <Icon icon="brain" size={16} /> [æ¨ç† (Reasoning)](#reasoning) - æ¨¡å‹æ‰§è¡Œå¤šæ­¥æ¨ç†ä»¥å¾—å‡ºç»“è®ºã€‚

æ¨¡å‹æ˜¯ [Agent](/oss/javascript/langchain/agents) çš„æ¨ç†å¼•æ“ã€‚å®ƒä»¬é©±åŠ¨ Agent çš„å†³ç­–è¿‡ç¨‹ï¼Œå†³å®šè°ƒç”¨å“ªäº›å·¥å…·ã€å¦‚ä½•è§£é‡Šç»“æœä»¥åŠä½•æ—¶æä¾›æœ€ç»ˆç­”æ¡ˆã€‚

æ‚¨é€‰æ‹©çš„æ¨¡å‹çš„è´¨é‡å’Œèƒ½åŠ›ç›´æ¥å½±å“ Agent çš„åŸºçº¿å¯é æ€§å’Œæ€§èƒ½ã€‚ä¸åŒçš„æ¨¡å‹æ“…é•¿ä¸åŒçš„ä»»åŠ¡â€”â€”æœ‰äº›æ›´æ“…é•¿éµå¾ªå¤æ‚çš„æŒ‡ä»¤ï¼Œæœ‰äº›æ“…é•¿ç»“æ„åŒ–æ¨ç†ï¼Œæœ‰äº›æ”¯æŒæ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£ä»¥å¤„ç†æ›´å¤šä¿¡æ¯ã€‚

LangChain çš„æ ‡å‡†æ¨¡å‹æ¥å£è®©æ‚¨å¯ä»¥è®¿é—®è®¸å¤šä¸åŒçš„æä¾›å•†é›†æˆï¼Œè¿™ä½¿å¾—å°è¯•å’Œåˆ‡æ¢æ¨¡å‹ä»¥æ‰¾åˆ°æœ€é€‚åˆæ‚¨ç”¨ä¾‹çš„æ¨¡å‹å˜å¾—å®¹æ˜“ã€‚

<Info>
  æœ‰å…³ç‰¹å®šäºæä¾›å•†çš„é›†æˆä¿¡æ¯å’ŒåŠŸèƒ½ï¼Œè¯·å‚é˜…æä¾›å•†çš„ [èŠå¤©æ¨¡å‹é¡µé¢](/oss/javascript/integrations/chat)ã€‚
</Info>

## åŸºæœ¬ç”¨æ³•

æ¨¡å‹å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼ä½¿ç”¨ï¼š

1. **ä¸ Agent ä¸€èµ·ä½¿ç”¨** - åœ¨åˆ›å»º [Agent](/oss/javascript/langchain/agents#model) æ—¶å¯ä»¥åŠ¨æ€æŒ‡å®šæ¨¡å‹ã€‚
2. **ç‹¬ç«‹ä½¿ç”¨** - æ¨¡å‹å¯ä»¥ç›´æ¥è°ƒç”¨ï¼ˆåœ¨ Agent å¾ªç¯ä¹‹å¤–ï¼‰ç”¨äºæ–‡æœ¬ç”Ÿæˆã€åˆ†ç±»æˆ–æå–ç­‰ä»»åŠ¡ï¼Œè€Œæ— éœ€ Agent æ¡†æ¶ã€‚

ç›¸åŒçš„æ¨¡å‹æ¥å£åœ¨è¿™ä¸¤ç§ä¸Šä¸‹æ–‡ä¸­éƒ½é€‚ç”¨ï¼Œè¿™ä¸ºæ‚¨æä¾›äº†çµæ´»æ€§ï¼Œå¯ä»¥ä»ç®€å•å¼€å§‹ï¼Œæ ¹æ®éœ€è¦æ‰©å±•åˆ°æ›´å¤æ‚çš„åŸºäº Agent çš„å·¥ä½œæµã€‚

### åˆå§‹åŒ–æ¨¡å‹

åœ¨ LangChain ä¸­å¼€å§‹ä½¿ç”¨ç‹¬ç«‹æ¨¡å‹çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ `initChatModel` ä»æ‚¨é€‰æ‹©çš„ [èŠå¤©æ¨¡å‹æä¾›å•†](/oss/javascript/integrations/chat) åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ï¼ˆç¤ºä¾‹å¦‚ä¸‹ï¼‰ï¼š

<Tabs>
  <Tab title="OpenAI">
    ğŸ‘‰ é˜…è¯» [OpenAI èŠå¤©æ¨¡å‹é›†æˆæ–‡æ¡£](/oss/javascript/integrations/chat/openai/)

    <CodeGroup>
      ```bash npm theme={null}
      npm install @langchain/openai
      ```

      ```bash pnpm theme={null}
      pnpm install @langchain/openai
      ```

      ```bash yarn theme={null}
      yarn add @langchain/openai
      ```

      ```bash bun theme={null}
      bun add @langchain/openai
      ```
    </CodeGroup>

    <CodeGroup>
      ```typescript initChatModel theme={null}
      import { initChatModel } from "langchain";

      process.env.OPENAI_API_KEY = "your-api-key";

      const model = await initChatModel("gpt-4.1");
      ```

      ```typescript Model Class theme={null}
      import { ChatOpenAI } from "@langchain/openai";

      const model = new ChatOpenAI({
        model: "gpt-4.1",
        apiKey: "your-api-key"
      });
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Anthropic">
    ğŸ‘‰ é˜…è¯» [Anthropic èŠå¤©æ¨¡å‹é›†æˆæ–‡æ¡£](/oss/javascript/integrations/chat/anthropic/)

    <CodeGroup>
      ```bash npm theme={null}
      npm install @langchain/anthropic
      ```

      ```bash pnpm theme={null}
      pnpm install @langchain/anthropic
      ```

      ```bash yarn theme={null}
      yarn add @langchain/anthropic
      ```

      ```bash pnpm theme={null}
      pnpm add @langchain/anthropic
      ```
    </CodeGroup>

    <CodeGroup>
      ```typescript initChatModel theme={null}
      import { initChatModel } from "langchain";

      process.env.ANTHROPIC_API_KEY = "your-api-key";

      const model = await initChatModel("claude-sonnet-4-5-20250929");
      ```

      ```typescript Model Class theme={null}
      import { ChatAnthropic } from "@langchain/anthropic";

      const model = new ChatAnthropic({
        model: "claude-sonnet-4-5-20250929",
        apiKey: "your-api-key"
      });
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Azure">
    ğŸ‘‰ é˜…è¯» [Azure èŠå¤©æ¨¡å‹é›†æˆæ–‡æ¡£](/oss/javascript/integrations/chat/azure/)

    <CodeGroup>
      ```bash npm theme={null}
      npm install @langchain/azure
      ```

      ```bash pnpm theme={null}
      pnpm install @langchain/azure
      ```

      ```bash yarn theme={null}
      yarn add @langchain/azure
      ```

      ```bash bun theme={null}
      bun add @langchain/azure
      ```
    </CodeGroup>

    <CodeGroup>
      ```typescript initChatModel theme={null}
      import { initChatModel } from "langchain";

      process.env.AZURE_OPENAI_API_KEY = "your-api-key";
      process.env.AZURE_OPENAI_ENDPOINT = "your-endpoint";
      process.env.OPENAI_API_VERSION = "your-api-version";

      const model = await initChatModel("azure_openai:gpt-4.1");
      ```

      ```typescript Model Class theme={null}
      import { AzureChatOpenAI } from "@langchain/openai";

      const model = new AzureChatOpenAI({
        model: "gpt-4.1",
        azureOpenAIApiKey: "your-api-key",
        azureOpenAIApiEndpoint: "your-endpoint",
        azureOpenAIApiVersion: "your-api-version"
      });
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Google Gemini">
    ğŸ‘‰ é˜…è¯» [Google GenAI èŠå¤©æ¨¡å‹é›†æˆæ–‡æ¡£](/oss/javascript/integrations/chat/google_generative_ai/)

    <CodeGroup>
      ```bash npm theme={null}
      npm install @langchain/google-genai
      ```

      ```bash pnpm theme={null}
      pnpm install @langchain/google-genai
      ```

      ```bash yarn theme={null}
      yarn add @langchain/google-genai
      ```

      ```bash bun theme={null}
      bun add @langchain/google-genai
      ```
    </CodeGroup>

    <CodeGroup>
      ```typescript initChatModel theme={null}
      import { initChatModel } from "langchain";

      process.env.GOOGLE_API_KEY = "your-api-key";

      const model = await initChatModel("google-genai:gemini-2.5-flash-lite");
      ```

      ```typescript Model Class theme={null}
      import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

      const model = new ChatGoogleGenerativeAI({
        model: "gemini-2.5-flash-lite",
        apiKey: "your-api-key"
      });
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Bedrock Converse">
    ğŸ‘‰ é˜…è¯» [AWS Bedrock èŠå¤©æ¨¡å‹é›†æˆæ–‡æ¡£](/oss/javascript/integrations/chat/bedrock_converse/)

    <CodeGroup>
      ```bash npm theme={null}
      npm install @langchain/aws
      ```

      ```bash pnpm theme={null}
      pnpm install @langchain/aws
      ```

      ```bash yarn theme={null}
      yarn add @langchain/aws
      ```

      ```bash bun theme={null}
      bun add @langchain/aws
      ```
    </CodeGroup>

    <CodeGroup>
      ```typescript initChatModel theme={null}
      import { initChatModel } from "langchain";

      // Follow the steps here to configure your credentials:
      // æŒ‰ç…§æ­¤å¤„çš„æ­¥éª¤é…ç½®æ‚¨çš„å‡­æ®ï¼š
      // https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html

      const model = await initChatModel("bedrock:gpt-4.1");
      ```

      ```typescript Model Class theme={null}
      import { ChatBedrockConverse } from "@langchain/aws";

      // Follow the steps here to configure your credentials:
      // æŒ‰ç…§æ­¤å¤„çš„æ­¥éª¤é…ç½®æ‚¨çš„å‡­æ®ï¼š
      // https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html

      const model = new ChatBedrockConverse({
        model: "gpt-4.1",
        region: "us-east-2"
      });
      ```
    </CodeGroup>
  </Tab>
</Tabs>

```typescript  theme={null}
const response = await model.invoke("Why do parrots talk?");
```

æŸ¥çœ‹ [`initChatModel`](https://reference.langchain.com/javascript/functions/langchain.chat_models_universal.initChatModel.html) äº†è§£æ›´å¤šç»†èŠ‚ï¼ŒåŒ…æ‹¬å¦‚ä½•ä¼ é€’æ¨¡å‹ [å‚æ•°](#parameters) çš„ä¿¡æ¯ã€‚

### æ”¯æŒçš„æ¨¡å‹

LangChain æ”¯æŒæ‰€æœ‰ä¸»è¦æ¨¡å‹æä¾›å•†ï¼ŒåŒ…æ‹¬ OpenAIã€Anthropicã€Googleã€Azureã€AWS Bedrock ç­‰ã€‚æ¯ä¸ªæä¾›å•†éƒ½æä¾›å„ç§å…·æœ‰ä¸åŒåŠŸèƒ½çš„æ¨¡å‹ã€‚æœ‰å…³ LangChain ä¸­æ”¯æŒçš„æ¨¡å‹çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚é˜… [é›†æˆé¡µé¢](/oss/javascript/integrations/providers/overview)ã€‚

### å…³é”®æ–¹æ³•

<Card title="Invoke (è°ƒç”¨)" href="#invoke" icon="paper-plane" arrow="true" horizontal>
  æ¨¡å‹æ¥æ”¶æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶åœ¨ç”Ÿæˆå®Œæ•´å“åº”åè¾“å‡ºæ¶ˆæ¯ã€‚
</Card>

<Card title="Stream (æµå¼ä¼ è¾“)" href="#stream" icon="tower-broadcast" arrow="true" horizontal>
  è°ƒç”¨æ¨¡å‹ï¼Œä½†åœ¨è¾“å‡ºå®æ—¶ç”Ÿæˆæ—¶æµå¼ä¼ è¾“è¾“å‡ºã€‚
</Card>

<Card title="Batch (æ‰¹å¤„ç†)" href="#batch" icon="grip" arrow="true" horizontal>
  æ‰¹é‡å‘æ¨¡å‹å‘é€å¤šä¸ªè¯·æ±‚ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„å¤„ç†ã€‚
</Card>

<Info>
  é™¤äº†èŠå¤©æ¨¡å‹ï¼ŒLangChain è¿˜æä¾›å¯¹å…¶ä»–ç›¸é‚»æŠ€æœ¯çš„æ”¯æŒï¼Œå¦‚åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨ã€‚è¯¦æƒ…è¯·å‚é˜… [é›†æˆé¡µé¢](/oss/javascript/integrations/providers/overview)ã€‚
</Info>

## å‚æ•° (Parameters)

èŠå¤©æ¨¡å‹æ¥å—å¯ç”¨äºé…ç½®å…¶è¡Œä¸ºçš„å‚æ•°ã€‚æ”¯æŒçš„å®Œæ•´å‚æ•°é›†å› æ¨¡å‹å’Œæä¾›å•†è€Œå¼‚ï¼Œä½†æ ‡å‡†å‚æ•°åŒ…æ‹¬ï¼š

<ParamField body="model" type="string" required>
  æ‚¨æƒ³ä¸æä¾›å•†ä¸€èµ·ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹çš„åç§°æˆ–æ ‡è¯†ç¬¦ã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ '{model_provider}:{model}' æ ¼å¼åœ¨å•ä¸ªå‚æ•°ä¸­æŒ‡å®šæ¨¡å‹åŠå…¶æä¾›å•†ï¼Œä¾‹å¦‚ 'openai:o1'ã€‚
</ParamField>

<ParamField body="apiKey" type="string">
  ä¸æ¨¡å‹æä¾›å•†è¿›è¡Œèº«ä»½éªŒè¯æ‰€éœ€çš„å¯†é’¥ã€‚è¿™é€šå¸¸åœ¨æ‚¨æ³¨å†Œè®¿é—®æ¨¡å‹æ—¶é¢å‘ã€‚é€šå¸¸é€šè¿‡è®¾ç½® <Tooltip tip="å…¶å€¼åœ¨ç¨‹åºå¤–éƒ¨è®¾ç½®çš„å˜é‡ï¼Œé€šå¸¸é€šè¿‡æ“ä½œç³»ç»Ÿæˆ–å¾®æœåŠ¡å†…ç½®çš„åŠŸèƒ½ã€‚">ç¯å¢ƒå˜é‡</Tooltip> æ¥è®¿é—®ã€‚
</ParamField>

<ParamField body="temperature" type="number">
  æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ã€‚è¾ƒé«˜çš„æ•°å­—ä½¿å“åº”æ›´å…·åˆ›é€ æ€§ï¼›è¾ƒä½çš„æ•°å­—ä½¿å®ƒä»¬æ›´å…·ç¡®å®šæ€§ã€‚
</ParamField>

<ParamField body="maxTokens" type="number">
  é™åˆ¶å“åº”ä¸­çš„ <Tooltip tip="æ¨¡å‹è¯»å–å’Œç”Ÿæˆçš„åŸºæœ¬å•ä½ã€‚æä¾›å•†å¯èƒ½æœ‰ä¸åŒçš„å®šä¹‰ï¼Œä½†ä¸€èˆ¬æ¥è¯´ï¼Œå®ƒä»¬å¯ä»¥ä»£è¡¨æ•´ä¸ªæˆ–éƒ¨åˆ†å•è¯ã€‚">token</Tooltip> æ€»æ•°ï¼Œæœ‰æ•ˆæ§åˆ¶è¾“å‡ºçš„é•¿åº¦ã€‚
</ParamField>

<ParamField body="timeout" type="number">
  åœ¨å–æ¶ˆè¯·æ±‚ä¹‹å‰ç­‰å¾…æ¨¡å‹å“åº”çš„æœ€é•¿æ—¶é—´ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰ã€‚
</ParamField>

<ParamField body="maxRetries" type="number">
  å¦‚æœè¯·æ±‚ç”±äºç½‘ç»œè¶…æ—¶æˆ–é€Ÿç‡é™åˆ¶ç­‰é—®é¢˜è€Œå¤±è´¥ï¼Œç³»ç»Ÿå°è¯•é‡æ–°å‘é€è¯·æ±‚çš„æœ€å¤§æ¬¡æ•°ã€‚
</ParamField>

ä½¿ç”¨ `initChatModel` æ—¶ï¼Œå°†è¿™äº›å‚æ•°ä½œä¸ºå†…è”å‚æ•°ä¼ é€’ï¼š

```typescript Initialize using model parameters theme={null}
const model = await initChatModel(
    "claude-sonnet-4-5-20250929",
    { temperature: 0.7, timeout: 30, max_tokens: 1000 }
)
```

<Info>
  æ¯ä¸ªèŠå¤©æ¨¡å‹é›†æˆå¯èƒ½å…·æœ‰ç”¨äºæ§åˆ¶æä¾›å•†ç‰¹å®šåŠŸèƒ½çš„å…¶ä»–å‚æ•°ã€‚

  ä¾‹å¦‚ï¼Œ[`ChatOpenAI`](https://reference.langchain.com/javascript/classes/_langchain_openai.ChatOpenAI.html) å…·æœ‰ `use_responses_api` æ¥æŒ‡ç¤ºæ˜¯å¦ä½¿ç”¨ OpenAI Responses æˆ– Completions APIã€‚

  è¦æŸ¥æ‰¾ç»™å®šèŠå¤©æ¨¡å‹æ”¯æŒçš„æ‰€æœ‰å‚æ•°ï¼Œè¯·å‰å¾€ [èŠå¤©æ¨¡å‹é›†æˆ](/oss/javascript/integrations/chat) é¡µé¢ã€‚
</Info>

***

## è°ƒç”¨ (Invocation)

å¿…é¡»è°ƒç”¨èŠå¤©æ¨¡å‹æ‰èƒ½ç”Ÿæˆè¾“å‡ºã€‚ä¸»è¦æœ‰ä¸‰ç§è°ƒç”¨æ–¹æ³•ï¼Œæ¯ç§æ–¹æ³•é€‚ç”¨äºä¸åŒçš„ç”¨ä¾‹ã€‚

### Invoke (è°ƒç”¨)

è°ƒç”¨æ¨¡å‹æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯ä½¿ç”¨ [`invoke()`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#invoke) ä¼ é€’ä¸€æ¡æ¶ˆæ¯æˆ–æ¶ˆæ¯åˆ—è¡¨ã€‚

```typescript Single message theme={null}
const response = await model.invoke("Why do parrots have colorful feathers?");
console.log(response);
```

å¯ä»¥å‘èŠå¤©æ¨¡å‹æä¾›æ¶ˆæ¯åˆ—è¡¨ä»¥è¡¨ç¤ºå¯¹è¯å†å²è®°å½•ã€‚æ¯æ¡æ¶ˆæ¯éƒ½æœ‰ä¸€ä¸ªè§’è‰²ï¼Œæ¨¡å‹ä½¿ç”¨è¯¥è§’è‰²æ¥æŒ‡ç¤ºè°åœ¨å¯¹è¯ä¸­å‘é€äº†æ¶ˆæ¯ã€‚

æœ‰å…³è§’è‰²ã€ç±»å‹å’Œå†…å®¹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [æ¶ˆæ¯](/oss/javascript/langchain/messages) æŒ‡å—ã€‚

```typescript Object format theme={null}
const conversation = [
  { role: "system", content: "You are a helpful assistant that translates English to French." }, // ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè´Ÿè´£å°†è‹±è¯­ç¿»è¯‘æˆæ³•è¯­ã€‚
  { role: "user", content: "Translate: I love programming." }, // ç¿»è¯‘ï¼šæˆ‘çˆ±ç¼–ç¨‹ã€‚
  { role: "assistant", content: "J'adore la programmation." },
  { role: "user", content: "Translate: I love building applications." }, // ç¿»è¯‘ï¼šæˆ‘çˆ±æ„å»ºåº”ç”¨ç¨‹åºã€‚
];

const response = await model.invoke(conversation);
console.log(response);  // AIMessage("J'adore crÃ©er des applications.")
```

```typescript Message objects theme={null}
import { HumanMessage, AIMessage, SystemMessage } from "langchain";

const conversation = [
  new SystemMessage("You are a helpful assistant that translates English to French."), // ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè´Ÿè´£å°†è‹±è¯­ç¿»è¯‘æˆæ³•è¯­ã€‚
  new HumanMessage("Translate: I love programming."), // ç¿»è¯‘ï¼šæˆ‘çˆ±ç¼–ç¨‹ã€‚
  new AIMessage("J'adore la programmation."),
  new HumanMessage("Translate: I love building applications."), // ç¿»è¯‘ï¼šæˆ‘çˆ±æ„å»ºåº”ç”¨ç¨‹åºã€‚
];

const response = await model.invoke(conversation);
console.log(response);  // AIMessage("J'adore crÃ©er des applications.")
```

<Info>
  å¦‚æœè°ƒç”¨çš„è¿”å›ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œè¯·ç¡®ä¿æ‚¨ä½¿ç”¨çš„æ˜¯èŠå¤©æ¨¡å‹è€Œä¸æ˜¯ LLMã€‚ä¼ ç»Ÿçš„æ–‡æœ¬è¡¥å…¨ LLM ç›´æ¥è¿”å›å­—ç¬¦ä¸²ã€‚LangChain èŠå¤©æ¨¡å‹ä»¥ "Chat" ä¸ºå‰ç¼€ï¼Œä¾‹å¦‚ [`ChatOpenAI`](https://reference.langchain.com/javascript/classes/_langchain_openai.ChatOpenAI.html)(/oss/integrations/chat/openai)ã€‚
</Info>

### Stream (æµå¼ä¼ è¾“)

å¤§å¤šæ•°æ¨¡å‹å¯ä»¥åœ¨ç”Ÿæˆè¾“å‡ºå†…å®¹çš„åŒæ—¶æµå¼ä¼ è¾“å®ƒä»¬ã€‚é€šè¿‡é€æ­¥æ˜¾ç¤ºè¾“å‡ºï¼Œæµå¼ä¼ è¾“æ˜¾è‘—æ”¹å–„äº†ç”¨æˆ·ä½“éªŒï¼Œç‰¹åˆ«æ˜¯å¯¹äºè¾ƒé•¿çš„å“åº”ã€‚

è°ƒç”¨ [`stream()`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#stream) è¿”å›ä¸€ä¸ª <Tooltip tip="ä¸€ä¸ªæŒ‰é¡ºåºé€æ­¥æä¾›é›†åˆä¸­æ¯ä¸ªé¡¹ç›®çš„å¯¹è±¡ã€‚">è¿­ä»£å™¨</Tooltip>ï¼Œéšç€è¾“å‡ºå—çš„äº§ç”Ÿè€Œç”Ÿæˆå®ƒä»¬ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å¾ªç¯å®æ—¶å¤„ç†æ¯ä¸ªå—ï¼š

<CodeGroup>
  ```typescript Basic text streaming theme={null}
  const stream = await model.stream("Why do parrots have colorful feathers?");
  for await (const chunk of stream) {
    console.log(chunk.text)
  }
  ```

  ```typescript Stream tool calls, reasoning, and other content theme={null}
  const stream = await model.stream("What color is the sky?");
  for await (const chunk of stream) {
    for (const block of chunk.contentBlocks) {
      if (block.type === "reasoning") {
        console.log(`Reasoning: ${block.reasoning}`);
      } else if (block.type === "tool_call_chunk") {
        console.log(`Tool call chunk: ${block}`);
      } else if (block.type === "text") {
        console.log(block.text);
      } else {
        ...
      }
    }
  }
  ```
</CodeGroup>

ä¸ [`invoke()`](#invoke)ï¼ˆåœ¨æ¨¡å‹å®Œæˆç”Ÿæˆå®Œæ•´å“åº”åè¿”å›å•ä¸ª [`AIMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessage.html)ï¼‰ç›¸åï¼Œ`stream()` è¿”å›å¤šä¸ª [`AIMessageChunk`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessageChunk.html) å¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«è¾“å‡ºæ–‡æœ¬çš„ä¸€éƒ¨åˆ†ã€‚é‡è¦çš„æ˜¯ï¼Œæµä¸­çš„æ¯ä¸ªå—éƒ½è¢«è®¾è®¡ä¸ºå¯ä»¥é€šè¿‡æ±‚å’Œèšåˆæˆå®Œæ•´çš„æ¶ˆæ¯ï¼š

```typescript Construct AIMessage theme={null}
let full: AIMessageChunk | null = null;
for await (const chunk of stream) {
  full = full ? full.concat(chunk) : chunk;
  console.log(full.text);
}

// The
// The sky
// The sky is
// The sky is typically
// The sky is typically blue
// ...

console.log(full.contentBlocks);
// [{"type": "text", "text": "The sky is typically blue..."}]
```

ç»“æœæ¶ˆæ¯å¯ä»¥åƒä½¿ç”¨ [`invoke()`](#invoke) ç”Ÿæˆçš„æ¶ˆæ¯ä¸€æ ·å¤„ç†â€”â€”ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥èšåˆåˆ°æ¶ˆæ¯å†å²è®°å½•ä¸­å¹¶ä½œä¸ºå¯¹è¯ä¸Šä¸‹æ–‡ä¼ å›æ¨¡å‹ã€‚

<Warning>
  æµå¼ä¼ è¾“ä»…åœ¨ç¨‹åºä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½çŸ¥é“å¦‚ä½•å¤„ç†å—æµæ—¶æ‰æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œä¸æ”¯æŒæµå¼ä¼ è¾“çš„åº”ç”¨ç¨‹åºå¯èƒ½éœ€è¦åœ¨å¤„ç†ä¹‹å‰å°†æ•´ä¸ªè¾“å‡ºå­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚
</Warning>

<Accordion title="é«˜çº§æµå¼ä¼ è¾“ä¸»é¢˜">
  <Accordion title="æµå¼ä¼ è¾“äº‹ä»¶">
    LangChain èŠå¤©æ¨¡å‹è¿˜å¯ä»¥ä½¿ç”¨ \[`streamEvents()`]\[BaseChatModel.streamEvents] æµå¼ä¼ è¾“è¯­ä¹‰äº‹ä»¶ã€‚

    è¿™ç®€åŒ–äº†åŸºäºäº‹ä»¶ç±»å‹å’Œå…¶ä»–å…ƒæ•°æ®çš„è¿‡æ»¤ï¼Œå¹¶å°†åœ¨åå°èšåˆå®Œæ•´æ¶ˆæ¯ã€‚è§ä¸‹æ–‡ç¤ºä¾‹ã€‚

    ```typescript  theme={null}
    const stream = await model.streamEvents("Hello");
    for await (const event of stream) {
        if (event.event === "on_chat_model_start") {
            console.log(`Input: ${event.data.input}`);
        }
        if (event.event === "on_chat_model_stream") {
            console.log(`Token: ${event.data.chunk.text}`);
        }
        if (event.event === "on_chat_model_end") {
            console.log(`Full message: ${event.data.output.text}`);
        }
    }
    ```

    ```txt  theme={null}
    Input: Hello
    Token: Hi
    Token:  there
    Token: !
    Token:  How
    Token:  can
    Token:  I
    ...
    Full message: Hi there! How can I help today?
    ```

    æœ‰å…³äº‹ä»¶ç±»å‹å’Œå…¶ä»–è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [`streamEvents()`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#streamEvents) å‚è€ƒã€‚
  </Accordion>

  <Accordion title="&#x22;è‡ªåŠ¨æµå¼ä¼ è¾“&#x22; èŠå¤©æ¨¡å‹">
    LangChain é€šè¿‡åœ¨æŸäº›æƒ…å†µä¸‹è‡ªåŠ¨å¯ç”¨æµå¼ä¼ è¾“æ¨¡å¼æ¥ç®€åŒ–èŠå¤©æ¨¡å‹çš„æµå¼ä¼ è¾“ï¼Œå³ä½¿æ‚¨æ²¡æœ‰æ˜¾å¼è°ƒç”¨æµå¼ä¼ è¾“æ–¹æ³•ã€‚å½“æ‚¨ä½¿ç”¨éæµå¼è°ƒç”¨æ–¹æ³•ä½†ä»æƒ³æµå¼ä¼ è¾“æ•´ä¸ªåº”ç”¨ç¨‹åºï¼ˆåŒ…æ‹¬æ¥è‡ªèŠå¤©æ¨¡å‹çš„ä¸­é—´ç»“æœï¼‰æ—¶ï¼Œè¿™ç‰¹åˆ«æœ‰ç”¨ã€‚

    ä¾‹å¦‚ï¼Œåœ¨ [LangGraph agents](/oss/javascript/langchain/agents) ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨èŠ‚ç‚¹å†…è°ƒç”¨ `model.invoke()`ï¼Œä½†å¦‚æœåœ¨æµå¼æ¨¡å¼ä¸‹è¿è¡Œï¼ŒLangChain å°†è‡ªåŠ¨å§”æ‰˜ç»™æµå¼ä¼ è¾“ã€‚

    #### å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„

    å½“æ‚¨ `invoke()` ä¸€ä¸ªèŠå¤©æ¨¡å‹æ—¶ï¼Œå¦‚æœ LangChain æ£€æµ‹åˆ°æ‚¨è¯•å›¾æµå¼ä¼ è¾“æ•´ä¸ªåº”ç”¨ç¨‹åºï¼Œå®ƒå°†è‡ªåŠ¨åˆ‡æ¢åˆ°å†…éƒ¨æµå¼ä¼ è¾“æ¨¡å¼ã€‚å°±ä½¿ç”¨ invoke çš„ä»£ç è€Œè¨€ï¼Œè°ƒç”¨çš„ç»“æœå°†æ˜¯ç›¸åŒçš„ï¼›ä½†æ˜¯ï¼Œåœ¨æµå¼ä¼ è¾“èŠå¤©æ¨¡å‹æ—¶ï¼ŒLangChain å°†è´Ÿè´£åœ¨ LangChain çš„å›è°ƒç³»ç»Ÿä¸­è°ƒç”¨ [`on_llm_new_token`](https://reference.langchain.com/javascript/interfaces/_langchain_core.callbacks_base.BaseCallbackHandlerMethods.html#onLlmNewToken) äº‹ä»¶ã€‚

    å›è°ƒäº‹ä»¶å…è®¸ LangGraph `stream()` å’Œ `streamEvents()` å®æ—¶å‘ˆç°èŠå¤©æ¨¡å‹çš„è¾“å‡ºã€‚
  </Accordion>
</Accordion>

### Batch (æ‰¹å¤„ç†)

å¯¹æ¨¡å‹çš„ä¸€ç»„ç‹¬ç«‹è¯·æ±‚è¿›è¡Œæ‰¹å¤„ç†å¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½å¹¶é™ä½æˆæœ¬ï¼Œå› ä¸ºå¤„ç†å¯ä»¥å¹¶è¡Œå®Œæˆï¼š

```typescript Batch theme={null}
const responses = await model.batch([
  "Why do parrots have colorful feathers?",
  "How do airplanes fly?",
  "What is quantum computing?",
  "Why do parrots have colorful feathers?",
  "How do airplanes fly?",
  "What is quantum computing?",
]);
for (const response of responses) {
  console.log(response);
}
```

<Tip>
  å½“ä½¿ç”¨ `batch()` å¤„ç†å¤§é‡è¾“å…¥æ—¶ï¼Œæ‚¨å¯èƒ½å¸Œæœ›æ§åˆ¶æœ€å¤§å¹¶è¡Œè°ƒç”¨æ•°ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨ [`RunnableConfig`](https://reference.langchain.com/javascript/interfaces/_langchain_core.runnables.RunnableConfig.html) å­—å…¸ä¸­è®¾ç½® `maxConcurrency` å±æ€§æ¥å®Œæˆã€‚

  ```typescript Batch with max concurrency theme={null}
  model.batch(
    listOfInputs,
    {
      maxConcurrency: 5,  // é™åˆ¶ä¸º 5 ä¸ªå¹¶è¡Œè°ƒç”¨
    }
  )
  ```

  æœ‰å…³æ”¯æŒå±æ€§çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚é˜… [`RunnableConfig`](https://reference.langchain.com/javascript/interfaces/_langchain_core.runnables.RunnableConfig.html) å‚è€ƒã€‚
</Tip>

æœ‰å…³æ‰¹å¤„ç†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [å‚è€ƒ](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#batch)ã€‚

***

## å·¥å…·è°ƒç”¨ (Tool calling)

æ¨¡å‹å¯ä»¥è¯·æ±‚è°ƒç”¨æ‰§è¡Œè¯¸å¦‚ä»æ•°æ®åº“è·å–æ•°æ®ã€æœç´¢ç½‘ç»œæˆ–è¿è¡Œä»£ç ç­‰ä»»åŠ¡çš„å·¥å…·ã€‚å·¥å…·æ˜¯ä»¥ä¸‹çš„é…å¯¹ï¼š

1. ä¸€ä¸ªæ¶æ„ï¼ŒåŒ…æ‹¬å·¥å…·çš„åç§°ã€æè¿°å’Œ/æˆ–å‚æ•°å®šä¹‰ï¼ˆé€šå¸¸æ˜¯ JSON schemaï¼‰
2. ä¸€ä¸ªè¦æ‰§è¡Œçš„å‡½æ•°æˆ– <Tooltip tip="ä¸€ç§å¯ä»¥æŒ‚èµ·æ‰§è¡Œå¹¶åœ¨ç¨åæ¢å¤çš„æ–¹æ³•">åç¨‹</Tooltip>ã€‚

<Note>
  æ‚¨å¯èƒ½ä¼šå¬åˆ°æœ¯è¯­ "function calling"ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰ã€‚æˆ‘ä»¬å°†å…¶ä¸ "tool calling"ï¼ˆå·¥å…·è°ƒç”¨ï¼‰äº’æ¢ä½¿ç”¨ã€‚
</Note>

è¿™æ˜¯ç”¨æˆ·ä¸æ¨¡å‹ä¹‹é—´çš„åŸºæœ¬å·¥å…·è°ƒç”¨æµç¨‹ï¼š

```mermaid  theme={null}
sequenceDiagram
    participant U as User
    participant M as Model
    participant T as Tools

    U->>M: "What's the weather in SF and NYC?"
    M->>M: Analyze request & decide tools needed

    par Parallel Tool Calls
        M->>T: getWeather("San Francisco")
        M->>T: getWeather("New York")
    end

    par Tool Execution
        T-->>M: SF weather data
        T-->>M: NYC weather data
    end

    M->>M: Process results & generate response
    M->>U: "SF: 72Â°F sunny, NYC: 68Â°F cloudy"
```

è¦ä½¿æ‚¨å®šä¹‰çš„å·¥å…·å¯ä¾›æ¨¡å‹ä½¿ç”¨ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ [`bindTools`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#bindTools) ç»‘å®šå®ƒä»¬ã€‚åœ¨éšåçš„è°ƒç”¨ä¸­ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©è°ƒç”¨ä»»ä½•ç»‘å®šçš„å·¥å…·ã€‚

ä¸€äº›æ¨¡å‹æä¾›å•†æä¾› <Tooltip tip="åœ¨æœåŠ¡å™¨ç«¯æ‰§è¡Œçš„å·¥å…·ï¼Œä¾‹å¦‚ç½‘ç»œæœç´¢å’Œä»£ç è§£é‡Šå™¨">å†…ç½®å·¥å…·</Tooltip>ï¼Œå¯ä»¥é€šè¿‡æ¨¡å‹æˆ–è°ƒç”¨å‚æ•°å¯ç”¨ï¼ˆä¾‹å¦‚ [`ChatOpenAI`](/oss/javascript/integrations/chat/openai)ã€[`ChatAnthropic`](/oss/javascript/integrations/chat/anthropic)ï¼‰ã€‚æŸ¥çœ‹ç›¸åº”çš„ [æä¾›å•†å‚è€ƒ](/oss/javascript/integrations/providers/overview) äº†è§£è¯¦æƒ…ã€‚

<Tip>
  æœ‰å…³åˆ›å»ºå·¥å…·çš„è¯¦ç»†ä¿¡æ¯å’Œå…¶ä»–é€‰é¡¹ï¼Œè¯·å‚é˜… [å·¥å…·æŒ‡å—](/oss/javascript/langchain/tools)ã€‚
</Tip>

```typescript Binding user tools theme={null}
import { tool } from "langchain";
import * as z from "zod";
import { ChatOpenAI } from "@langchain/openai";

const getWeather = tool(
  (input) => `It's sunny in ${input.location}.`,
  {
    name: "get_weather",
    description: "Get the weather at a location.",
    schema: z.object({
      location: z.string().describe("The location to get the weather for"), // è·å–å¤©æ°”çš„åœ°ç‚¹
    }),
  },
);

const model = new ChatOpenAI({ model: "gpt-4.1" });
const modelWithTools = model.bindTools([getWeather]);  // [!code highlight]

const response = await modelWithTools.invoke("What's the weather like in Boston?");
const toolCalls = response.tool_calls || [];
for (const tool_call of toolCalls) {
  // æŸ¥çœ‹æ¨¡å‹è¿›è¡Œçš„å·¥å…·è°ƒç”¨
  console.log(`Tool: ${tool_call.name}`);
  console.log(`Args: ${tool_call.args}`);
}
```

ç»‘å®šç”¨æˆ·å®šä¹‰çš„å·¥å…·æ—¶ï¼Œæ¨¡å‹çš„å“åº”åŒ…å«æ‰§è¡Œå·¥å…·çš„ **è¯·æ±‚**ã€‚å½“ä¸ [Agent](/oss/javascript/langchain/agents) åˆ†å¼€ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œæ‚¨éœ€è¦è´Ÿè´£æ‰§è¡Œè¯·æ±‚çš„å·¥å…·å¹¶å°†ç»“æœè¿”å›ç»™æ¨¡å‹ä»¥ä¾›åç»­æ¨ç†ä½¿ç”¨ã€‚å½“ä½¿ç”¨ [Agent](/oss/javascript/langchain/agents) æ—¶ï¼ŒAgent å¾ªç¯å°†ä¸ºæ‚¨å¤„ç†å·¥å…·æ‰§è¡Œå¾ªç¯ã€‚

ä¸‹é¢ï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸€äº›ä½¿ç”¨å·¥å…·è°ƒç”¨çš„å¸¸è§æ–¹æ³•ã€‚

<AccordionGroup>
  <Accordion title="å·¥å…·æ‰§è¡Œå¾ªç¯" icon="arrow-rotate-right">
    å½“æ¨¡å‹è¿”å›å·¥å…·è°ƒç”¨æ—¶ï¼Œæ‚¨éœ€è¦æ‰§è¡Œå·¥å…·å¹¶å°†ç»“æœä¼ å›æ¨¡å‹ã€‚è¿™åˆ›å»ºäº†ä¸€ä¸ªå¯¹è¯å¾ªç¯ï¼Œæ¨¡å‹å¯ä»¥ä½¿ç”¨å·¥å…·ç»“æœç”Ÿæˆå…¶æœ€ç»ˆå“åº”ã€‚LangChain åŒ…å«ä¸ºæ‚¨å¤„ç†æ­¤ç¼–æ’çš„ [Agent](/oss/javascript/langchain/agents) æŠ½è±¡ã€‚

    è¿™æ˜¯ä¸€ä¸ªå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„ç®€å•ç¤ºä¾‹ï¼š

    ```typescript Tool execution loop theme={null}
    // å°†ï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
    const modelWithTools = model.bindTools([get_weather])

    // ç¬¬ä¸€æ­¥ï¼šæ¨¡å‹ç”Ÿæˆå·¥å…·è°ƒç”¨
    const messages = [{"role": "user", "content": "What's the weather in Boston?"}]
    const ai_msg = await modelWithTools.invoke(messages)
    messages.push(ai_msg)

    // ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
    for (const tool_call of ai_msg.tool_calls) {
        // ä½¿ç”¨ç”Ÿæˆçš„å‚æ•°æ‰§è¡Œå·¥å…·
        const tool_result = await get_weather.invoke(tool_call)
        messages.push(tool_result)
    }

    // ç¬¬ä¸‰æ­¥ï¼šå°†ç»“æœä¼ å›æ¨¡å‹ä»¥è·å¾—æœ€ç»ˆå“åº”
    const final_response = await modelWithTools.invoke(messages)
    console.log(final_response.text)
    // "The current weather in Boston is 72Â°F and sunny."
    ```

    å·¥å…·è¿”å›çš„æ¯ä¸ª [`ToolMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.ToolMessage.html) éƒ½åŒ…å«ä¸€ä¸ªä¸åŸå§‹å·¥å…·è°ƒç”¨åŒ¹é…çš„ `tool_call_id`ï¼Œå¸®åŠ©æ¨¡å‹å°†ç»“æœä¸è¯·æ±‚å…³è”èµ·æ¥ã€‚
  </Accordion>

  <Accordion title="å¼ºåˆ¶å·¥å…·è°ƒç”¨" icon="asterisk">
    é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹å¯ä»¥è‡ªç”±é€‰æ‹©åŸºäºç”¨æˆ·è¾“å…¥ä½¿ç”¨å“ªä¸ªç»‘å®šå·¥å…·ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å¼ºåˆ¶é€‰æ‹©ä¸€ä¸ªå·¥å…·ï¼Œç¡®ä¿æ¨¡å‹ä½¿ç”¨ç‰¹å®šå·¥å…·æˆ–ç»™å®šåˆ—è¡¨ä¸­çš„ **ä»»ä½•** å·¥å…·ï¼š

    <CodeGroup>
      ```typescript Force use of any tool theme={null}
      const modelWithTools = model.bindTools([tool_1], { toolChoice: "any" })
      ```

      ```typescript Force use of specific tools theme={null}
      const modelWithTools = model.bindTools([tool_1], { toolChoice: "tool_1" })
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="å¹¶è¡Œå·¥å…·è°ƒç”¨" icon="layer-group">
    è®¸å¤šæ¨¡å‹æ”¯æŒåœ¨é€‚å½“æ—¶å¹¶è¡Œè°ƒç”¨å¤šä¸ªå·¥å…·ã€‚è¿™å…è®¸æ¨¡å‹åŒæ—¶ä»ä¸åŒæ¥æºæ”¶é›†ä¿¡æ¯ã€‚

    ```typescript Parallel tool calls theme={null}
    const modelWithTools = model.bind_tools([get_weather])

    const response = await modelWithTools.invoke(
        "What's the weather in Boston and Tokyo?"
    )


    // æ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆå¤šä¸ªå·¥å…·è°ƒç”¨
    console.log(response.tool_calls)
    // [
    //   { name: 'get_weather', args: { location: 'Boston' }, id: 'call_1' },
    //   { name: 'get_time', args: { location: 'Tokyo' }, id: 'call_2' }
    // ]


    // æ‰§è¡Œæ‰€æœ‰å·¥å…·ï¼ˆå¯ä»¥ä½¿ç”¨ async å¹¶è¡Œå®Œæˆï¼‰
    const results = []
    for (const tool_call of response.tool_calls || []) {
        if (tool_call.name === 'get_weather') {
            const result = await get_weather.invoke(tool_call)
            results.push(result)
        }
    }
    ```

    æ¨¡å‹æ ¹æ®è¯·æ±‚æ“ä½œçš„ç‹¬ç«‹æ€§æ™ºèƒ½åœ°ç¡®å®šä½•æ—¶é€‚åˆå¹¶è¡Œæ‰§è¡Œã€‚

    <Tip>
      å¤§å¤šæ•°æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹é»˜è®¤å¯ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ã€‚æœ‰äº›ï¼ˆåŒ…æ‹¬ [OpenAI](/oss/javascript/integrations/chat/openai) å’Œ [Anthropic](/oss/javascript/integrations/chat/anthropic)ï¼‰å…è®¸æ‚¨ç¦ç”¨æ­¤åŠŸèƒ½ã€‚ä¸ºæ­¤ï¼Œè¯·è®¾ç½® `parallel_tool_calls=False`ï¼š

      ```python  theme={null}
      model.bind_tools([get_weather], parallel_tool_calls=False)
      ```
    </Tip>
  </Accordion>

  <Accordion title="æµå¼å·¥å…·è°ƒç”¨" icon="rss">
    å½“æµå¼ä¼ è¾“å“åº”æ—¶ï¼Œå·¥å…·è°ƒç”¨é€šè¿‡ [`ToolCallChunk`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.ToolCallChunk.html) é€æ­¥æ„å»ºã€‚è¿™å…è®¸æ‚¨åœ¨å·¥å…·è°ƒç”¨ç”Ÿæˆæ—¶çœ‹åˆ°å®ƒä»¬ï¼Œè€Œä¸æ˜¯ç­‰å¾…å®Œæ•´å“åº”ã€‚

    ```typescript Streaming tool calls theme={null}
    const stream = await modelWithTools.stream(
        "What's the weather in Boston and Tokyo?"
    )
    for await (const chunk of stream) {
        // å·¥å…·è°ƒç”¨å—é€æ­¥åˆ°è¾¾
        if (chunk.tool_call_chunks) {
            for (const tool_chunk of chunk.tool_call_chunks) {
            console.log(`Tool: ${tool_chunk.get('name', '')}`)
            console.log(`Args: ${tool_chunk.get('args', '')}`)
            }
        }
    }

    // Output:
    // Tool: get_weather
    // Args:
    // Tool:
    // Args: {"loc
    // Tool:
    // Args: ation": "BOS"}
    // Tool: get_time
    // Args:
    // Tool:
    // Args: {"timezone": "Tokyo"}
    ```

    æ‚¨å¯ä»¥ç´¯ç§¯å—ä»¥æ„å»ºå®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼š

    ```typescript Accumulate tool calls theme={null}
    let full: AIMessageChunk | null = null
    const stream = await modelWithTools.stream("What's the weather in Boston?")
    for await (const chunk of stream) {
        full = full ? full.concat(chunk) : chunk
        console.log(full.contentBlocks)
    }
    ```
  </Accordion>
</AccordionGroup>

***

## ç»“æ„åŒ–è¾“å‡º (Structured output)

å¯ä»¥è¯·æ±‚æ¨¡å‹æä¾›åŒ¹é…ç»™å®šæ¶æ„çš„æ ¼å¼çš„å“åº”ã€‚è¿™å¯¹äºç¡®ä¿è¾“å‡ºå¯ä»¥è½»æ¾è§£æå¹¶ç”¨äºåç»­å¤„ç†éå¸¸æœ‰ç”¨ã€‚LangChain æ”¯æŒå¤šç§æ¶æ„ç±»å‹å’Œå¼ºåˆ¶ç»“æ„åŒ–è¾“å‡ºçš„æ–¹æ³•ã€‚

<Tip>
  è¦äº†è§£å…³äºç»“æ„åŒ–è¾“å‡ºçš„ä¿¡æ¯ï¼Œè¯·å‚é˜… [ç»“æ„åŒ–è¾“å‡º](/oss/javascript/langchain/structured-output)ã€‚
</Tip>

<Tabs>
  <Tab title="Zod">
    [zod schema](https://zod.dev/) æ˜¯å®šä¹‰è¾“å‡ºæ¶æ„çš„é¦–é€‰æ–¹æ³•ã€‚è¯·æ³¨æ„ï¼Œå½“æä¾› zod schema æ—¶ï¼Œæ¨¡å‹è¾“å‡ºä¹Ÿå°†ä½¿ç”¨ zod çš„ parse æ–¹æ³•é’ˆå¯¹ schema è¿›è¡ŒéªŒè¯ã€‚

    ```typescript  theme={null}
    import * as z from "zod";

    const Movie = z.object({
      title: z.string().describe("The title of the movie"), // ç”µå½±æ ‡é¢˜
      year: z.number().describe("The year the movie was released"), // ç”µå½±ä¸Šæ˜ å¹´ä»½
      director: z.string().describe("The director of the movie"), // ç”µå½±å¯¼æ¼”
      rating: z.number().describe("The movie's rating out of 10"), // ç”µå½±è¯„åˆ†ï¼ˆæ»¡åˆ† 10 åˆ†ï¼‰
    });

    const modelWithStructure = model.withStructuredOutput(Movie);

    const response = await modelWithStructure.invoke("Provide details about the movie Inception");
    console.log(response);
    // {
    //   title: "Inception",
    //   year: 2010,
    //   director: "Christopher Nolan",
    //   rating: 8.8,
    // }
    ```
  </Tab>

  <Tab title="JSON Schema">
    ä¸ºäº†æœ€å¤§ç¨‹åº¦çš„æ§åˆ¶æˆ–äº’æ“ä½œæ€§ï¼Œæ‚¨å¯ä»¥æä¾›åŸå§‹ JSON Schemaã€‚

    ```typescript  theme={null}
    const jsonSchema = {
      "title": "Movie",
      "description": "A movie with details",
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "The title of the movie",
        },
        "year": {
          "type": "integer",
          "description": "The year the movie was released",
        },
        "director": {
          "type": "string",
          "description": "The director of the movie",
        },
        "rating": {
          "type": "number",
          "description": "The movie's rating out of 10",
        },
      },
      "required": ["title", "year", "director", "rating"],
    }

    const modelWithStructure = model.withStructuredOutput(
      jsonSchema,
      { method: "jsonSchema" },
    )

    const response = await modelWithStructure.invoke("Provide details about the movie Inception")
    console.log(response)  // {'title': 'Inception', 'year': 2010, ...}
    ```
  </Tab>
</Tabs>

<Note>
  **ç»“æ„åŒ–è¾“å‡ºçš„å…³é”®æ³¨æ„äº‹é¡¹ï¼š**

  * **æ–¹æ³•å‚æ•°**: ä¸€äº›æä¾›å•†æ”¯æŒä¸åŒçš„æ–¹æ³• (`'jsonSchema'`, `'functionCalling'`, `'jsonMode'`)
  * **Include raw**: ä½¿ç”¨ [`includeRaw: true`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#withStructuredOutput) è·å–è§£æåçš„è¾“å‡ºå’ŒåŸå§‹ [`AIMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessage.html)
  * **éªŒè¯**: Zod æ¨¡å‹æä¾›è‡ªåŠ¨éªŒè¯ï¼Œè€Œ JSON Schema éœ€è¦æ‰‹åŠ¨éªŒè¯

  è¯·å‚é˜…æ‚¨çš„ [æä¾›å•†é›†æˆé¡µé¢](/oss/javascript/integrations/providers/overview) äº†è§£æ”¯æŒçš„æ–¹æ³•å’Œé…ç½®é€‰é¡¹ã€‚
</Note>

<Accordion title="ç¤ºä¾‹ï¼šä¸è§£æç»“æ„ä¸€èµ·è¾“å‡ºæ¶ˆæ¯">
  å°†åŸå§‹ [`AIMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessage.html) å¯¹è±¡ä¸è§£æåçš„è¡¨ç¤ºå½¢å¼ä¸€èµ·è¿”å›é€šå¸¸å¾ˆæœ‰ç”¨ï¼Œä»¥ä¾¿è®¿é—®å“åº”å…ƒæ•°æ®ï¼Œå¦‚ [token è®¡æ•°](#token-usage)ã€‚ä¸ºæ­¤ï¼Œåœ¨è°ƒç”¨ [`with_structured_output`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#withStructuredOutput) æ—¶è®¾ç½® [`include_raw=True`](https://reference.langchain.com/javascript/classes/_langchain_core.language_models_chat_models.BaseChatModel.html#withStructuredOutput) ï¼š

  ```typescript  theme={null}
  import * as z from "zod";

  const Movie = z.object({
    title: z.string().describe("The title of the movie"),
    year: z.number().describe("The year the movie was released"),
    director: z.string().describe("The director of the movie"),
    rating: z.number().describe("The movie's rating out of 10"),
    title: z.string().describe("The title of the movie"),
    year: z.number().describe("The year the movie was released"),
    director: z.string().describe("The director of the movie"),  // [!code highlight]
    rating: z.number().describe("The movie's rating out of 10"),
  });

  const modelWithStructure = model.withStructuredOutput(Movie, { includeRaw: true });

  const response = await modelWithStructure.invoke("Provide details about the movie Inception");
  console.log(response);
  // {
  //   raw: AIMessage { ... },
  //   parsed: { title: "Inception", ... }
  // }
  ```
</Accordion>

<Accordion title="ç¤ºä¾‹ï¼šåµŒå¥—ç»“æ„">
  Schema å¯ä»¥åµŒå¥—ï¼š

  ```typescript  theme={null}
  import * as z from "zod";

  const Actor = z.object({
    name: str
    role: z.string(),
  });

  const MovieDetails = z.object({
    title: z.string(),
    year: z.number(),
    cast: z.array(Actor),
    genres: z.array(z.string()),
    budget: z.number().nullable().describe("Budget in millions USD"),
  });

  const modelWithStructure = model.withStructuredOutput(MovieDetails);
  ```
</Accordion>

***

## é«˜çº§ä¸»é¢˜

### æ¨¡å‹é…ç½®æ–‡ä»¶ (Model profiles)

<Info>
  æ¨¡å‹é…ç½®æ–‡ä»¶éœ€è¦ `langchain>=1.1`ã€‚
</Info>

LangChain èŠå¤©æ¨¡å‹å¯ä»¥é€šè¿‡ `.profile` å±æ€§å…¬å¼€æ”¯æŒçš„åŠŸèƒ½å’Œèƒ½åŠ›å­—å…¸ï¼š

```typescript  theme={null}
model.profile;
// {
//   maxInputTokens: 400000,
//   imageInputs: true,
//   reasoningOutput: true,
//   toolCalling: true,
//   ...
// }
```

è¯·å‚é˜… [API å‚è€ƒ](https://reference.langchain.com/javascript/interfaces/_langchain_core.language_models_profile.ModelProfile.html) ä¸­çš„å®Œæ•´å­—æ®µé›†ã€‚

å¤§éƒ¨åˆ†æ¨¡å‹é…ç½®æ–‡ä»¶æ•°æ®ç”± [models.dev](https://github.com/sst/models.dev) é¡¹ç›®æä¾›æ”¯æŒï¼Œè¿™æ˜¯ä¸€ä¸ªæä¾›æ¨¡å‹èƒ½åŠ›æ•°æ®çš„å¼€æºè®¡åˆ’ã€‚è¿™äº›æ•°æ®ä¸º LangChain ä½¿ç”¨ç›®çš„å¢åŠ äº†é¢å¤–çš„å­—æ®µã€‚éšç€ä¸Šæ¸¸é¡¹ç›®çš„å‘å±•ï¼Œè¿™äº›å¢å¼ºåŠŸèƒ½ä¿æŒä¸€è‡´ã€‚

æ¨¡å‹é…ç½®æ–‡ä»¶æ•°æ®å…è®¸åº”ç”¨ç¨‹åºåŠ¨æ€åœ°è§£å†³æ¨¡å‹èƒ½åŠ›é—®é¢˜ã€‚ä¾‹å¦‚ï¼š

1. [æ‘˜è¦ä¸­é—´ä»¶](/oss/javascript/langchain/middleware/built-in#summarization) å¯ä»¥æ ¹æ®æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°è§¦å‘æ‘˜è¦ã€‚
2. `createAgent` ä¸­çš„ [ç»“æ„åŒ–è¾“å‡º](/oss/javascript/langchain/structured-output) ç­–ç•¥å¯ä»¥è‡ªåŠ¨æ¨æ–­ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡æ£€æŸ¥æ˜¯å¦æ”¯æŒåŸç”Ÿç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ï¼‰ã€‚
3. æ¨¡å‹è¾“å…¥å¯ä»¥æ ¹æ®æ”¯æŒçš„ [æ¨¡æ€](#multimodal) å’Œæœ€å¤§è¾“å…¥ token è¿›è¡Œé—¨æ§ã€‚

<Accordion title="ä¿®æ”¹é…ç½®æ–‡ä»¶æ•°æ®">
  å¦‚æœæ¨¡å‹é…ç½®æ–‡ä»¶æ•°æ®ç¼ºå¤±ã€é™ˆæ—§æˆ–ä¸æ­£ç¡®ï¼Œå¯ä»¥æ›´æ”¹å®ƒã€‚

  **é€‰é¡¹ 1 (å¿«é€Ÿä¿®å¤)**

  æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶å®ä¾‹åŒ–èŠå¤©æ¨¡å‹ï¼š

  ```typescript  theme={null}
  const customProfile = {
  maxInputTokens: 100_000,
  toolCalling: true,
  structuredOutput: true,
  // ...
  };
  const model = initChatModel("...", { profile: customProfile });
  ```

  **é€‰é¡¹ 2 (ä¸Šæ¸¸ä¿®å¤æ•°æ®)**

  æ•°æ®çš„ä¸»è¦æ¥æºæ˜¯ [models.dev](https://models.dev/) é¡¹ç›®ã€‚è¿™äº›æ•°æ®ä¸ LangChain [é›†æˆåŒ…](/oss/javascript/integrations/providers/overview) ä¸­çš„å…¶ä»–å­—æ®µå’Œè¦†ç›–åˆå¹¶ï¼Œå¹¶éšè¿™äº›åŒ…ä¸€èµ·å‘å¸ƒã€‚

  æ¨¡å‹é…ç½®æ–‡ä»¶æ•°æ®å¯ä»¥é€šè¿‡ä»¥ä¸‹è¿‡ç¨‹æ›´æ–°ï¼š

  1. (å¦‚æœéœ€è¦) é€šè¿‡å‘å…¶ [GitHub ä¸Šçš„å­˜å‚¨åº“](https://github.com/sst/models.dev) æäº¤æ‹‰å–è¯·æ±‚æ¥æ›´æ–° [models.dev](https://models.dev/) ä¸Šçš„æºæ•°æ®ã€‚
  2. (å¦‚æœéœ€è¦) é€šè¿‡å‘ LangChain [é›†æˆåŒ…](/oss/javascript/integrations/providers/overview) æäº¤æ‹‰å–è¯·æ±‚æ¥æ›´æ–° `langchain-<package>/profiles.toml` ä¸­çš„å…¶ä»–å­—æ®µå’Œè¦†ç›–ã€‚
</Accordion>

<Warning>
  æ¨¡å‹é…ç½®æ–‡ä»¶æ˜¯ä¸€ä¸ªæµ‹è¯•ç‰ˆåŠŸèƒ½ã€‚é…ç½®æ–‡ä»¶çš„æ ¼å¼å¯èƒ½ä¼šæ›´æ”¹ã€‚
</Warning>

### å¤šæ¨¡æ€ (Multimodal)

æŸäº›æ¨¡å‹å¯ä»¥å¤„ç†å’Œè¿”å›éæ–‡æœ¬æ•°æ®ï¼Œå¦‚å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ã€‚æ‚¨å¯ä»¥é€šè¿‡æä¾› [å†…å®¹å—](/oss/javascript/langchain/messages#message-content) å°†éæ–‡æœ¬æ•°æ®ä¼ é€’ç»™æ¨¡å‹ã€‚

<Tip>
  æ‰€æœ‰å…·æœ‰åº•å±‚å¤šæ¨¡æ€åŠŸèƒ½çš„ LangChain èŠå¤©æ¨¡å‹éƒ½æ”¯æŒï¼š

  1. è·¨æä¾›å•†æ ‡å‡†æ ¼å¼çš„æ•°æ®ï¼ˆè§ [æˆ‘ä»¬çš„æ¶ˆæ¯æŒ‡å—](/oss/javascript/langchain/messages)ï¼‰
  2. OpenAI [chat completions](https://platform.openai.com/docs/api-reference/chat) æ ¼å¼
  3. ç‰¹å®šäºè¯¥æä¾›å•†çš„ä»»ä½•æ ¼å¼ï¼ˆä¾‹å¦‚ï¼ŒAnthropic æ¨¡å‹æ¥å— Anthropic åŸç”Ÿæ ¼å¼ï¼‰
</Tip>

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ¶ˆæ¯æŒ‡å—çš„ [å¤šæ¨¡æ€éƒ¨åˆ†](/oss/javascript/langchain/messages#multimodal)ã€‚

<Tooltip tip="å¹¶éæ‰€æœ‰ LLM éƒ½æ˜¯å¹³ç­‰çš„ï¼" cta="æŸ¥çœ‹å‚è€ƒ" href="https://models.dev/">ä¸€äº›æ¨¡å‹</Tooltip> å¯ä»¥ä½œä¸ºå…¶å“åº”çš„ä¸€éƒ¨åˆ†è¿”å›å¤šæ¨¡æ€æ•°æ®ã€‚å¦‚æœè°ƒç”¨è¿™æ ·åšï¼Œç”Ÿæˆçš„ [`AIMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessage.html) å°†å…·æœ‰å¸¦æœ‰å¤šæ¨¡æ€ç±»å‹çš„å†…å®¹å—ã€‚

```typescript Multimodal output theme={null}
const response = await model.invoke("Create a picture of a cat");
console.log(response.contentBlocks);
// [
//   { type: "text", text: "Here's a picture of a cat" },
//   { type: "image", data: "...", mimeType: "image/jpeg" },
// ]
```

æœ‰å…³ç‰¹å®šæä¾›å•†çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [é›†æˆé¡µé¢](/oss/javascript/integrations/providers/overview)ã€‚

### æ¨ç† (Reasoning)

è®¸å¤šæ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œå¤šæ­¥æ¨ç†ä»¥å¾—å‡ºç»“è®ºã€‚è¿™æ¶‰åŠå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“äºç®¡ç†çš„æ­¥éª¤ã€‚

**å¦‚æœåº•å±‚æ¨¡å‹æ”¯æŒï¼Œ** æ‚¨å¯ä»¥å±•ç¤ºæ­¤æ¨ç†è¿‡ç¨‹ä»¥æ›´å¥½åœ°äº†è§£æ¨¡å‹å¦‚ä½•å¾—å‡ºå…¶æœ€ç»ˆç­”æ¡ˆã€‚

<CodeGroup>
  ```typescript Stream reasoning output theme={null}
  const stream = model.stream("Why do parrots have colorful feathers?");
  for await (const chunk of stream) {
      const reasoningSteps = chunk.contentBlocks.filter(b => b.type === "reasoning");
      console.log(reasoningSteps.length > 0 ? reasoningSteps : chunk.text);
  }
  ```

  ```typescript Complete reasoning output theme={null}
  const response = await model.invoke("Why do parrots have colorful feathers?");
  const reasoningSteps = response.contentBlocks.filter(b => b.type === "reasoning");
  console.log(reasoningSteps.map(step => step.reasoning).join(" "));
  ```
</CodeGroup>

æ ¹æ®æ¨¡å‹çš„ä¸åŒï¼Œæ‚¨æœ‰æ—¶å¯ä»¥æŒ‡å®šå®ƒåº”è¯¥æŠ•å…¥å¤šå°‘ç²¾åŠ›è¿›è¡Œæ¨ç†ã€‚åŒæ ·ï¼Œæ‚¨å¯ä»¥è¯·æ±‚æ¨¡å‹å®Œå…¨å…³é—­æ¨ç†ã€‚è¿™å¯èƒ½é‡‡å–åˆ†ç±»æ¨ç† "tiers"ï¼ˆä¾‹å¦‚ `'low'` æˆ– `'high'`ï¼‰æˆ–æ•´æ•° token é¢„ç®—çš„å½¢å¼ã€‚

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ‚¨çš„ç›¸åº”èŠå¤©æ¨¡å‹çš„ [é›†æˆé¡µé¢](/oss/javascript/integrations/providers/overview) æˆ– [å‚è€ƒ](https://reference.langchain.com/python/integrations/)ã€‚

### æœ¬åœ°æ¨¡å‹ (Local models)

LangChain æ”¯æŒåœ¨æ‚¨è‡ªå·±çš„ç¡¬ä»¶ä¸Šæœ¬åœ°è¿è¡Œæ¨¡å‹ã€‚è¿™å¯¹äºæ•°æ®éšç§è‡³å…³é‡è¦ã€æ‚¨æƒ³è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹æˆ–å¸Œæœ›é¿å…ä½¿ç”¨åŸºäºäº‘çš„æ¨¡å‹äº§ç”Ÿæˆæœ¬çš„åœºæ™¯éå¸¸æœ‰ç”¨ã€‚

[Ollama](/oss/javascript/integrations/chat/ollama) æ˜¯æœ¬åœ°è¿è¡ŒèŠå¤©å’ŒåµŒå…¥æ¨¡å‹çš„æœ€ç®€å•æ–¹æ³•ä¹‹ä¸€ã€‚

### æç¤ºç¼“å­˜ (Prompt caching)

è®¸å¤šæä¾›å•†æä¾›æç¤ºç¼“å­˜åŠŸèƒ½ï¼Œä»¥å‡å°‘é‡å¤å¤„ç†ç›¸åŒ token çš„å»¶è¿Ÿå’Œæˆæœ¬ã€‚è¿™äº›åŠŸèƒ½å¯ä»¥æ˜¯ **éšå¼** æˆ– **æ˜¾å¼** çš„ï¼š

* **éšå¼æç¤ºç¼“å­˜ï¼š** å¦‚æœè¯·æ±‚å‘½ä¸­ç¼“å­˜ï¼Œæä¾›å•†å°†è‡ªåŠ¨ä¼ é€’æˆæœ¬èŠ‚çº¦ã€‚ä¾‹å¦‚ï¼š[OpenAI](/oss/javascript/integrations/chat/openai) å’Œ [Gemini](/oss/javascript/integrations/chat/google)ã€‚
* **æ˜¾å¼ç¼“å­˜ï¼š** æä¾›å•†å…è®¸æ‚¨æ‰‹åŠ¨æŒ‡ç¤ºç¼“å­˜ç‚¹ä»¥è·å¾—æ›´å¤§çš„æ§åˆ¶æƒæˆ–ä¿è¯æˆæœ¬èŠ‚çº¦ã€‚ä¾‹å¦‚ï¼š
  * [`ChatOpenAI`](https://reference.langchain.com/javascript/classes/_langchain_openai.ChatOpenAI.html) (é€šè¿‡ `prompt_cache_key`)
  * Anthropic çš„ [`AnthropicPromptCachingMiddleware`](/oss/javascript/integrations/chat/anthropic#prompt-caching)
  * [Gemini](https://reference.langchain.com/python/integrations/langchain_google_genai/).
  * [AWS Bedrock](/oss/javascript/integrations/chat/bedrock#prompt-caching)

<Warning>
  æç¤ºç¼“å­˜é€šå¸¸ä»…åœ¨è¶…è¿‡æœ€å°è¾“å…¥ token é˜ˆå€¼æ—¶æ‰å¯ç”¨ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [æä¾›å•†é¡µé¢](/oss/javascript/integrations/chat)ã€‚
</Warning>

ç¼“å­˜ä½¿ç”¨æƒ…å†µå°†åæ˜ åœ¨æ¨¡å‹å“åº”çš„ [ä½¿ç”¨å…ƒæ•°æ®](/oss/javascript/langchain/messages#token-usage) ä¸­ã€‚

### æœåŠ¡å™¨ç«¯å·¥å…·ä½¿ç”¨ (Server-side tool use)

ä¸€äº›æä¾›å•†æ”¯æŒæœåŠ¡å™¨ç«¯ [å·¥å…·è°ƒç”¨](#tool-calling) å¾ªç¯ï¼šæ¨¡å‹å¯ä»¥ä¸ç½‘ç»œæœç´¢ã€ä»£ç è§£é‡Šå™¨å’Œå…¶ä»–å·¥å…·äº¤äº’ï¼Œå¹¶åœ¨å•ä¸ªå¯¹è¯å›åˆä¸­åˆ†æç»“æœã€‚

å¦‚æœæ¨¡å‹åœ¨æœåŠ¡å™¨ç«¯è°ƒç”¨å·¥å…·ï¼Œå“åº”æ¶ˆæ¯çš„å†…å®¹å°†åŒ…å«ä»£è¡¨è°ƒç”¨å’Œå·¥å…·ç»“æœçš„å†…å®¹ã€‚è®¿é—®å“åº”çš„ [å†…å®¹å—](/oss/javascript/langchain/messages#standard-content-blocks) å°†ä»¥ä¸æä¾›å•†æ— å…³çš„æ ¼å¼è¿”å›æœåŠ¡å™¨ç«¯å·¥å…·è°ƒç”¨å’Œç»“æœï¼š

```typescript  theme={null}
import { initChatModel } from "langchain";

const model = await initChatModel("gpt-4.1-mini");
const modelWithTools = model.bindTools([{ type: "web_search" }])

const message = await modelWithTools.invoke("What was a positive news story from today?");
console.log(message.contentBlocks);
```

è¿™ä»£è¡¨å•ä¸ªå¯¹è¯å›åˆï¼›æ²¡æœ‰åƒå®¢æˆ·ç«¯ [å·¥å…·è°ƒç”¨](#tool-calling) ä¸­é‚£æ ·éœ€è¦ä¼ å…¥çš„å…³è” [ToolMessage](/oss/javascript/langchain/messages#tool-message) å¯¹è±¡ã€‚

è¯·å‚é˜…ç»™å®šæä¾›å•†çš„ [é›†æˆé¡µé¢](/oss/javascript/integrations/chat) ä»¥è·å–å¯ç”¨å·¥å…·å’Œä½¿ç”¨è¯¦æƒ…ã€‚

### Base URL æˆ–ä»£ç†

å¯¹äºè®¸å¤šèŠå¤©æ¨¡å‹é›†æˆï¼Œæ‚¨å¯ä»¥é…ç½® API è¯·æ±‚çš„åŸºæœ¬ URLï¼Œè¿™å…è®¸æ‚¨ä½¿ç”¨å…·æœ‰ OpenAI å…¼å®¹ API çš„æ¨¡å‹æä¾›å•†æˆ–ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚

<Accordion title="Base URL" icon="link">
  è®¸å¤šæ¨¡å‹æä¾›å•†æä¾› OpenAI å…¼å®¹çš„ APIï¼ˆä¾‹å¦‚ [Together AI](https://www.together.ai/)ã€[vLLM](https://github.com/vllm-project/vllm)ï¼‰ã€‚æ‚¨å¯ä»¥é€šè¿‡æŒ‡å®šé€‚å½“çš„ `base_url` å‚æ•°ä¸è¿™äº›æä¾›å•†ä¸€èµ·ä½¿ç”¨ `initChatModel`ï¼š

  ```python  theme={null}
  model = initChatModel(
      "MODEL_NAME",
      {
          modelProvider: "openai",
          baseUrl: "BASE_URL",
          apiKey: "YOUR_API_KEY",
      }
  )
  ```

  <Note>
    å½“ä½¿ç”¨ç›´æ¥èŠå¤©æ¨¡å‹ç±»å®ä¾‹åŒ–æ—¶ï¼Œå‚æ•°åç§°å¯èƒ½å› æä¾›å•†è€Œå¼‚ã€‚æŸ¥çœ‹ç›¸åº”çš„ [å‚è€ƒ](/oss/javascript/integrations/providers/overview) äº†è§£è¯¦æƒ…ã€‚
  </Note>
</Accordion>

### å¯¹æ•°æ¦‚ç‡ (Log probabilities)

æŸäº›æ¨¡å‹å¯ä»¥é€šè¿‡åœ¨åˆå§‹åŒ–æ¨¡å‹æ—¶è®¾ç½® `logprobs` å‚æ•°æ¥é…ç½®ä¸ºè¿”å›è¡¨ç¤ºç»™å®š token å¯èƒ½æ€§çš„ token çº§å¯¹æ•°æ¦‚ç‡ï¼š

```typescript  theme={null}
const model = new ChatOpenAI({
    model: "gpt-4.1",
    logprobs: true,
});

const responseMessage = await model.invoke("Why do parrots talk?");

responseMessage.response_metadata.logprobs.content.slice(0, 5);
```

### Token ä½¿ç”¨æƒ…å†µ (Token usage)

è®¸å¤šæ¨¡å‹æä¾›å•†ä½œä¸ºè°ƒç”¨å“åº”çš„ä¸€éƒ¨åˆ†è¿”å› token ä½¿ç”¨ä¿¡æ¯ã€‚å¯ç”¨æ—¶ï¼Œæ­¤ä¿¡æ¯å°†åŒ…å«åœ¨ç›¸åº”æ¨¡å‹ç”Ÿæˆçš„ [`AIMessage`](https://reference.langchain.com/javascript/classes/_langchain_core.messages.AIMessage.html) å¯¹è±¡ä¸Šã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [æ¶ˆæ¯](/oss/javascript/langchain/messages) æŒ‡å—ã€‚

<Note>
  ä¸€äº›æä¾›å•† APIï¼Œç‰¹åˆ«æ˜¯ OpenAI å’Œ Azure OpenAI èŠå¤©å®Œæˆï¼Œè¦æ±‚ç”¨æˆ·é€‰æ‹©åŠ å…¥ä»¥åœ¨æµå¼ä¼ è¾“ä¸Šä¸‹æ–‡ä¸­æ¥æ”¶ token ä½¿ç”¨æ•°æ®ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…é›†æˆæŒ‡å—çš„ [æµå¼ä½¿ç”¨å…ƒæ•°æ®](/oss/javascript/integrations/chat/openai#streaming-usage-metadata) éƒ¨åˆ†ã€‚
</Note>

### è°ƒç”¨é…ç½® (Invocation config)

è°ƒç”¨æ¨¡å‹æ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [`RunnableConfig`](https://reference.langchain.com/javascript/interfaces/_langchain_core.runnables.RunnableConfig.html) å¯¹è±¡é€šè¿‡ `config` å‚æ•°ä¼ é€’å…¶ä»–é…ç½®ã€‚è¿™æä¾›äº†å¯¹æ‰§è¡Œè¡Œä¸ºã€å›è°ƒå’Œå…ƒæ•°æ®è·Ÿè¸ªçš„è¿è¡Œæ—¶æ§åˆ¶ã€‚

å¸¸è§çš„é…ç½®é€‰é¡¹åŒ…æ‹¬ï¼š

```typescript Invocation with config theme={null}
const response = await model.invoke(
    "Tell me a joke",
    {
        runName: "joke_generation",      // æ­¤è¿è¡Œçš„è‡ªå®šä¹‰åç§°
        tags: ["humor", "demo"],          // ç”¨äºåˆ†ç±»çš„æ ‡ç­¾
        metadata: {"user_id": "123"},     // è‡ªå®šä¹‰å…ƒæ•°æ®
        callbacks: [my_callback_handler], // å›è°ƒå¤„ç†ç¨‹åº
    }
)
```

å½“å‡ºç°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œè¿™äº›é…ç½®å€¼ç‰¹åˆ«æœ‰ç”¨ï¼š

* ä½¿ç”¨ [LangSmith](https://docs.langchain.com/langsmith/home) è·Ÿè¸ªè¿›è¡Œè°ƒè¯•
* å®ç°è‡ªå®šä¹‰æ—¥å¿—è®°å½•æˆ–ç›‘æ§
* æ§åˆ¶ç”Ÿäº§ä¸­çš„èµ„æºä½¿ç”¨
* è·¨å¤æ‚ç®¡é“è·Ÿè¸ªè°ƒç”¨

<Accordion title="å…³é”®é…ç½®å±æ€§">
  <ParamField body="runName" type="string">
    åœ¨æ—¥å¿—å’Œè·Ÿè¸ªä¸­æ ‡è¯†æ­¤ç‰¹å®šè°ƒç”¨ã€‚å­è°ƒç”¨ä¸ç»§æ‰¿ã€‚
  </ParamField>

  <ParamField body="tags" type="string[]">
    æ‰€æœ‰å­è°ƒç”¨ç»§æ‰¿çš„æ ‡ç­¾ï¼Œç”¨äºåœ¨è°ƒè¯•å·¥å…·ä¸­è¿›è¡Œè¿‡æ»¤å’Œç»„ç»‡ã€‚
  </ParamField>

  <ParamField body="metadata" type="object">
    ç”¨äºè·Ÿè¸ªé™„åŠ ä¸Šä¸‹æ–‡çš„è‡ªå®šä¹‰é”®å€¼å¯¹ï¼Œç”±æ‰€æœ‰å­è°ƒç”¨ç»§æ‰¿ã€‚
  </ParamField>

  <ParamField body="maxConcurrency" type="number">
    ä½¿ç”¨ `batch()` æ—¶æ§åˆ¶æœ€å¤§å¹¶è¡Œè°ƒç”¨æ•°ã€‚
  </ParamField>

  <ParamField body="callbacks" type="CallbackHandler[]">
    ç”¨äºåœ¨æ‰§è¡ŒæœŸé—´ç›‘è§†å’Œå“åº”äº‹ä»¶çš„å¤„ç†ç¨‹åºã€‚
  </ParamField>

  <ParamField body="recursion_limit" type="number">
    é“¾çš„æœ€å¤§é€’å½’æ·±åº¦ï¼Œä»¥é˜²æ­¢å¤æ‚ç®¡é“ä¸­çš„æ— é™å¾ªç¯ã€‚
  </ParamField>
</Accordion>

<Tip>
  è¯·å‚é˜…å®Œæ•´çš„ [`RunnableConfig`](https://reference.langchain.com/javascript/interfaces/_langchain_core.runnables.RunnableConfig.html) å‚è€ƒä»¥è·å–æ‰€æœ‰æ”¯æŒçš„å±æ€§ã€‚
</Tip>

***

<Callout icon="pen-to-square" iconType="regular">
  [åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µé¢](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/models.mdx) æˆ– [æäº¤ issue](https://github.com/langchain-ai/docs/issues/new/choose)ã€‚
</Callout>

<Tip icon="terminal" iconType="regular">
  [å°†è¿™äº›æ–‡æ¡£è¿æ¥](/use-these-docs) åˆ° Claudeã€VSCode ç­‰ï¼Œé€šè¿‡ MCP è·å–å®æ—¶ç­”æ¡ˆã€‚
</Tip>
