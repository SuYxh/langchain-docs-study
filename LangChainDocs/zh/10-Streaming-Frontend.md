## æ–‡æ¡£ç´¢å¼•
åœ¨ä»¥ä¸‹ä½ç½®è·å–å®Œæ•´çš„æ–‡æ¡£ç´¢å¼•ï¼šhttps://docs.langchain.com/llms.txt
ä½¿ç”¨æ­¤æ–‡ä»¶åœ¨è¿›ä¸€æ­¥æ¢ç´¢ä¹‹å‰å‘ç°æ‰€æœ‰å¯ç”¨é¡µé¢ã€‚

# å‰ç«¯

> ä½¿ç”¨æ¥è‡ª LangChain ä»£ç†ã€LangGraph å›¾å’Œè‡ªå®šä¹‰ API çš„å®æ—¶æµæ„å»ºç”Ÿæˆå¼ UI

`useStream` React hook æä¾›äº†ä¸ LangGraph æµå¼ä¼ è¾“åŠŸèƒ½çš„æ— ç¼é›†æˆã€‚å®ƒå¤„ç†äº†æµå¼ä¼ è¾“ã€çŠ¶æ€ç®¡ç†å’Œåˆ†æ”¯é€»è¾‘çš„æ‰€æœ‰å¤æ‚æ€§ï¼Œè®©æ‚¨å¯ä»¥ä¸“æ³¨äºæ„å»ºå‡ºè‰²çš„ç”Ÿæˆå¼ UI ä½“éªŒã€‚

ä¸»è¦ç‰¹æ€§ï¼š

* <Icon icon="messages" size={16} /> **æ¶ˆæ¯æµå¼ä¼ è¾“** â€” å¤„ç†æ¶ˆæ¯å—æµä»¥å½¢æˆå®Œæ•´çš„æ¶ˆæ¯
* <Icon icon="arrows-rotate" size={16} /> **è‡ªåŠ¨çŠ¶æ€ç®¡ç†** â€” é’ˆå¯¹æ¶ˆæ¯ã€ä¸­æ–­ã€åŠ è½½çŠ¶æ€å’Œé”™è¯¯
* <Icon icon="code-branch" size={16} /> **å¯¹è¯åˆ†æ”¯** â€” ä»èŠå¤©å†å²è®°å½•çš„ä»»ä½•ç‚¹åˆ›å»ºå¤‡ç”¨å¯¹è¯è·¯å¾„
* <Icon icon="palette" size={16} /> **UI æ— å…³è®¾è®¡** â€” è‡ªå¸¦ç»„ä»¶å’Œæ ·å¼

## å®‰è£…

å®‰è£… LangGraph SDK ä»¥åœ¨æ‚¨çš„ React åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨ `useStream` hookï¼š

```bash  theme={null}
npm install @langchain/langgraph-sdk
```

## åŸºæœ¬ç”¨æ³•

`useStream` hook å¯ä»¥è¿æ¥åˆ°ä»»ä½• LangGraph å›¾ï¼Œæ— è®ºæ˜¯ä»æ‚¨è‡ªå·±çš„ç«¯ç‚¹è¿è¡Œï¼Œè¿˜æ˜¯ä½¿ç”¨ [LangSmith deployments](/langsmith/deployments) éƒ¨ç½²çš„ã€‚

```tsx  theme={null}
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const stream = useStream({
    assistantId: "agent",
    // æœ¬åœ°å¼€å‘
    apiUrl: "http://localhost:2024",
    // ç”Ÿäº§éƒ¨ç½² (LangSmith æ‰˜ç®¡)
    // apiUrl: "https://your-deployment.us.langgraph.app"
  });

  const handleSubmit = (message: string) => {
    stream.submit({
      messages: [
        { content: message, type: "human" }
      ],
    });
  };

  return (
    <div>
      {stream.messages.map((message, idx) => (
        <div key={message.id ?? idx}>
          {message.type}: {message.content}
        </div>
      ))}

      {stream.isLoading && <div>Loading...</div>}
      {stream.error && <div>Error: {stream.error.message}</div>}
    </div>
  );
}
```

<Tip>
  äº†è§£å¦‚ä½• [å°†æ‚¨çš„ä»£ç†éƒ¨ç½²åˆ° LangSmith](/oss/javascript/langchain/deploy) ä»¥è·å¾—å…·æœ‰å†…ç½®å¯è§‚æµ‹æ€§ã€èº«ä»½éªŒè¯å’Œæ‰©å±•æ€§çš„ç”Ÿäº§å°±ç»ªå‹æ‰˜ç®¡ã€‚
</Tip>

<Accordion title="`useStream` å‚æ•°">
  <ParamField body="assistantId" type="string" required>
    è¦è¿æ¥çš„ä»£ç†çš„ IDã€‚ä½¿ç”¨ LangSmith éƒ¨ç½²æ—¶ï¼Œè¿™å¿…é¡»ä¸éƒ¨ç½²ä»ªè¡¨æ¿ä¸­æ˜¾ç¤ºçš„ä»£ç† ID åŒ¹é…ã€‚å¯¹äºè‡ªå®šä¹‰ API éƒ¨ç½²æˆ–æœ¬åœ°å¼€å‘ï¼Œè¿™å¯ä»¥æ˜¯æ‚¨çš„æœåŠ¡å™¨ç”¨äºæ ‡è¯†ä»£ç†çš„ä»»ä½•å­—ç¬¦ä¸²ã€‚
  </ParamField>

  <ParamField body="apiUrl" type="string">
    LangGraph æœåŠ¡å™¨çš„ URLã€‚æœ¬åœ°å¼€å‘é»˜è®¤ä¸º `http://localhost:2024`ã€‚
  </ParamField>

  <ParamField body="apiKey" type="string">
    ç”¨äºèº«ä»½éªŒè¯çš„ API å¯†é’¥ã€‚è¿æ¥åˆ° LangSmith ä¸Šéƒ¨ç½²çš„ä»£ç†æ—¶éœ€è¦ã€‚
  </ParamField>

  <ParamField body="threadId" type="string">
    è¿æ¥åˆ°ç°æœ‰çº¿ç¨‹è€Œä¸æ˜¯åˆ›å»ºæ–°çº¿ç¨‹ã€‚ç”¨äºæ¢å¤å¯¹è¯ã€‚
  </ParamField>

  <ParamField body="onThreadId" type="(id: string) => void">
    åˆ›å»ºæ–°çº¿ç¨‹æ—¶è°ƒç”¨çš„å›è°ƒã€‚ä½¿ç”¨å®ƒæ¥æŒä¹…åŒ–çº¿ç¨‹ ID ä»¥ä¾›ä»¥åä½¿ç”¨ã€‚
  </ParamField>

  <ParamField body="reconnectOnMount" type="boolean | (() => Storage)">
    ç»„ä»¶æŒ‚è½½æ—¶è‡ªåŠ¨æ¢å¤æ­£åœ¨è¿›è¡Œçš„è¿è¡Œã€‚è®¾ç½®ä¸º `true` ä»¥ä½¿ç”¨ä¼šè¯å­˜å‚¨ï¼Œæˆ–æä¾›è‡ªå®šä¹‰å­˜å‚¨å‡½æ•°ã€‚
  </ParamField>

  <ParamField body="onCreated" type="(run: Run) => void">
    åˆ›å»ºæ–°è¿è¡Œæ—¶è°ƒç”¨çš„å›è°ƒã€‚ç”¨äºæŒä¹…åŒ–è¿è¡Œå…ƒæ•°æ®ä»¥è¿›è¡Œæ¢å¤ã€‚
  </ParamField>

  <ParamField body="onError" type="(error: Error) => void">
    æµå¼ä¼ è¾“æœŸé—´å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨çš„å›è°ƒã€‚
  </ParamField>

  <ParamField body="onFinish" type="(state: StateType, run?: Run) => void">
    æµå¼ä¼ è¾“æˆåŠŸå®Œæˆå¹¶è¿”å›æœ€ç»ˆçŠ¶æ€æ—¶è°ƒç”¨çš„å›è°ƒã€‚
  </ParamField>

  <ParamField body="onCustomEvent" type="(data: unknown, context: { mutate }) => void">
    ä½¿ç”¨ `writer` å¤„ç†ä»æ‚¨çš„ä»£ç†å‘å‡ºçš„è‡ªå®šä¹‰äº‹ä»¶ã€‚è¯·å‚é˜… [è‡ªå®šä¹‰æµå¼äº‹ä»¶](#custom-streaming-events)ã€‚
  </ParamField>

  <ParamField body="onUpdateEvent" type="(data: unknown, context: { mutate }) => void">
    å¤„ç†æ¯ä¸ªå›¾æ­¥éª¤åçš„çŠ¶æ€æ›´æ–°äº‹ä»¶ã€‚
  </ParamField>

  <ParamField body="onMetadataEvent" type="(metadata: { run_id, thread_id }) => void">
    å¤„ç†åŒ…å«è¿è¡Œå’Œçº¿ç¨‹ä¿¡æ¯çš„å…ƒæ•°æ®äº‹ä»¶ã€‚
  </ParamField>

  <ParamField body="messagesKey" type="string" default="messages">
    å›¾çŠ¶æ€ä¸­åŒ…å«æ¶ˆæ¯æ•°ç»„çš„é”®ã€‚
  </ParamField>

  <ParamField body="throttle" type="boolean" default="true">
    æ‰¹é‡å¤„ç†çŠ¶æ€æ›´æ–°ä»¥è·å¾—æ›´å¥½çš„æ¸²æŸ“æ€§èƒ½ã€‚ç¦ç”¨ä»¥è¿›è¡Œç«‹å³æ›´æ–°ã€‚
  </ParamField>

  <ParamField body="initialValues" type="StateType | null">
    ç¬¬ä¸€ä¸ªæµåŠ è½½æ—¶æ˜¾ç¤ºçš„åˆå§‹çŠ¶æ€å€¼ã€‚ç”¨äºç«‹å³æ˜¾ç¤ºç¼“å­˜çš„çº¿ç¨‹æ•°æ®ã€‚
  </ParamField>
</Accordion>

<Accordion title="`useStream` è¿”å›å€¼">
  <ParamField body="messages" type="Message[]">
    å½“å‰çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼ŒåŒ…æ‹¬äººç±»å’Œ AI æ¶ˆæ¯ã€‚
  </ParamField>

  <ParamField body="values" type="StateType">
    å½“å‰çš„å›¾çŠ¶æ€å€¼ã€‚ç±»å‹æ˜¯ä»ä»£ç†æˆ–å›¾ç±»å‹å‚æ•°æ¨æ–­å‡ºæ¥çš„ã€‚
  </ParamField>

  <ParamField body="isLoading" type="boolean">
    æµæ˜¯å¦å½“å‰æ­£åœ¨è¿›è¡Œä¸­ã€‚ä½¿ç”¨å®ƒæ¥æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨ã€‚
  </ParamField>

  <ParamField body="error" type="Error | null">
    æµå¼ä¼ è¾“æœŸé—´å‘ç”Ÿçš„ä»»ä½•é”™è¯¯ã€‚æ²¡æœ‰é”™è¯¯æ—¶ä¸º `null`ã€‚
  </ParamField>

  <ParamField body="interrupt" type="Interrupt | undefined">
    å½“å‰éœ€è¦ç”¨æˆ·è¾“å…¥çš„ä¸­æ–­ï¼Œä¾‹å¦‚äººæœºäº¤äº’ (human-in-the-loop) æ‰¹å‡†è¯·æ±‚ã€‚
  </ParamField>

  <ParamField body="toolCalls" type="ToolCallWithResult[]">
    æ‰€æœ‰æ¶ˆæ¯ä¸­çš„æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ŒåŠå…¶ç»“æœå’ŒçŠ¶æ€ï¼ˆ`pending`ã€`completed` æˆ– `error`ï¼‰ã€‚
  </ParamField>

  <ParamField body="submit" type="(input, options?) => Promise<void>">
    å‘ä»£ç†æäº¤æ–°è¾“å…¥ã€‚å½“ä½¿ç”¨å‘½ä»¤ä»ä¸­æ–­æ¢å¤æ—¶ï¼Œä¼ é€’ `null` ä½œä¸ºè¾“å…¥ã€‚é€‰é¡¹åŒ…æ‹¬ç”¨äºåˆ†æ”¯çš„ `checkpoint`ã€ç”¨äºä¹è§‚æ›´æ–°çš„ `optimisticValues` å’Œç”¨äºä¹è§‚çº¿ç¨‹åˆ›å»ºçš„ `threadId`ã€‚
  </ParamField>

  <ParamField body="stop" type="() => void">
    ç«‹å³åœæ­¢å½“å‰æµã€‚
  </ParamField>

  <ParamField body="joinStream" type="(runId: string) => void">
    é€šè¿‡è¿è¡Œ ID æ¢å¤ç°æœ‰æµã€‚ä¸ `onCreated` ä¸€èµ·ä½¿ç”¨ä»¥è¿›è¡Œæ‰‹åŠ¨æµæ¢å¤ã€‚
  </ParamField>

  <ParamField body="setBranch" type="(branch: string) => void">
    åˆ‡æ¢åˆ°å¯¹è¯å†å²è®°å½•ä¸­çš„ä¸åŒåˆ†æ”¯ã€‚
  </ParamField>

  <ParamField body="getToolCalls" type="(message) => ToolCall[]">
    è·å–ç‰¹å®š AI æ¶ˆæ¯çš„æ‰€æœ‰å·¥å…·è°ƒç”¨ã€‚
  </ParamField>

  <ParamField body="getMessagesMetadata" type="(message) => MessageMetadata">
    è·å–æ¶ˆæ¯çš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ç”¨äºè¯†åˆ«æºèŠ‚ç‚¹çš„ `langgraph_node` ç­‰æµå¼ä¿¡æ¯ï¼Œä»¥åŠç”¨äºåˆ†æ”¯çš„ `firstSeenState`ã€‚
  </ParamField>

  <ParamField body="experimental_branchTree" type="BranchTree">
    ç”¨äºéåŸºäºæ¶ˆæ¯çš„å›¾çš„é«˜çº§åˆ†æ”¯æ§åˆ¶çš„çº¿ç¨‹æ ‘è¡¨ç¤ºã€‚
  </ParamField>
</Accordion>

## çº¿ç¨‹ç®¡ç†

ä½¿ç”¨å†…ç½®çš„çº¿ç¨‹ç®¡ç†è·Ÿè¸ªå¯¹è¯ã€‚æ‚¨å¯ä»¥è®¿é—®å½“å‰çº¿ç¨‹ ID å¹¶åœ¨åˆ›å»ºæ–°çº¿ç¨‹æ—¶è·å¾—é€šçŸ¥ï¼š

```tsx  theme={null}
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const [threadId, setThreadId] = useState<string | null>(null);

  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId: threadId,
    onThreadId: setThreadId,
  });

  // åˆ›å»ºæ–°çº¿ç¨‹æ—¶ threadId ä¼šæ›´æ–°
  // å°†å…¶å­˜å‚¨åœ¨ URL å‚æ•°æˆ– localStorage ä¸­ä»¥è¿›è¡ŒæŒä¹…åŒ–
}
```

æˆ‘ä»¬å»ºè®®å­˜å‚¨ `threadId` ä»¥ä¾¿ç”¨æˆ·åœ¨é¡µé¢åˆ·æ–°åæ¢å¤å¯¹è¯ã€‚

### é¡µé¢åˆ·æ–°åæ¢å¤

`useStream` hook å¯ä»¥é€šè¿‡è®¾ç½® `reconnectOnMount: true` åœ¨æŒ‚è½½æ—¶è‡ªåŠ¨æ¢å¤æ­£åœ¨è¿›è¡Œçš„è¿è¡Œã€‚è¿™å¯¹äºåœ¨é¡µé¢åˆ·æ–°åç»§ç»­æµå¼ä¼ è¾“éå¸¸æœ‰ç”¨ï¼Œå¯ç¡®ä¿ä¸ä¼šä¸¢å¤±åœæœºæœŸé—´ç”Ÿæˆçš„æ¶ˆæ¯å’Œäº‹ä»¶ã€‚

```tsx  theme={null}
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  reconnectOnMount: true,
});
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„è¿è¡Œ ID å­˜å‚¨åœ¨ `window.sessionStorage` ä¸­ï¼Œå¯ä»¥é€šè¿‡ä¼ é€’è‡ªå®šä¹‰å­˜å‚¨å‡½æ•°æ¥äº¤æ¢ï¼š

```tsx  theme={null}
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  reconnectOnMount: () => window.localStorage,
});
```

è¦æ‰‹åŠ¨æ§åˆ¶æ¢å¤è¿‡ç¨‹ï¼Œè¯·ä½¿ç”¨è¿è¡Œå›è°ƒæ¥æŒä¹…åŒ–å…ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨ `joinStream` è¿›è¡Œæ¢å¤ï¼š

```tsx  theme={null}
import { useStream } from "@langchain/langgraph-sdk/react";
import { useEffect, useRef } from "react";

function Chat({ threadId }: { threadId: string | null }) {
  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    onCreated: (run) => {
      // æµå¼€å§‹æ—¶æŒä¹…åŒ–è¿è¡Œ ID
      window.sessionStorage.setItem(`resume:${run.thread_id}`, run.run_id);
    },
    onFinish: (_, run) => {
      // æµå®Œæˆæ—¶æ¸…ç†
      window.sessionStorage.removeItem(`resume:${run?.thread_id}`);
    },
  });

  // å¦‚æœæœ‰å­˜å‚¨çš„è¿è¡Œ IDï¼Œåˆ™åœ¨æŒ‚è½½æ—¶æ¢å¤æµ
  const joinedThreadId = useRef<string | null>(null);
  useEffect(() => {
    if (!threadId) return;
    const runId = window.sessionStorage.getItem(`resume:${threadId}`);
    if (runId && joinedThreadId.current !== threadId) {
      stream.joinStream(runId);
      joinedThreadId.current = threadId;
    }
  }, [threadId]);

  const handleSubmit = (text: string) => {
    // ä½¿ç”¨ streamResumable ç¡®ä¿ä¸ä¼šä¸¢å¤±äº‹ä»¶
    stream.submit(
      { messages: [{ type: "human", content: text }] },
      { streamResumable: true }
    );
  };
}
```

<Card title="å°è¯•ä¼šè¯æŒä¹…åŒ–ç¤ºä¾‹" icon="rotate" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/session-persistence">
  åœ¨ `session-persistence` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¸¦æœ‰ `reconnectOnMount` å’Œçº¿ç¨‹æŒä¹…åŒ–çš„æµæ¢å¤çš„å®Œæ•´å®ç°ã€‚
</Card>

## ä¹è§‚æ›´æ–°

æ‚¨å¯ä»¥åœ¨æ‰§è¡Œç½‘ç»œè¯·æ±‚ä¹‹å‰ä¹è§‚åœ°æ›´æ–°å®¢æˆ·ç«¯çŠ¶æ€ï¼Œä»è€Œå‘ç”¨æˆ·æä¾›å³æ—¶åé¦ˆï¼š

```tsx  theme={null}
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});

const handleSubmit = (text: string) => {
  const newMessage = { type: "human" as const, content: text };

  stream.submit(
    { messages: [newMessage] },
    {
      optimisticValues(prev) {
        const prevMessages = prev.messages ?? [];
        return { ...prev, messages: [...prevMessages, newMessage] };
      },
    }
  );
};
```

### ä¹è§‚çº¿ç¨‹åˆ›å»º

åœ¨ `submit` ä¸­ä½¿ç”¨ `threadId` é€‰é¡¹ä»¥å¯ç”¨ä¹è§‚ UI æ¨¡å¼ï¼Œåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œæ‚¨éœ€è¦åœ¨åˆ›å»ºçº¿ç¨‹ä¹‹å‰çŸ¥é“çº¿ç¨‹ IDï¼š

```tsx  theme={null}
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const [threadId, setThreadId] = useState<string | null>(null);
  const [optimisticThreadId] = useState(() => crypto.randomUUID());

  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    onThreadId: setThreadId,
  });

  const handleSubmit = (text: string) => {
    // ç«‹å³å¯¼èˆªï¼Œæ— éœ€ç­‰å¾…çº¿ç¨‹åˆ›å»º
    window.history.pushState({}, "", `/threads/${optimisticThreadId}`);

    // ä½¿ç”¨é¢„å®šçš„ ID åˆ›å»ºçº¿ç¨‹
    stream.submit(
      { messages: [{ type: "human", content: text }] },
      { threadId: optimisticThreadId }
    );
  };
}
```

### ç¼“å­˜çº¿ç¨‹æ˜¾ç¤º

ä½¿ç”¨ `initialValues` é€‰é¡¹åœ¨ä»æœåŠ¡å™¨åŠ è½½å†å²è®°å½•çš„åŒæ—¶ç«‹å³æ˜¾ç¤ºç¼“å­˜çš„çº¿ç¨‹æ•°æ®ï¼š

```tsx  theme={null}
function Chat({ threadId, cachedData }) {
  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    initialValues: cachedData?.values,
  });

  // ç«‹å³æ˜¾ç¤ºç¼“å­˜çš„æ¶ˆæ¯ï¼Œç„¶ååœ¨æœåŠ¡å™¨å“åº”æ—¶æ›´æ–°
}
```

## åˆ†æ”¯

é€šè¿‡ç¼–è¾‘ä»¥å‰çš„æ¶ˆæ¯æˆ–é‡æ–°ç”Ÿæˆ AI å“åº”æ¥åˆ›å»ºå¤‡ç”¨å¯¹è¯è·¯å¾„ã€‚ä½¿ç”¨ `getMessagesMetadata()` è®¿é—®ç”¨äºåˆ†æ”¯çš„æ£€æŸ¥ç‚¹ä¿¡æ¯ï¼š

<CodeGroup>
  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import { BranchSwitcher } from "./BranchSwitcher";

  function Chat() {
    const stream = useStream({
      assistantId: "agent",
      apiUrl: "http://localhost:2024",
    });

    return (
      <div>
        {stream.messages.map((message) => {
          const meta = stream.getMessagesMetadata(message);
          const parentCheckpoint = meta?.firstSeenState?.parent_checkpoint;

          return (
            <div key={message.id}>
              <div>{message.content as string}</div>

              {/* ç¼–è¾‘äººç±»æ¶ˆæ¯ */}
              {message.type === "human" && (
                <button
                  onClick={() => {
                    const newContent = prompt("Edit message:", message.content as string);
                    if (newContent) {
                      stream.submit(
                        { messages: [{ type: "human", content: newContent }] },
                        { checkpoint: parentCheckpoint }
                      );
                    }
                  }}
                >
                  Edit
                </button>
              )}

              {/* é‡æ–°ç”Ÿæˆ AI æ¶ˆæ¯ */}
              {message.type === "ai" && (
                <button
                  onClick={() => stream.submit(undefined, { checkpoint: parentCheckpoint })}
                >
                  Regenerate
                </button>
              )}

              {/* åœ¨åˆ†æ”¯ä¹‹é—´åˆ‡æ¢ */}
              <BranchSwitcher
                branch={meta?.branch}
                branchOptions={meta?.branchOptions}
                onSelect={(branch) => stream.setBranch(branch)}
              />
            </div>
          );
        })}
      </div>
    );
  }
  ```

  ```tsx BranchSwitcher.tsx theme={null}
  /**
   * ç”¨äºåœ¨å¯¹è¯åˆ†æ”¯ä¹‹é—´å¯¼èˆªçš„ç»„ä»¶ã€‚
   * æ˜¾ç¤ºå½“å‰åˆ†æ”¯ä½ç½®å¹¶å…è®¸åœ¨å¤‡é€‰æ–¹æ¡ˆä¹‹é—´åˆ‡æ¢ã€‚
   */
  export function BranchSwitcher({
    branch,
    branchOptions,
    onSelect,
  }: {
    branch: string | undefined;
    branchOptions: string[] | undefined;
    onSelect: (branch: string) => void;
  }) {
    if (!branchOptions || !branch) return null;
    const index = branchOptions.indexOf(branch);

    return (
      <div className="flex items-center gap-2">
        <button
          type="button"
          disabled={index <= 0}
          onClick={() => onSelect(branchOptions[index - 1])}
        >
          â†
        </button>
        <span>{index + 1} / {branchOptions.length}</span>
        <button
          type="button"
          disabled={index >= branchOptions.length - 1}
          onClick={() => onSelect(branchOptions[index + 1])}
        >
          â†’
        </button>
      </div>
    );
  }
  ```
</CodeGroup>

å¯¹äºé«˜çº§ç”¨ä¾‹ï¼Œè¯·ä½¿ç”¨ `experimental_branchTree` å±æ€§æ¥è·å–éåŸºäºæ¶ˆæ¯çš„å›¾çš„çº¿ç¨‹æ ‘è¡¨ç¤ºã€‚

<Card title="å°è¯•åˆ†æ”¯ç¤ºä¾‹" icon="code-branch" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/branching-chat">
  åœ¨ `branching-chat` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¯¹è¯åˆ†æ”¯çš„å®Œæ•´å®ç°ï¼ŒåŒ…æ‹¬ç¼–è¾‘ã€é‡æ–°ç”Ÿæˆå’Œåˆ†æ”¯åˆ‡æ¢ã€‚
</Card>

## ç±»å‹å®‰å…¨æµå¼ä¼ è¾“

`useStream` hook åœ¨ä¸é€šè¿‡ [`createAgent`](https://reference.langchain.com/javascript/functions/langchain.index.createAgent.html) åˆ›å»ºçš„ä»£ç†æˆ–é€šè¿‡ [`StateGraph`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.StateGraph.html) åˆ›å»ºçš„å›¾ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œæ”¯æŒå®Œæ•´çš„ç±»å‹æ¨æ–­ã€‚ä¼ é€’ `typeof agent` æˆ– `typeof graph` ä½œä¸ºç±»å‹å‚æ•°ä»¥è‡ªåŠ¨æ¨æ–­å·¥å…·è°ƒç”¨ç±»å‹ã€‚

### ä½¿ç”¨ `createAgent`

å½“ä½¿ç”¨ [`createAgent`](https://reference.langchain.com/javascript/functions/langchain.index.createAgent.html) æ—¶ï¼Œå·¥å…·è°ƒç”¨ç±»å‹ä¼šè‡ªåŠ¨ä»æ‚¨æ³¨å†Œåˆ°ä»£ç†çš„å·¥å…·ä¸­æ¨æ–­å‡ºæ¥ï¼š

<CodeGroup>
  ```typescript agent.ts theme={null}
  import { createAgent, tool } from "langchain";
  import { z } from "zod";

  const getWeather = tool(
    async ({ location }) => `Weather in ${location}: Sunny, 72Â°F`,
    {
      name: "get_weather",
      description: "Get weather for a location",
      schema: z.object({
        location: z.string().describe("The city to get weather for"),
      }),
    }
  );

  export const agent = createAgent({
    model: "openai:gpt-4.1-mini",
    tools: [getWeather],
  });
  ```

  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { agent } from "./agent";

  function Chat() {
    // å·¥å…·è°ƒç”¨ä¼šæ ¹æ®ä»£ç†çš„å·¥å…·è‡ªåŠ¨è®¾å®šç±»å‹
    const stream = useStream<typeof agent>({
      assistantId: "agent",
      apiUrl: "http://localhost:2024",
    });

    // stream.toolCalls[0].call.name ç±»å‹ä¸º "get_weather"
    // stream.toolCalls[0].call.args ç±»å‹ä¸º { location: string }
  }
  ```
</CodeGroup>

### ä½¿ç”¨ `StateGraph`

å¯¹äºè‡ªå®šä¹‰ [`StateGraph`](https://reference.langchain.com/javascript/classes/_langchain_langgraph.index.StateGraph.html) åº”ç”¨ç¨‹åºï¼ŒçŠ¶æ€ç±»å‹æ˜¯ä»å›¾çš„æ³¨é‡Šä¸­æ¨æ–­å‡ºæ¥çš„ï¼š

<CodeGroup>
  ```typescript graph.ts theme={null}
  import { StateGraph, MessagesAnnotation, START, END } from "@langchain/langgraph";
  import { ChatOpenAI } from "@langchain/openai";

  const model = new ChatOpenAI({ model: "gpt-4.1-mini" });

  const workflow = new StateGraph(MessagesAnnotation)
    .addNode("agent", async (state) => {
      const response = await model.invoke(state.messages);
      return { messages: [response] };
    })
    .addEdge(START, "agent")
    .addEdge("agent", END);

  export const graph = workflow.compile();
  ```

  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { graph } from "./graph";

  function Chat() {
    // çŠ¶æ€ç±»å‹ä¼šè‡ªåŠ¨ä»å›¾ä¸­æ¨æ–­å‡ºæ¥
    const stream = useStream<typeof graph>({
      assistantId: "my-graph",
      apiUrl: "http://localhost:2024",
    });

    // stream.values åŸºäºå›¾çš„çŠ¶æ€æ³¨é‡Šè¿›è¡Œç±»å‹å®šä¹‰
  }
  ```
</CodeGroup>

### ä½¿ç”¨ Annotation ç±»å‹

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨ LangGraph.jsï¼Œæ‚¨å¯ä»¥é‡ç”¨å›¾çš„ Annotation ç±»å‹ã€‚è¯·ç¡®ä¿ä»…å¯¼å…¥ç±»å‹ï¼Œä»¥é¿å…å¯¼å…¥æ•´ä¸ª LangGraph.js è¿è¡Œæ—¶ï¼š

```tsx  theme={null}
import {
  Annotation,
  MessagesAnnotation,
  type StateType,
  type UpdateType,
} from "@langchain/langgraph/web";

const AgentState = Annotation.Root({
  ...MessagesAnnotation.spec,
  context: Annotation<string>(),
});

const stream = useStream<
  StateType<typeof AgentState.spec>,
  { UpdateType: UpdateType<typeof AgentState.spec> }
>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});
```

### é«˜çº§ç±»å‹é…ç½®

æ‚¨å¯ä»¥ä¸ºä¸­æ–­ã€è‡ªå®šä¹‰äº‹ä»¶å’Œå¯é…ç½®é€‰é¡¹æŒ‡å®šå…¶ä»–ç±»å‹å‚æ•°ï¼š

```tsx  theme={null}
import type { Message } from "@langchain/langgraph-sdk";

type State = { messages: Message[]; context?: string };

const stream = useStream<
  State,
  {
    UpdateType: { messages: Message[] | Message; context?: string };
    InterruptType: string;
    CustomEventType: { type: "progress" | "debug"; payload: unknown };
    ConfigurableType: { model: string };
  }
>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});

// stream.interrupt ç±»å‹ä¸º string | undefined
// onCustomEvent æ¥æ”¶ç±»å‹åŒ–çš„äº‹ä»¶
```

## æ¸²æŸ“å·¥å…·è°ƒç”¨

ä½¿ç”¨ `getToolCalls` ä» AI æ¶ˆæ¯ä¸­æå–å¹¶æ¸²æŸ“å·¥å…·è°ƒç”¨ã€‚å·¥å…·è°ƒç”¨åŒ…æ‹¬è°ƒç”¨è¯¦ç»†ä¿¡æ¯ã€ç»“æœï¼ˆå¦‚æœå·²å®Œæˆï¼‰å’ŒçŠ¶æ€ã€‚

<CodeGroup>
  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { agent } from "./agent";
  import { ToolCallCard } from "./ToolCallCard";
  import { MessageBubble } from "./MessageBubble";

  function Chat() {
    const stream = useStream<typeof agent>({
      assistantId: "agent",
      apiUrl: "http://localhost:2024",
    });

    return (
      <div className="flex flex-col gap-4">
        {stream.messages.map((message, idx) => {
          if (message.type === "ai") {
            const toolCalls = stream.getToolCalls(message);

            if (toolCalls.length > 0) {
              return (
                <div key={message.id ?? idx} className="flex flex-col gap-2">
                  {toolCalls.map((toolCall) => (
                    <ToolCallCard key={toolCall.id} toolCall={toolCall} />
                  ))}
                </div>
              );
            }
          }

          return <MessageBubble key={message.id ?? idx} message={message} />;
        })}
      </div>
    );
  }
  ```

  ```tsx ToolCallCard.tsx theme={null}
  import type {
    ToolCallWithResult,
    ToolCallFromTool,
    ToolCallState,
    InferAgentToolCalls,
  } from "@langchain/langgraph-sdk/react";
  import type { ToolMessage } from "@langchain/langgraph-sdk";
  import type { agent } from "./agent";
  import type { getWeather } from "./tools";
  import { parseToolResult } from "./utils";
  import { WeatherCard } from "./WeatherCard";

  /**
   * ä¸ºæ­¤ç»„ä»¶å®šä¹‰å·¥å…·è°ƒç”¨ç±»å‹ã€‚
   * å¯¹äºä»£ç†ä½¿ç”¨ InferAgentToolCallsï¼Œå¯¹äºå•ä¸ªå·¥å…·ä½¿ç”¨ ToolCallFromToolã€‚
   */
  type AgentToolCalls = InferAgentToolCalls<typeof agent>;

  /**
   * æ¸²æŸ“å·¥å…·è°ƒç”¨åŠå…¶ç»“æœçš„ç»„ä»¶ã€‚
   * ä½¿ç”¨ç±»å‹åŒ–çš„ ToolCallWithResult è¿›è¡Œå¯è¾¨è¯†è”åˆç±»å‹ç¼©å°ã€‚
   */
  export function ToolCallCard({
    toolCall,
  }: {
    toolCall: ToolCallWithResult<AgentToolCalls>;
  }) {
    const { call, result, state } = toolCall;

    // å½“ call.name æ˜¯å­—é¢é‡ç±»å‹æ—¶ï¼Œç±»å‹ç¼©å°èµ·ä½œç”¨
    if (call.name === "get_weather") {
      return <WeatherCard call={call} result={result} state={state} />;
    }

    // å…¶ä»–å·¥å…·çš„åå¤‡æ–¹æ¡ˆ
    return <GenericToolCallCard call={call} result={result} state={state} />;
  }
  ```

  ```tsx GenericToolCallCard.tsx theme={null}
  import type { ToolCallState } from "@langchain/langgraph-sdk/react";
  import type { ToolMessage } from "@langchain/langgraph-sdk";
  import { parseToolResult } from "./utils";

  /**
   * æœªçŸ¥æˆ–æœªå¤„ç†å·¥å…·çš„é€šç”¨åå¤‡æ–¹æ¡ˆã€‚
   * ä½¿ç”¨é€‚ç”¨äºä»»ä½•å·¥å…·è°ƒç”¨çš„ç®€å•ç±»å‹ã€‚
   */
  export function GenericToolCallCard({
    call,
    result,
    state,
  }: {
    call: { name: string; args: Record<string, unknown> };
    result?: ToolMessage;
    state: ToolCallState;
  }) {
    const isLoading = state === "pending";
    const parsedResult = parseToolResult(result);

    return (
      <div className="bg-neutral-900 rounded-lg p-4 border border-neutral-800">
        <div className="flex items-center gap-3 mb-3">
          <div className="flex-1">
            <div className="text-sm font-medium text-white font-mono">
              {call.name}
            </div>
            <div className="text-xs text-neutral-500">
              {isLoading ? "Processing..." : "Completed"}
            </div>
          </div>
        </div>
        <pre className="text-xs bg-black rounded p-2 mb-2 overflow-x-auto">
          {JSON.stringify(call.args, null, 2)}
        </pre>
        {result && (
          <div className="text-sm rounded-lg p-3 bg-black text-neutral-300">
            {parsedResult.content}
          </div>
        )}
      </div>
    );
  }
  ```

  ```tsx WeatherCard.tsx theme={null}
  import type { ToolCallFromTool, ToolCallState } from "@langchain/langgraph-sdk/react";
  import type { ToolMessage } from "@langchain/langgraph-sdk";
  import type { getWeather } from "./tools";
  import { parseToolResult } from "./utils";

  // ç›´æ¥ä»å·¥å…·å®šä¹‰æ¨æ–­å·¥å…·è°ƒç”¨ç±»å‹
  type GetWeatherToolCall = ToolCallFromTool<typeof getWeather>;

  /**
   * å…·æœ‰ä¸°å¯Œ UI çš„å¤©æ°”ç‰¹å®šå·¥å…·å¡ç‰‡ã€‚
   * ä½¿ç”¨ ToolCallFromTool ä»å·¥å…·æ¶æ„æ¨æ–­ args ç±»å‹ã€‚
   */
  export function WeatherCard({
    call,
    result,
    state,
  }: {
    call: GetWeatherToolCall;
    result?: ToolMessage;
    state: ToolCallState;
  }) {
    const isLoading = state === "pending";
    const parsedResult = parseToolResult(result);

    return (
      <div className="relative overflow-hidden rounded-xl">
        {/* å¤©ç©ºæ¸å˜èƒŒæ™¯ */}
        <div className="absolute inset-0 bg-gradient-to-br from-sky-600 to-indigo-600" />

        <div className="relative p-4">
          <div className="flex items-center gap-2 text-white/80 text-xs mb-3">
            {/* call.args ç±»å‹ä¸º { location: string }ï¼Œæ¥è‡ªå·¥å…·æ¶æ„ */}
            <span className="font-medium">{call.args.location}</span>
            {isLoading && <span className="ml-auto">Loading...</span>}
          </div>

          {parsedResult.status === "error" ? (
            <div className="bg-red-500/20 rounded-lg p-3 text-red-200 text-sm">
              {parsedResult.content}
            </div>
          ) : (
            <div className="text-white text-lg font-medium">
              {parsedResult.content || "Fetching weather..."}
            </div>
          )}
        </div>
      </div>
    );
  }
  ```

  ```typescript tools.ts theme={null}
  import { tool } from "@langchain/core/tools";
  import { z } from "zod";

  // ä½¿ç”¨ Zod æ¶æ„å®šä¹‰å¤©æ°”å·¥å…·
  export const getWeather = tool(
    async ({ location }) => {
      // å·¥å…·å®ç°
      return JSON.stringify({ status: "success", content: `Weather in ${location}: Sunny, 72Â°F` });
    },
    {
      name: "get_weather",
      description: "Get the current weather for a location",
      schema: z.object({
        location: z.string().describe("The city and state, e.g. San Francisco, CA"),
      }),
    }
  );
  ```

  ```typescript utils.ts theme={null}
  import type { ToolMessage } from "@langchain/langgraph-sdk";

  /**
   * å®‰å…¨è§£æå·¥å…·ç»“æœçš„è¾…åŠ©å‡½æ•°ã€‚
   * å·¥å…·ç»“æœå¯ä»¥æ˜¯ JSON å­—ç¬¦ä¸²æˆ–çº¯æ–‡æœ¬ã€‚
   */
  export function parseToolResult(result?: ToolMessage): {
    status: string;
    content: string;
  } {
    if (!result) return { status: "pending", content: "" };
    try {
      return JSON.parse(result.content as string);
    } catch {
      return { status: "success", content: result.content as string };
    }
  }
  ```
</CodeGroup>

<Card title="å°è¯•å·¥å…·è°ƒç”¨ç¤ºä¾‹" icon="hammer" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/tool-calling-agent">
  åœ¨ `tool-calling-agent` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¸¦æœ‰å¤©æ°”ã€è®¡ç®—å™¨å’Œç¬”è®°å·¥å…·çš„å·¥å…·è°ƒç”¨æ¸²æŸ“çš„å®Œæ•´å®ç°ã€‚
</Card>

## è‡ªå®šä¹‰æµå¼äº‹ä»¶

ä½¿ç”¨å·¥å…·æˆ–èŠ‚ç‚¹ä¸­çš„ `writer` ä»æ‚¨çš„ä»£ç†æµå¼ä¼ è¾“è‡ªå®šä¹‰æ•°æ®ã€‚ä½¿ç”¨ `onCustomEvent` å›è°ƒåœ¨ UI ä¸­å¤„ç†è¿™äº›äº‹ä»¶ã€‚

<CodeGroup>
  ```typescript agent.ts theme={null}
  import { tool, type ToolRuntime } from "langchain";
  import { z } from "zod";

  // å®šä¹‰æ‚¨çš„è‡ªå®šä¹‰äº‹ä»¶ç±»å‹
  interface ProgressData {
    type: "progress";
    id: string;
    message: string;
    progress: number;
  }

  const analyzeDataTool = tool(
    async ({ dataSource }, config: ToolRuntime) => {
      const steps = ["Connecting...", "Fetching...", "Processing...", "Done!"];

      for (let i = 0; i < steps.length; i++) {
        // åœ¨æ‰§è¡ŒæœŸé—´å‘å‡ºè¿›åº¦äº‹ä»¶
        config.writer?.({
          type: "progress",
          id: `analysis-${Date.now()}`,
          message: steps[i],
          progress: ((i + 1) / steps.length) * 100,
        } satisfies ProgressData);

        await new Promise((resolve) => setTimeout(resolve, 500));
      }

      return JSON.stringify({ result: "Analysis complete" });
    },
    {
      name: "analyze_data",
      description: "Analyze data with progress updates",
      schema: z.object({
        dataSource: z.string().describe("Data source to analyze"),
      }),
    }
  );
  ```

  ```tsx Chat.tsx theme={null}
  import { useState, useCallback } from "react";
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { agent } from "./agent";

  interface ProgressData {
    type: "progress";
    id: string;
    message: string;
    progress: number;
  }

  function isProgressData(data: unknown): data is ProgressData {
    return (
      typeof data === "object" &&
      data !== null &&
      "type" in data &&
      (data as ProgressData).type === "progress"
    );
  }

  function CustomStreamingUI() {
    const [progressData, setProgressData] = useState<Map<string, ProgressData>>(
      new Map()
    );

    const handleCustomEvent = useCallback((data: unknown) => {
      if (isProgressData(data)) {
        setProgressData((prev) => {
          const updated = new Map(prev);
          updated.set(data.id, data);
          return updated;
        });
      }
    }, []);

    const stream = useStream<typeof agent>({
      assistantId: "custom-streaming",
      apiUrl: "http://localhost:2024",
      onCustomEvent: handleCustomEvent,
    });

    return (
      <div>
        {/* æ¸²æŸ“è¿›åº¦å¡ç‰‡ */}
        {Array.from(progressData.values()).map((data) => (
          <div key={data.id} className="bg-neutral-800 rounded-lg p-4 mb-4">
            <div className="flex justify-between mb-2">
              <span className="text-sm text-white">{data.message}</span>
              <span className="text-xs text-neutral-400">{data.progress}%</span>
            </div>
            <div className="w-full bg-neutral-700 rounded-full h-2">
              <div
                className="bg-blue-500 h-2 rounded-full transition-all"
                style={{ width: `${data.progress}%` }}
              />
            </div>
          </div>
        ))}
      </div>
    );
  }
  ```
</CodeGroup>

<Card title="å°è¯•è‡ªå®šä¹‰æµå¼ç¤ºä¾‹" icon="bolt" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/custom-streaming">
  åœ¨ `custom-streaming` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¸¦æœ‰è¿›åº¦æ¡ã€çŠ¶æ€å¾½ç« å’Œæ–‡ä»¶æ“ä½œå¡ç‰‡çš„è‡ªå®šä¹‰äº‹ä»¶çš„å®Œæ•´å®ç°ã€‚
</Card>

## äº‹ä»¶å¤„ç†

`useStream` hook æä¾›äº†å›è°ƒé€‰é¡¹ï¼Œè®©æ‚¨å¯ä»¥è®¿é—®ä¸åŒç±»å‹çš„æµå¼äº‹ä»¶ã€‚æ‚¨ä¸éœ€è¦æ˜¾å¼é…ç½®æµæ¨¡å¼â€”â€”åªéœ€ä¸ºæ‚¨æƒ³è¦å¤„ç†çš„äº‹ä»¶ç±»å‹ä¼ é€’å›è°ƒï¼š

```tsx  theme={null}
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",

  // å¤„ç†æ¯ä¸ªå›¾æ­¥éª¤åçš„çŠ¶æ€æ›´æ–°
  onUpdateEvent: (update, options) => {
    console.log("Graph update:", update);
  },

  // å¤„ç†ä»æ‚¨çš„å›¾æµå¼ä¼ è¾“çš„è‡ªå®šä¹‰äº‹ä»¶
  onCustomEvent: (event, options) => {
    console.log("Custom event:", event);
  },

  // å¤„ç†å¸¦æœ‰è¿è¡Œ/çº¿ç¨‹ä¿¡æ¯çš„å…ƒæ•°æ®äº‹ä»¶
  onMetadataEvent: (metadata) => {
    console.log("Run ID:", metadata.run_id);
    console.log("Thread ID:", metadata.thread_id);
  },

  onError: (error) => {
    console.error("Stream error:", error);
  },

  onFinish: (state, options) => {
    console.log("Stream finished with final state:", state);
  },
});
```

### å¯ç”¨å›è°ƒ

| å›è°ƒ | æè¿° | æµæ¨¡å¼ |
| ----------------- | ------------------------------------------------------------ | ----------- |
| `onUpdateEvent` | åœ¨æ¯ä¸ªå›¾æ­¥éª¤åæ¥æ”¶åˆ°çŠ¶æ€æ›´æ–°æ—¶è°ƒç”¨ | `updates` |
| `onCustomEvent` | å½“ä»æ‚¨çš„å›¾æ¥æ”¶åˆ°è‡ªå®šä¹‰äº‹ä»¶æ—¶è°ƒç”¨ | `custom` |
| `onMetadataEvent` | ä½¿ç”¨è¿è¡Œå’Œçº¿ç¨‹å…ƒæ•°æ®è°ƒç”¨ | `metadata` |
| `onError` | å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨ | - |
| `onFinish` | æµå®Œæˆæ—¶è°ƒç”¨ | - |

## å¤šæ™ºèƒ½ä½“æµå¼ä¼ è¾“

åœ¨å¤„ç†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæˆ–å…·æœ‰å¤šä¸ªèŠ‚ç‚¹çš„å›¾æ—¶ï¼Œä½¿ç”¨æ¶ˆæ¯å…ƒæ•°æ®æ¥æ ‡è¯†å“ªä¸ªèŠ‚ç‚¹ç”Ÿæˆäº†æ¯æ¡æ¶ˆæ¯ã€‚å½“å¤šä¸ª LLM å¹¶è¡Œè¿è¡Œå¹¶ä¸”æ‚¨å¸Œæœ›ä»¥ä¸åŒçš„è§†è§‰æ ·å¼æ˜¾ç¤ºå…¶è¾“å‡ºæ—¶ï¼Œè¿™ç‰¹åˆ«æœ‰ç”¨ã€‚

<CodeGroup>
  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { agent } from "./agent";
  import { MessageBubble } from "./MessageBubble";

  // ç”¨äºè§†è§‰æ˜¾ç¤ºçš„èŠ‚ç‚¹é…ç½®
  const NODE_CONFIG: Record<string, { label: string; color: string }> = {
    researcher_analytical: { label: "Analytical Research", color: "cyan" },
    researcher_creative: { label: "Creative Research", color: "purple" },
    researcher_practical: { label: "Practical Research", color: "emerald" },
  };

  function MultiAgentChat() {
    const stream = useStream<typeof agent>({
      assistantId: "parallel-research",
      apiUrl: "http://localhost:2024",
    });

    return (
      <div className="flex flex-col gap-4">
        {stream.messages.map((message, idx) => {
          if (message.type !== "ai") {
            return <MessageBubble key={message.id ?? idx} message={message} />;
          }

          // è·å–æµå¼å…ƒæ•°æ®ä»¥è¯†åˆ«æºèŠ‚ç‚¹
          const metadata = stream.getMessagesMetadata?.(message);
          const nodeName =
            (metadata?.streamMetadata?.langgraph_node as string) ||
            (message as { name?: string }).name;

          const config = nodeName ? NODE_CONFIG[nodeName] : null;

          if (!config) {
            return <MessageBubble key={message.id ?? idx} message={message} />;
          }

          return (
            <div
              key={message.id ?? idx}
              className={`bg-${config.color}-950/30 border border-${config.color}-500/30 rounded-xl p-4`}
            >
              <div className={`text-sm font-semibold text-${config.color}-400 mb-2`}>
                {config.label}
              </div>
              <div className="text-neutral-200 whitespace-pre-wrap">
                {typeof message.content === "string" ? message.content : ""}
              </div>
            </div>
          );
        })}
      </div>
    );
  }
  ```

  ```typescript agent.ts theme={null}
  import { ChatOpenAI } from "@langchain/openai";
  import {
    StateGraph,
    START,
    END,
    Send,
    StateSchema,
    MessagesValue,
    GraphNode,
    ConditionalEdgeRouter,
  } from "@langchain/langgraph";
  import { AIMessage } from "@langchain/core/messages";
  import { z } from "zod";

  // ä½¿ç”¨ä¸åŒçš„æ¨¡å‹å®ä¾‹ä»¥è·å¾—å¤šæ ·æ€§
  const analyticalModel = new ChatOpenAI({ model: "gpt-4.1-mini", temperature: 0.3 });
  const creativeModel = new ChatOpenAI({ model: "gpt-4.1-mini", temperature: 0.9 });
  const practicalModel = new ChatOpenAI({ model: "gpt-4.1-mini", temperature: 0.5 });

  // å®šä¹‰çŠ¶æ€æ¶æ„
  const StateAnnotation = new StateSchema({
    messages: MessagesValue,
    topic: z.string().default(""),
    analyticalResearch: z.string().default(""),
    creativeResearch: z.string().default(""),
    practicalResearch: z.string().default(""),
  });

  type State = typeof StateAnnotation.State;

  // æ‰‡å‡ºåˆ°å¹¶è¡Œç ”ç©¶äººå‘˜
  const fanOutToResearchers: ConditionalEdgeRouter<State> = (state) => {
    return [
      new Send("researcher_analytical", state),
      new Send("researcher_creative", state),
      new Send("researcher_practical", state),
    ];
  };

  const dispatcherNode: GraphNode<State> = async (state) => {
    const lastMessage = state.messages.at(-1);
    const topic = typeof lastMessage?.content === "string" ? lastMessage.content : "";
    return { topic };
  };

  const analyticalResearcherNode: GraphNode<State> = async (state) => {
    const response = await analyticalModel.invoke([
      { role: "system", content: "You are an analytical research expert. Focus on data and evidence." },
      { role: "user", content: `Research: ${state.topic}` },
    ]);
    return {
      analyticalResearch: response.content as string,
      messages: [new AIMessage({ content: response.content as string, name: "researcher_analytical" })],
    };
  };

  // åˆ›æ„å’Œå®è·µç ”ç©¶äººå‘˜çš„ç±»ä¼¼èŠ‚ç‚¹...

  // æ„å»ºå…·æœ‰å¹¶è¡Œæ‰§è¡Œçš„å›¾
  const workflow = new StateGraph(StateAnnotation)
    .addNode("dispatcher", dispatcherNode)
    .addNode("researcher_analytical", analyticalResearcherNode)
    .addNode("researcher_creative", creativeResearcherNode)
    .addNode("researcher_practical", practicalResearcherNode)
    .addEdge(START, "dispatcher")
    .addConditionalEdges("dispatcher", fanOutToResearchers)
    .addEdge("researcher_analytical", END)
    .addEdge("researcher_creative", END)
    .addEdge("researcher_practical", END);

  export const agent = workflow.compile();
  ```
</CodeGroup>

<Card title="å°è¯•å¹¶è¡Œç ”ç©¶ç¤ºä¾‹" icon="users" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/parallel-research">
  åœ¨ `parallel-research` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“æµå¼ä¼ è¾“çš„å®Œæ•´å®ç°ï¼Œè¯¥ç¤ºä¾‹å…·æœ‰ä¸‰ä¸ªå¹¶è¡Œç ”ç©¶äººå‘˜å’Œç‹¬ç‰¹çš„è§†è§‰æ ·å¼ã€‚
</Card>

## äººæœºäº¤äº’ (Human-in-the-loop)

å½“ä»£ç†éœ€è¦äººå·¥æ‰¹å‡†æ‰èƒ½æ‰§è¡Œå·¥å…·æ—¶å¤„ç†ä¸­æ–­ã€‚åœ¨ [å¦‚ä½•å¤„ç†ä¸­æ–­](/oss/javascript/langgraph/interrupts#pause-using-interrupt) æŒ‡å—ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚

<CodeGroup>
  ```tsx Chat.tsx theme={null}
  import { useState } from "react";
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { HITLRequest, HITLResponse } from "langchain";
  import type { agent } from "./agent";
  import { MessageBubble } from "./MessageBubble";

  function HumanInTheLoopChat() {
    const stream = useStream<typeof agent, { InterruptType: HITLRequest }>({
      assistantId: "human-in-the-loop",
      apiUrl: "http://localhost:2024",
    });

    const [isProcessing, setIsProcessing] = useState(false);

    // ä¸­æ–­å€¼çš„ç±»å‹æ–­è¨€
    const hitlRequest = stream.interrupt?.value as HITLRequest | undefined;

    const handleApprove = async (index: number) => {
      if (!hitlRequest) return;
      setIsProcessing(true);

      try {
        const decisions: HITLResponse["decisions"] =
          hitlRequest.actionRequests.map((_, i) =>
            i === index ? { type: "approve" } : { type: "approve" }
          );

        await stream.submit(null, {
          command: {
            resume: { decisions } as HITLResponse,
          },
        });
      } finally {
        setIsProcessing(false);
      }
    };

    const handleReject = async (index: number, reason: string) => {
      if (!hitlRequest) return;
      setIsProcessing(true);

      try {
        const decisions: HITLResponse["decisions"] =
          hitlRequest.actionRequests.map((_, i) =>
            i === index
              ? { type: "reject", message: reason }
              : { type: "reject", message: "Rejected along with other actions" }
          );

        await stream.submit(null, {
          command: {
            resume: { decisions } as HITLResponse,
          },
        });
      } finally {
        setIsProcessing(false);
      }
    };

    return (
      <div>
        {/* æ¸²æŸ“æ¶ˆæ¯ */}
        {stream.messages.map((message, idx) => (
          <MessageBubble key={message.id ?? idx} message={message} />
        ))}

        {/* ä¸­æ–­æ—¶æ¸²æŸ“æ‰¹å‡† UI */}
        {hitlRequest && hitlRequest.actionRequests.length > 0 && (
          <div className="bg-amber-900/20 border border-amber-500/30 rounded-xl p-4 mt-4">
            <h3 className="text-amber-400 font-semibold mb-4">
              Action requires approval
            </h3>

            {hitlRequest.actionRequests.map((action, idx) => (
              <div
                key={idx}
                className="bg-neutral-900 rounded-lg p-4 mb-4 last:mb-0"
              >
                <div className="flex items-center gap-2 mb-2">
                  <span className="text-sm font-mono text-white">
                    {action.name}
                  </span>
                </div>

                <pre className="text-xs bg-black rounded p-2 mb-3 overflow-x-auto">
                  {JSON.stringify(action.args, null, 2)}
                </pre>

                <div className="flex gap-2">
                  <button
                    onClick={() => handleApprove(idx)}
                    disabled={isProcessing}
                    className="px-3 py-1.5 bg-green-600 hover:bg-green-700 text-white text-sm rounded disabled:opacity-50"
                  >
                    Approve
                  </button>
                  <button
                    onClick={() => handleReject(idx, "User rejected")}
                    disabled={isProcessing}
                    className="px-3 py-1.5 bg-red-600 hover:bg-red-700 text-white text-sm rounded disabled:opacity-50"
                  >
                    Reject
                  </button>
                </div>
              </div>
            ))}
          </div>
        )}
      </div>
    );
  }
  ```

  ```typescript agent.ts theme={null}
  import { createAgent, tool, humanInTheLoopMiddleware } from "langchain";
  import { ChatOpenAI } from "@langchain/openai";
  import { MemorySaver } from "@langchain/langgraph";
  import { z } from "zod";

  const model = new ChatOpenAI({ model: "gpt-4.1-mini" });

  // éœ€è¦äººå·¥æ‰¹å‡†çš„å·¥å…·
  const sendEmail = tool(
    async ({ to, subject, body }) => {
      return {
        status: "success",
        content: `Email sent to ${to} with subject "${subject}"`,
      };
    },
    {
      name: "send_email",
      description: "Send an email. Requires human approval.",
      schema: z.object({
        to: z.string().describe("Recipient email address"),
        subject: z.string().describe("Email subject"),
        body: z.string().describe("Email body"),
      }),
    }
  );

  // éœ€è¦æ‰¹å‡†ä½†é€‰é¡¹æœ‰é™çš„å·¥å…·
  const deleteFile = tool(
    async ({ path }) => {
      return { status: "success", content: `File "${path}" deleted` };
    },
    {
      name: "delete_file",
      description: "Delete a file. Requires human approval.",
      schema: z.object({
        path: z.string().describe("File path to delete"),
      }),
    }
  );

  // å®‰å…¨å·¥å…· - æ— éœ€æ‰¹å‡†
  const readFile = tool(
    async ({ path }) => {
      return { status: "success", content: `Contents of ${path}...` };
    },
    {
      name: "read_file",
      description: "Read file contents. No approval needed.",
      schema: z.object({
        path: z.string().describe("File path to read"),
      }),
    }
  );

  // åˆ›å»ºå¸¦æœ‰ HITL ä¸­é—´ä»¶çš„ä»£ç†
  export const agent = createAgent({
    model,
    tools: [sendEmail, deleteFile, readFile],
    middleware: [
      humanInTheLoopMiddleware({
        interruptOn: {
          // ç”µå­é‚®ä»¶éœ€è¦æ‰€æœ‰å†³ç­–ç±»å‹
          send_email: {
            allowedDecisions: ["approve", "edit", "reject"],
            description: "ğŸ“§ Review email before sending",
          },
          // åˆ é™¤ä»…å…è®¸æ‰¹å‡†/æ‹’ç»
          delete_file: {
            allowedDecisions: ["approve", "reject"],
            description: "ğŸ—‘ï¸ Confirm file deletion",
          },
          // è¯»å–æ˜¯å®‰å…¨çš„ - è‡ªåŠ¨æ‰¹å‡†
          read_file: false,
        },
      }),
    ],
    // HITL æ‰€éœ€ - è·¨ä¸­æ–­æŒä¹…åŒ–çŠ¶æ€
    checkpointer: new MemorySaver(),
  });
  ```
</CodeGroup>

<Card title="å°è¯•äººæœºäº¤äº’ç¤ºä¾‹" icon="hand" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/human-in-the-loop">
  åœ¨ `human-in-the-loop` ç¤ºä¾‹ä¸­æŸ¥çœ‹æ‰¹å‡†å·¥ä½œæµçš„å®Œæ•´å®ç°ï¼ŒåŒ…æ‹¬æ‰¹å‡†ã€æ‹’ç»å’Œç¼–è¾‘æ“ä½œã€‚
</Card>

## æ¨ç†æ¨¡å‹

<Warning>
  æ‰©å±•æ¨ç†/æ€è€ƒæ”¯æŒç›®å‰æ˜¯å®éªŒæ€§çš„ã€‚æ¨ç† token çš„æµå¼æ¥å£å› æä¾›å•†ï¼ˆOpenAI vs. Anthropicï¼‰è€Œå¼‚ï¼Œå¹¶ä¸”éšç€æŠ½è±¡çš„å‘å±•å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚
</Warning>

å½“ä½¿ç”¨å…·æœ‰æ‰©å±•æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼ˆå¦‚ OpenAI çš„æ¨ç†æ¨¡å‹æˆ– Anthropic çš„æ‰©å±•æ€è€ƒï¼‰æ—¶ï¼Œæ€è€ƒè¿‡ç¨‹åµŒå…¥åœ¨æ¶ˆæ¯å†…å®¹ä¸­ã€‚æ‚¨éœ€è¦å•ç‹¬æå–å¹¶æ˜¾ç¤ºå®ƒã€‚

<CodeGroup>
  ```tsx Chat.tsx theme={null}
  import { useStream } from "@langchain/langgraph-sdk/react";
  import type { Message } from "@langchain/langgraph-sdk";
  import type { agent } from "./agent";
  import { getReasoningFromMessage, getTextContent } from "./utils";

  function ReasoningChat() {
    const stream = useStream<typeof agent>({
      assistantId: "reasoning-agent",
      apiUrl: "http://localhost:2024",
    });

    return (
      <div className="flex flex-col gap-4">
        {stream.messages.map((message, idx) => {
          if (message.type === "ai") {
            const reasoning = getReasoningFromMessage(message);
            const textContent = getTextContent(message);

            return (
              <div key={message.id ?? idx}>
                {/* å¦‚æœå­˜åœ¨ï¼Œæ¸²æŸ“æ¨ç†æ°”æ³¡ */}
                {reasoning && (
                  <div className="mb-4">
                    <div className="text-xs font-medium text-amber-400/80 mb-2">
                      Reasoning
                    </div>
                    <div className="bg-amber-950/50 border border-amber-500/20 rounded-2xl px-4 py-3">
                      <div className="text-sm text-amber-100/90 whitespace-pre-wrap">
                        {reasoning}
                      </div>
                    </div>
                  </div>
                )}

                {/* æ¸²æŸ“æ–‡æœ¬å†…å®¹ */}
                {textContent && (
                  <div className="text-neutral-100 whitespace-pre-wrap">
                    {textContent}
                  </div>
                )}
              </div>
            );
          }

          return <MessageBubble key={message.id ?? idx} message={message} />;
        })}

        {stream.isLoading && (
          <div className="flex items-center gap-2 text-amber-400/70">
            <span className="text-sm">Thinking...</span>
          </div>
        )}
      </div>
    );
  }
  ```

  ```typescript utils.ts theme={null}
  import type { Message, AIMessage } from "@langchain/langgraph-sdk";

  /**
   * ä» AI æ¶ˆæ¯ä¸­æå–æ¨ç†/æ€è€ƒå†…å®¹ã€‚
   * æ”¯æŒ OpenAI æ¨ç† (additional_kwargs.reasoning.summary)
   * å’Œ Anthropic æ‰©å±•æ€è€ƒ (content blocks with type "thinking")ã€‚
   */
  export function getReasoningFromMessage(message: Message): string | undefined {
    type MessageWithExtras = AIMessage & {
      additional_kwargs?: {
        reasoning?: {
          summary?: Array<{ type: string; text: string }>;
        };
      };
      contentBlocks?: Array<{ type: string; thinking?: string }>;
    };

    const msg = message as MessageWithExtras;

    // æ£€æŸ¥ additional_kwargs ä¸­çš„ OpenAI æ¨ç†
    if (msg.additional_kwargs?.reasoning?.summary) {
      const content = msg.additional_kwargs.reasoning.summary
        .filter((item) => item.type === "summary_text")
        .map((item) => item.text)
        .join("");

      if (content.trim()) return content;
    }

    // æ£€æŸ¥ contentBlocks ä¸­çš„ Anthropic æ€è€ƒ
    if (msg.contentBlocks?.length) {
      const thinking = msg.contentBlocks
        .filter((b) => b.type === "thinking" && b.thinking)
        .map((b) => b.thinking)
        .join("\n");

      if (thinking) return thinking;
    }

    // æ£€æŸ¥ message.content æ•°ç»„ä¸­çš„æ€è€ƒ
    if (Array.isArray(msg.content)) {
      const thinking = msg.content
        .filter((b): b is { type: "thinking"; thinking: string } =>
          typeof b === "object" && b?.type === "thinking" && "thinking" in b
        )
        .map((b) => b.thinking)
        .join("\n");

      if (thinking) return thinking;
    }

    return undefined;
  }

  /**
   * ä»æ¶ˆæ¯ä¸­æå–æ–‡æœ¬å†…å®¹ã€‚
   */
  export function getTextContent(message: Message): string {
    if (typeof message.content === "string") return message.content;

    if (Array.isArray(message.content)) {
      return message.content
        .filter((c): c is { type: "text"; text: string } => c.type === "text")
        .map((c) => c.text)
        .join("");
    }

    return "";
  }
  ```
</CodeGroup>

<Card title="å°è¯•æ¨ç†ç¤ºä¾‹" icon="brain" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/reasoning-agent">
  åœ¨ `reasoning-agent` ç¤ºä¾‹ä¸­æŸ¥çœ‹ä½¿ç”¨ OpenAI å’Œ Anthropic æ¨¡å‹æ˜¾ç¤ºæ¨ç† token çš„å®Œæ•´å®ç°ã€‚
</Card>

## è‡ªå®šä¹‰çŠ¶æ€ç±»å‹

å¯¹äºè‡ªå®šä¹‰ LangGraph åº”ç”¨ç¨‹åºï¼Œå°†æ‚¨çš„å·¥å…·è°ƒç”¨ç±»å‹åµŒå…¥åˆ°çŠ¶æ€çš„ messages å±æ€§ä¸­ã€‚

```tsx  theme={null}
import { Message } from "@langchain/langgraph-sdk";
import { useStream } from "@langchain/langgraph-sdk/react";

// å°†æ‚¨çš„å·¥å…·è°ƒç”¨ç±»å‹å®šä¹‰ä¸ºå¯è¾¨è¯†è”åˆ
type MyToolCalls =
  | { name: "search"; args: { query: string }; id?: string }
  | { name: "calculate"; args: { expression: string }; id?: string };

// å°†å·¥å…·è°ƒç”¨ç±»å‹åµŒå…¥åˆ°æ‚¨çš„çŠ¶æ€æ¶ˆæ¯ä¸­
interface MyGraphState {
  messages: Message<MyToolCalls>[];
  context?: string;
}

function CustomGraphChat() {
  const stream = useStream<MyGraphState>({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.values ç±»å‹ä¸º MyGraphState
  // stream.toolCalls[0].call.name ç±»å‹ä¸º "search" | "calculate"
}
```

æ‚¨è¿˜å¯ä»¥ä¸ºä¸­æ–­å’Œå¯é…ç½®é€‰é¡¹æŒ‡å®šå…¶ä»–ç±»å‹é…ç½®ï¼š

```tsx  theme={null}
interface MyGraphState {
  messages: Message<MyToolCalls>[];
}

function CustomGraphChat() {
  const stream = useStream<
    MyGraphState,
    {
      InterruptType: { question: string };
      ConfigurableType: { userId: string };
    }
  >({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.interrupt ç±»å‹ä¸º { question: string } | undefined
}
```

## è‡ªå®šä¹‰ä¼ è¾“

å¯¹äºè‡ªå®šä¹‰ API ç«¯ç‚¹æˆ–éæ ‡å‡†éƒ¨ç½²ï¼Œè¯·ä½¿ç”¨ `transport` é€‰é¡¹é…åˆ `FetchStreamTransport` è¿æ¥åˆ°ä»»ä½•æµå¼ APIã€‚

```tsx  theme={null}
import { useMemo } from "react";
import { useStream, FetchStreamTransport } from "@langchain/langgraph-sdk/react";

function CustomAPIChat({ apiKey }: { apiKey: string }) {
  // ä½¿ç”¨è‡ªå®šä¹‰è¯·æ±‚å¤„ç†åˆ›å»ºä¼ è¾“
  const transport = useMemo(() => {
    return new FetchStreamTransport({
      apiUrl: "/api/my-agent",
      onRequest: async (url: string, init: RequestInit) => {
        // å°† API å¯†é’¥æˆ–å…¶ä»–è‡ªå®šä¹‰æ•°æ®æ³¨å…¥è¯·æ±‚
        const customBody = JSON.stringify({
          ...(JSON.parse(init.body as string) || {}),
          apiKey,
        });

        return {
          ...init,
          body: customBody,
          headers: {
            ...init.headers,
            "X-Custom-Header": "value",
          },
        };
      },
    });
  }, [apiKey]);

  const stream = useStream({
    transport,
  });

  // åƒå¾€å¸¸ä¸€æ ·ä½¿ç”¨ stream
  return (
    <div>
      {stream.messages.map((message, idx) => (
        <MessageBubble key={message.id ?? idx} message={message} />
      ))}
    </div>
  );
}
```

## ç›¸å…³å†…å®¹

* [æµå¼ä¼ è¾“æ¦‚è¿°](/oss/javascript/langchain/streaming/overview) â€” ä½¿ç”¨ LangChain ä»£ç†çš„æœåŠ¡å™¨ç«¯æµå¼ä¼ è¾“
* [useStream API å‚è€ƒ](https://reference.langchain.com/javascript/functions/_langchain_langgraph-sdk.react.useStream.html) â€” å®Œæ•´çš„ API æ–‡æ¡£
* [ä»£ç†èŠå¤© UI](/oss/javascript/langchain/ui) â€” LangGraph ä»£ç†çš„é¢„æ„å»ºèŠå¤©ç•Œé¢
* [äººæœºäº¤äº’](/oss/javascript/langchain/human-in-the-loop) â€” é…ç½®ç”¨äºäººå·¥å®¡æ ¸çš„ä¸­æ–­
* [å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ](/oss/javascript/langchain/multi-agent) â€” æ„å»ºå…·æœ‰å¤šä¸ª LLM çš„ä»£ç†

***

<Callout icon="pen-to-square" iconType="regular">
  [åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µé¢](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/streaming/frontend.mdx) æˆ– [æäº¤é—®é¢˜](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>

<Tip icon="terminal" iconType="regular">
  [å°†è¿™äº›æ–‡æ¡£è¿æ¥](/use-these-docs) åˆ° Claude, VSCode, ä»¥åŠæ›´å¤šé€šè¿‡ MCP è·å–å®æ—¶ç­”æ¡ˆã€‚
</Tip>
