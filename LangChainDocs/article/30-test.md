# 30. Agent æµ‹è¯•ï¼šç¡®ä¿ä½ çš„ AI ç¨³å®šå¯é 

## ç®€å•æ¥è¯´

æƒ³è±¡ä½ å¼€å‘äº†ä¸€ä¸ªå¤©æ°” Agentï¼Œæµ‹è¯•æ—¶ä¸€åˆ‡æ­£å¸¸ï¼š

```
ç”¨æˆ·ï¼š"æ—§é‡‘å±±å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
Agentï¼šè°ƒç”¨ get_weather å·¥å…· â†’ "æ—§é‡‘å±±ä»Šå¤© 25Â°Cï¼Œæ™´æœ—"
```

ä¸Šçº¿åç”¨æˆ·åé¦ˆï¼š"ä½ ä»¬çš„ AI ä¸é è°±ï¼Œé—®å¤©æ°”ç›´æ¥çç¼–ï¼"

ä¸€æŸ¥æ—¥å¿—ï¼Œå‘ç° Agent æœ‰æ—¶å€™ä¸è°ƒç”¨å·¥å…·ï¼Œç›´æ¥ç¼–é€ å¤©æ°”æ•°æ®...

**é—®é¢˜æ¥äº†**ï¼šLLM æ˜¯éç¡®å®šæ€§çš„ï¼ŒåŒæ ·çš„è¾“å…¥å¯èƒ½äº§ç”Ÿä¸åŒçš„è¾“å‡ºã€‚

**ä¼ ç»Ÿæµ‹è¯•æ–¹æ³•å¤±æ•ˆäº†**ï¼š
- å•å…ƒæµ‹è¯•ï¼ŸLLM è¾“å‡ºä¸å›ºå®šï¼Œæ²¡æ³•æ–­è¨€
- é›†æˆæµ‹è¯•ï¼Ÿæ¯æ¬¡è¿è¡Œç»“æœå¯èƒ½ä¸åŒ
- æ€ä¹ˆä¿è¯ Agent è¡Œä¸ºç¨³å®šï¼Ÿ

**Agent æµ‹è¯•çš„æ ¸å¿ƒæ€è·¯**ï¼šä¸æµ‹å…·ä½“è¾“å‡ºï¼Œæµ‹**æ‰§è¡Œè½¨è¿¹ï¼ˆTrajectoryï¼‰**ã€‚

```
âœ… æ­£ç¡®è½¨è¿¹ï¼šç”¨æˆ·æé—® â†’ è°ƒç”¨ get_weather â†’ è¿”å›ç»“æœ
âŒ é”™è¯¯è½¨è¿¹ï¼šç”¨æˆ·æé—® â†’ ç›´æ¥ç¼–é€ ç­”æ¡ˆï¼ˆæ²¡æœ‰è°ƒç”¨å·¥å…·ï¼‰
```

## æœ¬èŠ‚ç›®æ ‡

1. ç†è§£ Agent æµ‹è¯•çš„æ ¸å¿ƒæŒ‘æˆ˜
2. æŒæ¡è½¨è¿¹åŒ¹é…æµ‹è¯•ï¼ˆTrajectory Matchï¼‰
3. å­¦ä¼šä½¿ç”¨ LLM-as-Judge è¯„ä¼°
4. äº†è§£ LangSmith é›†æˆæµ‹è¯•

## ä¸šåŠ¡åœºæ™¯

å‡è®¾ä½ å¼€å‘äº†ä¸€ä¸ª**å¤©æ°”åŠ©æ‰‹ Agent**ï¼š

```typescript
import { createAgent, tool } from "langchain";
import * as z from "zod";

const getWeather = tool(
  async ({ city }) => {
    // è°ƒç”¨å¤©æ°” API
    return `It's 75 degrees and sunny in ${city}.`;
  },
  {
    name: "get_weather",
    description: "è·å–åŸå¸‚å¤©æ°”ä¿¡æ¯",
    schema: z.object({
      city: z.string().describe("åŸå¸‚å")
    })
  }
);

const agent = createAgent({
  model: "gpt-4.1",
  tools: [getWeather],
  systemPrompt: "ä½ æ˜¯å¤©æ°”åŠ©æ‰‹ï¼Œä½¿ç”¨ get_weather å·¥å…·æŸ¥è¯¢å¤©æ°”ã€‚"
});
```

ä½ éœ€è¦æµ‹è¯•ï¼š
1. ç”¨æˆ·é—®å¤©æ°”æ—¶ï¼ŒAgent **å¿…é¡»**è°ƒç”¨ `get_weather` å·¥å…·
2. å·¥å…·å‚æ•°æ˜¯æ­£ç¡®çš„åŸå¸‚å
3. æœ€ç»ˆå›å¤åŸºäºå·¥å…·è¿”å›çš„çœŸå®æ•°æ®

## ä¸¤ç§æµ‹è¯•æ–¹æ³•

### æ–¹æ³• 1ï¼šè½¨è¿¹åŒ¹é…ï¼ˆTrajectory Matchï¼‰

é¢„å®šä¹‰æœŸæœ›çš„æ‰§è¡Œè½¨è¿¹ï¼ŒéªŒè¯å®é™…è½¨è¿¹æ˜¯å¦åŒ¹é…ã€‚

**ä¼˜ç‚¹**ï¼šç¡®å®šæ€§ã€å¿«é€Ÿã€æ— é¢å¤– LLM è°ƒç”¨
**ç¼ºç‚¹**ï¼šéœ€è¦é¢„å…ˆçŸ¥é“æœŸæœ›è¡Œä¸º

### æ–¹æ³• 2ï¼šLLM-as-Judge

ç”¨å¦ä¸€ä¸ª LLM è¯„ä¼° Agent çš„æ‰§è¡Œè½¨è¿¹æ˜¯å¦åˆç†ã€‚

**ä¼˜ç‚¹**ï¼šçµæ´»ã€å¯è¯„ä¼°å¤æ‚è¡Œä¸º
**ç¼ºç‚¹**ï¼šéœ€è¦é¢å¤– LLM è°ƒç”¨ã€ç»“æœä¸å®Œå…¨ç¡®å®š

## è½¨è¿¹åŒ¹é…æµ‹è¯•

### å®‰è£… AgentEvals

```bash
npm install agentevals @langchain/core
```

### å››ç§åŒ¹é…æ¨¡å¼

| æ¨¡å¼ | æè¿° | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `strict` | å®Œå…¨åŒ¹é…ï¼Œé¡ºåºå’Œå†…å®¹éƒ½è¦ä¸€è‡´ | ä¸¥æ ¼çš„å·¥ä½œæµç¨‹ |
| `unordered` | å·¥å…·è°ƒç”¨ç›¸åŒï¼Œé¡ºåºå¯ä»¥ä¸åŒ | é¡ºåºä¸é‡è¦çš„åœºæ™¯ |
| `subset` | Agent åªè°ƒç”¨å‚è€ƒè½¨è¿¹ä¸­çš„å·¥å…· | ç¡®ä¿ä¸è¶Šæƒ |
| `superset` | Agent è‡³å°‘è°ƒç”¨å‚è€ƒè½¨è¿¹ä¸­çš„å·¥å…· | ç¡®ä¿æœ€å°è¡Œä¸º |

### ä¸¥æ ¼åŒ¹é…æµ‹è¯•

ç¡®ä¿ Agent çš„æ‰§è¡Œè½¨è¿¹å®Œå…¨ç¬¦åˆé¢„æœŸï¼š

```typescript
import { createAgent, tool } from "langchain";
import { HumanMessage, AIMessage, ToolMessage } from "@langchain/core/messages";
import { createTrajectoryMatchEvaluator } from "agentevals";
import * as z from "zod";

const getWeather = tool(
  async ({ city }) => `It's 75 degrees and sunny in ${city}.`,
  {
    name: "get_weather",
    description: "è·å–å¤©æ°”",
    schema: z.object({ city: z.string() })
  }
);

const agent = createAgent({
  model: "gpt-4.1",
  tools: [getWeather]
});

const evaluator = createTrajectoryMatchEvaluator({
  trajectoryMatchMode: "strict"
});

async function testWeatherToolCalled() {
  const result = await agent.invoke({
    messages: [new HumanMessage("What's the weather in San Francisco?")]
  });

  const referenceTrajectory = [
    new HumanMessage("What's the weather in San Francisco?"),
    new AIMessage({
      content: "",
      tool_calls: [
        { id: "call_1", name: "get_weather", args: { city: "San Francisco" } }
      ]
    }),
    new ToolMessage({
      content: "It's 75 degrees and sunny in San Francisco.",
      tool_call_id: "call_1"
    }),
    new AIMessage("The weather in San Francisco is 75 degrees and sunny."),
  ];

  const evaluation = await evaluator({
    outputs: result.messages,
    referenceOutputs: referenceTrajectory
  });

  console.log(evaluation);
  // { key: 'trajectory_strict_match', score: true }
  
  expect(evaluation.score).toBe(true);
}
```

### æ— åºåŒ¹é…æµ‹è¯•

å½“è°ƒç”¨é¡ºåºä¸é‡è¦æ—¶ä½¿ç”¨ï¼š

```typescript
const getWeather = tool(
  async ({ city }) => `Weather in ${city}: 75Â°F`,
  {
    name: "get_weather",
    description: "è·å–å¤©æ°”",
    schema: z.object({ city: z.string() })
  }
);

const getEvents = tool(
  async ({ city }) => `Events in ${city}: Concert tonight`,
  {
    name: "get_events",
    description: "è·å–æ´»åŠ¨",
    schema: z.object({ city: z.string() })
  }
);

const agent = createAgent({
  model: "gpt-4.1",
  tools: [getWeather, getEvents]
});

const evaluator = createTrajectoryMatchEvaluator({
  trajectoryMatchMode: "unordered"
});

async function testMultipleToolsAnyOrder() {
  const result = await agent.invoke({
    messages: [new HumanMessage("What's happening in SF today?")]
  });

  const referenceTrajectory = [
    new HumanMessage("What's happening in SF today?"),
    new AIMessage({
      content: "",
      tool_calls: [
        { id: "call_1", name: "get_events", args: { city: "SF" } },
        { id: "call_2", name: "get_weather", args: { city: "SF" } },
      ]
    }),
    new ToolMessage({ content: "Events in SF: Concert tonight", tool_call_id: "call_1" }),
    new ToolMessage({ content: "Weather in SF: 75Â°F", tool_call_id: "call_2" }),
    new AIMessage("Today in SF: 75Â°F with a concert tonight."),
  ];

  const evaluation = await evaluator({
    outputs: result.messages,
    referenceOutputs: referenceTrajectory,
  });

  expect(evaluation.score).toBe(true);
}
```

### å­é›†/è¶…é›†åŒ¹é…

ç¡®ä¿ Agent è°ƒç”¨äº†å¿…è¦çš„å·¥å…·ï¼Œæˆ–æ²¡æœ‰è°ƒç”¨å¤šä½™çš„å·¥å…·ï¼š

```typescript
const evaluator = createTrajectoryMatchEvaluator({
  trajectoryMatchMode: "superset"
});

async function testMinimumRequiredTools() {
  const result = await agent.invoke({
    messages: [new HumanMessage("What's the weather in Boston?")]
  });

  const referenceTrajectory = [
    new HumanMessage("What's the weather in Boston?"),
    new AIMessage({
      content: "",
      tool_calls: [
        { id: "call_1", name: "get_weather", args: { city: "Boston" } },
      ]
    }),
    new ToolMessage({
      content: "Weather in Boston: 75Â°F",
      tool_call_id: "call_1"
    }),
    new AIMessage("The weather in Boston is 75Â°F."),
  ];

  const evaluation = await evaluator({
    outputs: result.messages,
    referenceOutputs: referenceTrajectory,
  });

  expect(evaluation.score).toBe(true);
}
```

## LLM-as-Judge è¯„ä¼°

å½“é¢„å®šä¹‰è½¨è¿¹ä¸å¯è¡Œæ—¶ï¼Œç”¨ LLM è¯„ä¼° Agent è¡Œä¸ºæ˜¯å¦åˆç†ã€‚

### æ— å‚è€ƒè½¨è¿¹è¯„ä¼°

```typescript
import { createTrajectoryLLMAsJudge, TRAJECTORY_ACCURACY_PROMPT } from "agentevals";

const evaluator = createTrajectoryLLMAsJudge({
  model: "openai:o3-mini",
  prompt: TRAJECTORY_ACCURACY_PROMPT
});

async function testTrajectoryQuality() {
  const result = await agent.invoke({
    messages: [new HumanMessage("What's the weather in Seattle?")]
  });

  const evaluation = await evaluator({
    outputs: result.messages
  });

  console.log(evaluation);
  // {
  //   key: 'trajectory_accuracy',
  //   score: true,
  //   comment: 'The agent correctly used the weather tool...'
  // }

  expect(evaluation.score).toBe(true);
}
```

### å¸¦å‚è€ƒè½¨è¿¹è¯„ä¼°

æä¾›å‚è€ƒè½¨è¿¹ï¼Œè®© Judge è¯„ä¼°æ˜¯å¦ç¬¦åˆé¢„æœŸï¼š

```typescript
import { 
  createTrajectoryLLMAsJudge, 
  TRAJECTORY_ACCURACY_PROMPT_WITH_REFERENCE 
} from "agentevals";

const evaluator = createTrajectoryLLMAsJudge({
  model: "openai:o3-mini",
  prompt: TRAJECTORY_ACCURACY_PROMPT_WITH_REFERENCE
});

async function testWithReference() {
  const result = await agent.invoke({
    messages: [new HumanMessage("What's the weather in Seattle?")]
  });

  const referenceTrajectory = [
    new HumanMessage("What's the weather in Seattle?"),
    new AIMessage({
      content: "",
      tool_calls: [{ id: "call_1", name: "get_weather", args: { city: "Seattle" } }]
    }),
    new ToolMessage({ content: "Weather: 65Â°F, cloudy", tool_call_id: "call_1" }),
    new AIMessage("Seattle is 65Â°F and cloudy today."),
  ];

  const evaluation = await evaluator({
    outputs: result.messages,
    referenceOutputs: referenceTrajectory
  });

  expect(evaluation.score).toBe(true);
}
```

## LangSmith é›†æˆ

### é…ç½®ç¯å¢ƒ

```bash
export LANGSMITH_API_KEY="your_api_key"
export LANGSMITH_TRACING="true"
```

### ä½¿ç”¨ Vitest/Jest é›†æˆ

```typescript
import * as ls from "langsmith/vitest";
// import * as ls from "langsmith/jest";

import { createTrajectoryLLMAsJudge, TRAJECTORY_ACCURACY_PROMPT } from "agentevals";
import { HumanMessage, AIMessage, ToolMessage } from "@langchain/core/messages";

const trajectoryEvaluator = createTrajectoryLLMAsJudge({
  model: "openai:o3-mini",
  prompt: TRAJECTORY_ACCURACY_PROMPT
});

ls.describe("Weather Agent Tests", () => {
  ls.test("should call weather tool for weather questions", {
    inputs: {
      messages: [{ role: "user", content: "What is the weather in SF?" }]
    },
    referenceOutputs: {
      messages: [
        new HumanMessage("What is the weather in SF?"),
        new AIMessage({
          content: "",
          tool_calls: [{ id: "call_1", name: "get_weather", args: { city: "SF" } }]
        }),
        new ToolMessage({
          content: "It's 75 degrees and sunny in SF.",
          tool_call_id: "call_1"
        }),
        new AIMessage("The weather in SF is 75 degrees and sunny."),
      ],
    },
  }, async ({ inputs, referenceOutputs }) => {
    const result = await agent.invoke({
      messages: [new HumanMessage("What is the weather in SF?")]
    });

    ls.logOutputs({ messages: result.messages });

    await trajectoryEvaluator({
      inputs,
      outputs: result.messages,
      referenceOutputs,
    });
  });
});
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
vitest run weather-agent.eval.ts
# æˆ–
jest weather-agent.eval.ts
```

### ä½¿ç”¨ evaluate å‡½æ•°

```typescript
import { evaluate } from "langsmith/evaluation";
import { createTrajectoryLLMAsJudge, TRAJECTORY_ACCURACY_PROMPT } from "agentevals";

const trajectoryEvaluator = createTrajectoryLLMAsJudge({
  model: "openai:o3-mini",
  prompt: TRAJECTORY_ACCURACY_PROMPT
});

async function runAgent(inputs: any) {
  const result = await agent.invoke(inputs);
  return result.messages;
}

await evaluate(
  runAgent,
  {
    data: "weather_agent_test_dataset",
    evaluators: [trajectoryEvaluator],
  }
);
```

## æµ‹è¯•ç­–ç•¥å»ºè®®

### 1. åˆ†å±‚æµ‹è¯•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  E2E æµ‹è¯•ï¼ˆå°‘é‡ï¼‰                            â”‚
â”‚  - å®Œæ•´æµç¨‹æµ‹è¯•                              â”‚
â”‚  - ä½¿ç”¨ LLM-as-Judge                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  é›†æˆæµ‹è¯•ï¼ˆä¸­ç­‰ï¼‰                            â”‚
â”‚  - è½¨è¿¹åŒ¹é…æµ‹è¯•                              â”‚
â”‚  - å…³é”®è·¯å¾„è¦†ç›–                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å•å…ƒæµ‹è¯•ï¼ˆå¤§é‡ï¼‰                            â”‚
â”‚  - å·¥å…·å‡½æ•°æµ‹è¯•                              â”‚
â”‚  - Mock LLM è°ƒç”¨                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å…³é”®è¡Œä¸ºæµ‹è¯•

é‡ç‚¹æµ‹è¯•è¿™äº›è¡Œä¸ºï¼š
- Agent **å¿…é¡»è°ƒç”¨**ç‰¹å®šå·¥å…·çš„åœºæ™¯
- Agent **ä¸èƒ½è°ƒç”¨**ç‰¹å®šå·¥å…·çš„åœºæ™¯
- å·¥å…·å‚æ•°çš„æ­£ç¡®æ€§
- é”™è¯¯å¤„ç†å’Œæ¢å¤

```typescript
describe("Weather Agent Critical Behaviors", () => {
  test("MUST call weather tool when asked about weather", async () => {
    // è½¨è¿¹åŒ¹é… - strict æ¨¡å¼
  });

  test("MUST NOT call weather tool for general questions", async () => {
    // ç¡®ä¿ä¸ä¼šå¯¹"ä½ å¥½"è¿™ç±»é—®é¢˜è°ƒç”¨å¤©æ°”å·¥å…·
  });

  test("MUST handle API errors gracefully", async () => {
    // Mock å·¥å…·è¿”å›é”™è¯¯ï¼ŒéªŒè¯ Agent å¤„ç†
  });
});
```

### 3. å›å½’æµ‹è¯•

ä¿å­˜å†å²æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿æ–°æ”¹åŠ¨ä¸ç ´åå·²æœ‰è¡Œä¸ºï¼š

```typescript
const regressionTestCases = [
  {
    input: "Weather in SF?",
    expectedToolCalls: ["get_weather"],
    description: "Basic weather query"
  },
  {
    input: "Tell me about SF",
    expectedToolCalls: [],
    description: "Should not call tool for general info"
  }
];

for (const testCase of regressionTestCases) {
  test(testCase.description, async () => {
    // ...
  });
}
```

## å®Œæ•´æµ‹è¯•ç¤ºä¾‹

```typescript
// weather-agent.test.ts
import { createAgent, tool } from "langchain";
import { HumanMessage, AIMessage, ToolMessage } from "@langchain/core/messages";
import { 
  createTrajectoryMatchEvaluator,
  createTrajectoryLLMAsJudge,
  TRAJECTORY_ACCURACY_PROMPT
} from "agentevals";
import * as z from "zod";

const getWeather = tool(
  async ({ city }) => `Weather in ${city}: 75Â°F, sunny`,
  {
    name: "get_weather",
    description: "Get weather for a city",
    schema: z.object({ city: z.string() })
  }
);

const agent = createAgent({
  model: "gpt-4.1",
  tools: [getWeather],
  systemPrompt: "You are a weather assistant. Use get_weather tool for weather queries."
});

describe("Weather Agent", () => {
  const strictEvaluator = createTrajectoryMatchEvaluator({
    trajectoryMatchMode: "strict"
  });

  const llmJudge = createTrajectoryLLMAsJudge({
    model: "openai:o3-mini",
    prompt: TRAJECTORY_ACCURACY_PROMPT
  });

  test("calls weather tool for weather questions", async () => {
    const result = await agent.invoke({
      messages: [new HumanMessage("What's the weather in Tokyo?")]
    });

    const reference = [
      new HumanMessage("What's the weather in Tokyo?"),
      new AIMessage({
        content: "",
        tool_calls: [{ id: "call_1", name: "get_weather", args: { city: "Tokyo" } }]
      }),
      new ToolMessage({ content: "Weather in Tokyo: 75Â°F, sunny", tool_call_id: "call_1" }),
      new AIMessage("The weather in Tokyo is 75Â°F and sunny."),
    ];

    const evaluation = await strictEvaluator({
      outputs: result.messages,
      referenceOutputs: reference
    });

    expect(evaluation.score).toBe(true);
  });

  test("produces reasonable trajectory (LLM judge)", async () => {
    const result = await agent.invoke({
      messages: [new HumanMessage("How's the weather in Paris?")]
    });

    const evaluation = await llmJudge({
      outputs: result.messages
    });

    expect(evaluation.score).toBe(true);
    console.log("Judge comment:", evaluation.comment);
  });
});
```

## æœ¬ç« å°ç»“

Agent æµ‹è¯•çš„æ ¸å¿ƒè¦ç‚¹ï¼š

1. **æ ¸å¿ƒæŒ‘æˆ˜**ï¼š
   - LLM éç¡®å®šæ€§ï¼Œä¼ ç»Ÿæ–­è¨€å¤±æ•ˆ
   - éœ€è¦æµ‹è¯•æ‰§è¡Œè½¨è¿¹è€Œéå…·ä½“è¾“å‡º

2. **ä¸¤ç§æ–¹æ³•**ï¼š
   - è½¨è¿¹åŒ¹é…ï¼šç¡®å®šæ€§ã€å¿«é€Ÿã€é¢„å®šä¹‰æœŸæœ›
   - LLM-as-Judgeï¼šçµæ´»ã€è¯„ä¼°å¤æ‚è¡Œä¸º

3. **è½¨è¿¹åŒ¹é…æ¨¡å¼**ï¼š
   - strictï¼šå®Œå…¨åŒ¹é…
   - unorderedï¼šé¡ºåºæ— å…³
   - subsetï¼šä¸èƒ½å¤šè°ƒç”¨
   - supersetï¼šè‡³å°‘è°ƒç”¨

4. **æµ‹è¯•ç­–ç•¥**ï¼š
   - åˆ†å±‚æµ‹è¯•ï¼šE2E < é›†æˆ < å•å…ƒ
   - å…³é”®è¡Œä¸ºæµ‹è¯•ï¼šå¿…é¡»/ä¸èƒ½è°ƒç”¨
   - å›å½’æµ‹è¯•ï¼šä¿æŠ¤å·²æœ‰è¡Œä¸º

5. **LangSmith é›†æˆ**ï¼š
   - Vitest/Jest é›†æˆ
   - evaluate å‡½æ•°
   - è‡ªåŠ¨è®°å½•æµ‹è¯•ç»“æœ

Agent æµ‹è¯•æ˜¯ä¿è¯ç”Ÿäº§è´¨é‡çš„å…³é”®ï¼Œè™½ç„¶ä¸èƒ½ 100% ä¿è¯è¡Œä¸ºä¸€è‡´ï¼Œä½†èƒ½å¤§å¹…é™ä½å‡ºé”™æ¦‚ç‡ï¼

## æ•™ç¨‹æ€»ç»“

æ­å–œä½ å®Œæˆäº† **LangChain ä¸­æ–‡æ•™ç¨‹** å…¨éƒ¨ 30 ç¯‡æ–‡ç« ï¼

è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹å­¦åˆ°çš„å†…å®¹ï¼š

| ç¯‡ç«  | å†…å®¹ |
|------|------|
| **åŸºç¡€å…¥é—¨ç¯‡** | Agent æ¦‚å¿µã€å·¥å…·è°ƒç”¨ã€æ¶ˆæ¯ç³»ç»Ÿã€æ¨¡å‹é…ç½® |
| **é«˜çº§åŠŸèƒ½ç¯‡** | ç»“æ„åŒ–è¾“å‡ºã€ä¸­é—´ä»¶ã€æŠ¤æ ã€è¿è¡Œæ—¶é…ç½® |
| **ä¸Šä¸‹æ–‡å·¥ç¨‹ç¯‡** | ä¸Šä¸‹æ–‡ç®¡ç†ã€MCP åè®®ã€äººæœºåä½œ |
| **å¤šä»£ç†ç³»ç»Ÿç¯‡** | Subagentsã€Handoffsã€Skillsã€Routerã€Custom Workflow |
| **RAG ä¸çŸ¥è¯†åº“ç¯‡** | æ£€ç´¢æµæ°´çº¿ã€ä¸‰ç§ RAG æ¶æ„ |
| **å·¥å…·ä¸éƒ¨ç½²ç¯‡** | LangSmith Studioã€Agent Chat UIã€æµ‹è¯•ç­–ç•¥ |

ç°åœ¨ä½ å·²ç»æŒæ¡äº†æ„å»ºç”Ÿäº§çº§ AI Agent çš„å®Œæ•´æŠ€èƒ½ï¼ğŸ‰
