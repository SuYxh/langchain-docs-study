# LangChain Retrieval (检索) 深度解读

## 1. 一句话省流 (The Essence)

**Retrieval（检索）就是给 AI 装一个"外接大脑"** —— 让大模型在回答问题时，能够实时去外部知识库（你的文档、数据库、网页等）查资料，而不是只靠"出厂时学到的知识"瞎编。

---

## 2. 核心痛点与解决方案 (The "Why")

### 痛点：大模型的两大"硬伤"

| 硬伤 | 具体表现 | 倒霉事举例 |
|------|----------|------------|
| **有限的上下文窗口 (Finite Context)** | 一次性喂不进去整本书、整个知识库 | 你想让 AI 读完你公司 500 页的产品手册？门都没有，Token 直接爆炸 |
| **静态的知识储备 (Static Knowledge)** | 训练数据是历史快照，不知道最新信息 | 问 GPT "今天股票涨了吗？" —— 它只能说"我不知道，我的知识截止到 202X 年" |

### 解决方案：RAG（检索增强生成）

**核心思路：** 不要让模型"死记硬背"，而是让它学会"查资料"！

```
用户问问题 --> AI 先去知识库搜相关内容 --> 把搜到的内容当"小抄"喂给 AI --> AI 基于小抄生成回答
```

这就是 **Retrieval-Augmented Generation (RAG)** 的核心逻辑 —— 检索增强生成。

---

## 3. 生活化类比 (The Analogy)

### 类比：餐厅大厨 vs. 开卷考试的学生

想象 LLM 是一个**经验丰富的大厨**，他脑子里记住了上万道菜谱（训练数据）。

| 场景 | 没有 RAG 的大厨 | 有 RAG 的大厨 |
|------|-----------------|---------------|
| 顾客点了一道家常菜 | 凭记忆做，没问题 | 同样搞定 |
| 顾客说"我要吃你们上周新推出的创意菜" | 懵逼："啥？我不知道有新菜啊..."（知识过时） | 翻开最新菜单（检索），找到配方，完美执行 |
| 顾客说"按照你们店的秘方做这道菜" | "秘方？我没学过..."（缺乏私有知识） | 去后厨查秘方本（知识库），照着做 |

**类比映射表：**

| RAG 概念 | 餐厅类比 |
|----------|----------|
| **LLM** | 大厨的烹饪技能和经验 |
| **Knowledge Base（知识库）** | 后厨的秘方本、最新菜单、食材清单 |
| **Retriever（检索器）** | 大厨去后厨翻资料的动作 |
| **Document Loader** | 把各种来源的菜谱（纸质的、电子的、手写的）整理成统一格式 |
| **Embedding（向量嵌入）** | 给每道菜谱贴上"口味标签"，方便按口味快速查找 |
| **Vector Store（向量数据库）** | 一个智能菜谱柜，能按"口味相似度"快速定位菜谱 |

---

## 4. 关键概念拆解 (Key Concepts)

### 4.1 Document Loaders（文档加载器）

**人话：** 数据搬运工，负责把各种格式的数据（PDF、网页、Notion、Google Drive 等）"翻译"成 LangChain 能理解的统一格式 `Document`。

> 就像你要做菜，得先把食材从冰箱、菜市场、网购包裹里统一拿出来放案板上。

### 4.2 Embeddings（向量嵌入）

**人话：** 把文字变成一串数字（向量），让计算机能用数学方式衡量"两段话有多像"。

> 就像给每道菜打上"辣度、甜度、油腻度"的评分，这样找"和鱼香肉丝口味相似的菜"就很快了。

### 4.3 Vector Store（向量数据库）

**人话：** 专门存储和查询这些"数字版文本"的数据库。查询时不是精确匹配关键词，而是找"意思最接近的"。

> 传统搜索：搜"苹果手机" 只能找到包含"苹果手机"这几个字的内容
> 向量搜索：搜"苹果手机" 还能找到 "iPhone 14 Pro Max"（语义相近）

### 4.4 Retriever（检索器）

**人话：** 接口/抽象层，你告诉它"我想找什么"，它返回"相关的文档"。是连接"用户查询"和"向量数据库"的桥梁。

### 4.5 RAG（检索增强生成）

**人话：** 一种架构模式 —— 先搜资料，再让 AI 基于搜到的资料回答问题。让 AI 从"闭卷考试"变成"开卷考试"。

---

## 5. 代码"人话"解读 (Code Walkthrough)

### 5.1 Agentic RAG 基础示例

```typescript
import { tool, createAgent } from "langchain";

// 定义一个"工具"：获取网页内容
const fetchUrl = tool(
    (url: string) => {
        return `Fetched content from ${url}`;
    },
    { name: "fetch_url", description: "Fetch text content from a URL" }
);

// 创建一个 Agent，并把工具给它
const agent = createAgent({
    model: "claude-sonnet-4-0",
    tools: [fetchUrl],  // <-- 关键：把"查资料的能力"交给 Agent
    systemPrompt,
});
```

**这段代码在干嘛？**

1. **定义工具（tool）：** 相当于给 AI 一把"瑞士军刀"，这里的刀是"能访问网页 URL"的能力
2. **创建 Agent：** 一个能自己思考"我需不需要用工具"的智能体
3. **绑定工具：** `tools: [fetchUrl]` 就是告诉 Agent："嘿，你现在会查网页了！"

**核心逻辑意图：** Agent 在回答问题时，会自己判断"我是不是需要去查资料"，如果需要，就调用 `fetchUrl` 工具去获取外部信息。

### 5.2 完整的文档检索 Agent

```typescript
const fetchDocumentation = tool(
    async (input) => {
        // 安全检查：只允许访问特定域名
        if (!ALLOWED_DOMAINS.some((domain) => input.url.startsWith(domain))) {
            return `Error: URL not allowed...`;
        }
        // 实际去抓取网页内容
        const response = await fetch(input.url);
        return response.text();
    },
    {
        name: "fetch_documentation",
        description: "Fetch and convert documentation from a URL",
        schema: z.object({
            url: z.string().describe("The URL of the documentation to fetch"),
        }),
    }
);
```

**这段代码的逻辑意图：**

1. **安全白名单：** 只允许 Agent 访问指定的官方文档网站（防止 AI 乱爬网页）
2. **参数校验：** 用 `zod` 定义了工具需要的输入格式（URL 字符串）
3. **异步抓取：** 真正去网络上拉取文档内容

---

## 6. 三种 RAG 架构对比 (Architecture Comparison)

文档介绍了三种 RAG 架构，来看看它们的区别：

| 架构 | 一句话描述 | 控制度 | 灵活性 | 延迟 | 适用场景 |
|------|-----------|--------|--------|------|----------|
| **2-Step RAG** | 先搜后答，流程固定 | 高 | 低 | 快且可预测 | FAQ 机器人、文档问答 |
| **Agentic RAG** | AI 自己决定什么时候搜、搜什么 | 低 | 高 | 不确定 | 研究助手、多工具协作 |
| **Hybrid RAG** | 两者结合，加入质量校验环节 | 中 | 中 | 不确定 | 需要高质量回答的领域问答 |

### 2-Step RAG 流程图（人话版）

```
用户提问 --> [必定执行] 搜索相关文档 --> [必定执行] 生成回答 --> 返回给用户
```

**特点：** 简单粗暴，每次都搜，流程固定。适合"用户问的 99% 都需要查资料"的场景。

### Agentic RAG 流程图（人话版）

```
用户提问 --> AI 思考：我需要查资料吗？
           |
           ├── 不需要 --> 直接回答
           |
           └── 需要 --> 调用工具搜索 --> 搜到的够吗？
                                        |
                                        ├── 够了 --> 生成回答
                                        |
                                        └── 不够 --> 继续搜/换个方式搜
```

**特点：** AI 自己当"项目经理"，决定工作流程。更智能，但也更不可控。

### Hybrid RAG 流程图（人话版）

```
用户提问 --> 优化问题（让问题更精准）--> 搜索 --> 搜到的够用吗？
                                              |
                                              ├── 不够 --> 重新优化问题，再搜
                                              |
                                              └── 够了 --> 生成回答 --> 回答质量合格吗？
                                                                      |
                                                                      ├── 合格 --> 返回
                                                                      |
                                                                      └── 不合格 --> 换个思路重试
```

**特点：** 加入了"质量控制"环节，适合对回答准确度要求高的场景。

---

## 7. 真实应用场景 (Real-world Scenarios)

### 场景 1：企业内部知识库问答机器人

**背景：** 你们公司有 500 页的产品手册、200 个常见问题文档、还有内部 Wiki...

**没有 RAG：**
- 用户："我们产品支持 M1 芯片吗？"
- AI："我不知道，我没学过你们公司的产品..."

**有了 2-Step RAG：**
- 用户提问 --> 从产品手册向量库搜索 --> 找到相关段落 --> AI 基于段落回答
- AI："根据产品手册第 127 页，我们的 v2.3 版本开始全面支持 M1 芯片..."

### 场景 2：智能研究助手

**背景：** 帮用户调研最新的 AI 论文、技术博客

**用 Agentic RAG 的优势：**
- 用户："帮我调研一下 2024 年最火的 RAG 优化技术"
- Agent 思考：这个问题需要查资料...
- Agent 调用工具：搜 arXiv 论文 --> 搜技术博客 --> 搜 GitHub 热门项目
- Agent 判断：搜到的够了，开始整合
- 输出：结构化的调研报告

### 场景 3：电商客服（高质量要求）

**背景：** 需要准确回答用户关于退货政策、商品参数的问题，不能瞎编

**用 Hybrid RAG 的优势：**
- 用户："我买的这个手机能退吗？"
- 系统优化问题："查询手机类目商品的退货政策"
- 搜索退货政策文档
- 生成回答
- **自动校验**：回答里提到的政策是否和文档一致？
- 校验通过 --> 返回用户
- 校验失败 --> 重新生成或标记需要人工介入

---

## 8. 总结：什么时候用什么架构？

| 你的场景 | 推荐架构 | 理由 |
|----------|----------|------|
| 问题明确，答案在知识库里肯定有 | 2-Step RAG | 简单高效，延迟可控 |
| 问题复杂，可能需要多轮搜索或多个数据源 | Agentic RAG | 灵活，AI 自己规划 |
| 对准确性要求高，不能出错 | Hybrid RAG | 有质量校验兜底 |

---

## 9. 检索流水线一览 (Pipeline Overview)

```
数据源（Google Drive, Slack, Notion 等）
        |
        v
   Document Loaders（文档加载器）
        |
        v
    Documents（统一格式的文档）
        |
        v
   Split into chunks（切分成小块）
        |
        v
   Embedding Model（向量化）
        |
        v
   Vector Store（向量数据库）
        |
        |<--- User Query（用户查询）--> Query Embedding（查询向量化）
        |
        v
   Retriever（检索匹配）
        |
        v
   LLM（基于检索结果生成回答）
        |
        v
   Answer（最终答案）
```

**核心设计理念：** 模块化！每个环节都可以独立替换，换个向量数据库？换个 Embedding 模型？不用重写整个系统。

---

## 10. 记住这几点就够了

1. **RAG = 让 AI 学会"查资料"**，解决知识过时和私有数据的问题
2. **Embedding 是核心黑魔法**，让"语义搜索"成为可能
3. **三种架构选对场景**：简单场景用 2-Step，复杂场景用 Agentic，高要求场景用 Hybrid
4. **模块化设计**：LangChain 的检索流水线每个环节都可拆卸替换

现在你可以自信地告诉别人："RAG 不就是给 AI 开卷考试嘛！" 
